From euler at psu.edu  Thu Sep  5 00:15:00 2019
From: euler at psu.edu (Gray, Gary L)
Date: Wed, 4 Sep 2019 22:15:00 +0000
Subject: pdflatex not finding local files in Win 10
Message-ID: <9C99BF11-C3EA-489F-9014-8B48E377FEAA@psu.edu>

I just finished installing TeX Live 2019 in a Windows 10 VM using the .exe installer on this page:

http://tug.org/texlive/acquire-netinstall.html

The install completed successfully, but when I typeset using pdflatex, it isn't finding local files I put in:

C:\texlive\texmf-local\tex\latex\local\

or in:

C:\texlive\texmf-local\tex\latex\

Both of these directories were created by the installer. A fresh install on macOS finds files placed in the corresponding folder on my Library folder. What else do I need to do to get TeX to find files placed there?

Thank you!

-- Gary L. Gray

From daleif at math.au.dk  Thu Sep  5 10:27:03 2019
From: daleif at math.au.dk (Lars Madsen)
Date: Thu, 5 Sep 2019 08:27:03 +0000
Subject: pdflatex not finding local files in Win 10
In-Reply-To: <9C99BF11-C3EA-489F-9014-8B48E377FEAA@psu.edu>
References: <9C99BF11-C3EA-489F-9014-8B48E377FEAA@psu.edu>
Message-ID: <DB8PR01MB5947202C0B797CD49FD517D1F2BB0@DB8PR01MB5947.eurprd01.prod.exchangelabs.com>

does running

texhash

help?

I do not remember if texmf-local is always searched or needs to have its contents presearched via texhash

There is also an interface for this in the texlive manager (Update filename database)


/Lars Madsen
Institut for Matematik / Department of Mathematics
Aarhus Universitet / Aarhus University
Mere info: http://au.dk/daleif at math<http://au.dk/daleif at imf> / More information: http://au.dk/en/daleif at math<http://au.dk/en/daleif at imf>

________________________________
From: texhax <texhax-bounces+daleif=imf.au.dk at tug.org> on behalf of Gray, Gary L <euler at psu.edu>
Sent: 05 September 2019 00:15
To: texhax at tug.org <texhax at tug.org>
Subject: pdflatex not finding local files in Win 10

I just finished installing TeX Live 2019 in a Windows 10 VM using the .exe installer on this page:

http://tug.org/texlive/acquire-netinstall.html

The install completed successfully, but when I typeset using pdflatex, it isn't finding local files I put in:

C:\texlive\texmf-local\tex\latex\local\

or in:

C:\texlive\texmf-local\tex\latex\

Both of these directories were created by the installer. A fresh install on macOS finds files placed in the corresponding folder on my Library folder. What else do I need to do to get TeX to find files placed there?

Thank you!

-- Gary L. Gray
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190905/43d46def/attachment.html>

From marchywka at hotmail.com  Thu Sep  5 11:11:18 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Thu, 5 Sep 2019 09:11:18 +0000
Subject: pdflatex not finding local files in Win 10
In-Reply-To: <DB8PR01MB5947202C0B797CD49FD517D1F2BB0@DB8PR01MB5947.eurprd01.prod.exchangelabs.com>
References: <9C99BF11-C3EA-489F-9014-8B48E377FEAA@psu.edu>
 <DB8PR01MB5947202C0B797CD49FD517D1F2BB0@DB8PR01MB5947.eurprd01.prod.exchangelabs.com>
Message-ID: <DM6PR08MB604248479C37A9AB45D70AA6BEBB0@DM6PR08MB6042.namprd08.prod.outlook.com>

On Thu, Sep 05, 2019 at 08:27:03AM +0000, Lars Madsen wrote:
>    does running
> 
>    texhash
> 
>    help?
> 
>    I do not remember if texmf-local is always searched or needs to have its contents presearched via texhash
> 
>    There is also an interface for this in the texlive manager (Update filename database)

Are there any kpse utilities that may help at least if you have cygwin ? I got familiar with some of these just
doing a new install and ended up writing my own bash scripts to pre and post pend
specific paths to the installed ones. It looks like first query  kpsewhich for current value,


valorig=`kpsewhich -var-value=$var`

add some new stuff and advertise the result,

concat "$val" "$valorig"
kpse_has || export $var="$valorig$sep{{}$val}//"

see if anything changed and run texhash,

valfinal=`kpsewhich -var-value=$var`
[ "$valorig" == "$valfinal" ] || texhash "$val"

run on three variables apparently tex uses at various times,


. kpse_util prp TEXINPUTS  $over
. kpse_util prp BSTINPUTS  $over
. kpse_util prp BIBINPUTS  $over



> 
>    /Lars Madsen
>    Institut for Matematik / Department of Mathematics
>    Aarhus Universitet / Aarhus University
>    Mere info: [http://au.dk/daleif at imf]http://au.dk/daleif at math / More information:
>    [http://au.dk/en/daleif at imf]http://au.dk/en/daleif at math
>      ______________________________________________________________________________________________________________________
> 
>    From: texhax <texhax-bounces+daleif=imf.au.dk at tug.org> on behalf of Gray, Gary L <euler at psu.edu>
>    Sent: 05 September 2019 00:15
>    To: texhax at tug.org <texhax at tug.org>
>    Subject: pdflatex not finding local files in Win 10
> 
>    I just finished installing TeX Live 2019 in a Windows 10 VM using the .exe installer on this page:
>    [http://tug.org/texlive/acquire-netinstall.html]http://tug.org/texlive/acquire-netinstall.html
>    The install completed successfully, but when I typeset using pdflatex, it isn't finding local files I put in:
>    C:\texlive\texmf-local\tex\latex\local\
>    or in:
>    C:\texlive\texmf-local\tex\latex\
>    Both of these directories were created by the installer. A fresh install on macOS finds files placed in the corresponding
>    folder on my Library folder. What else do I need to do to get TeX to find files placed there?
>    Thank you!
>    -- Gary L. Gray

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From euler at psu.edu  Thu Sep  5 15:03:16 2019
From: euler at psu.edu (Gray, Gary L)
Date: Thu, 5 Sep 2019 13:03:16 +0000
Subject: pdflatex not finding local files in Win 10
In-Reply-To: <DB8PR01MB5947202C0B797CD49FD517D1F2BB0@DB8PR01MB5947.eurprd01.prod.exchangelabs.com>
References: <9C99BF11-C3EA-489F-9014-8B48E377FEAA@psu.edu>
 <DB8PR01MB5947202C0B797CD49FD517D1F2BB0@DB8PR01MB5947.eurprd01.prod.exchangelabs.com>
Message-ID: <36904D4B-CA57-4649-AA47-4D7CBBDB2E41@psu.edu>

That did it! Thank you -- I had forgotten about that.

Gary

> On Sep 5, 2019, at 4:27 AM, Lars Madsen <daleif at math.au.dk> wrote:
> 
> does running 
> 
> texhash
> 
> help?
> 
> I do not remember if texmf-local is always searched or needs to have its contents presearched via texhash
> 
> There is also an interface for this in the texlive manager (Update filename database)
> 
> 
> /Lars Madsen
> Institut for Matematik / Department of Mathematics
> Aarhus Universitet / Aarhus University
> Mere info: http://au.dk/daleif at math / More information: http://au.dk/en/daleif at math
> 
> From: texhax <texhax-bounces+daleif=imf.au.dk at tug.org> on behalf of Gray, Gary L <euler at psu.edu>
> Sent: 05 September 2019 00:15
> To: texhax at tug.org <texhax at tug.org>
> Subject: pdflatex not finding local files in Win 10
>  
> I just finished installing TeX Live 2019 in a Windows 10 VM using the .exe installer on this page:
> 
> http://tug.org/texlive/acquire-netinstall.html
> 
> The install completed successfully, but when I typeset using pdflatex, it isn't finding local files I put in:
> 
> C:\texlive\texmf-local\tex\latex\local\
> 
> or in:
> 
> C:\texlive\texmf-local\tex\latex\
> 
> Both of these directories were created by the installer. A fresh install on macOS finds files placed in the corresponding folder on my Library folder. What else do I need to do to get TeX to find files placed there?
> 
> Thank you!
> 
> -- Gary L. Gray



From marchywka at hotmail.com  Thu Sep  5 16:07:10 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Thu, 5 Sep 2019 14:07:10 +0000
Subject: pdflatex not finding local files in Win 10
In-Reply-To: <36904D4B-CA57-4649-AA47-4D7CBBDB2E41@psu.edu>
References: <9C99BF11-C3EA-489F-9014-8B48E377FEAA@psu.edu>
 <DB8PR01MB5947202C0B797CD49FD517D1F2BB0@DB8PR01MB5947.eurprd01.prod.exchangelabs.com>
 <36904D4B-CA57-4649-AA47-4D7CBBDB2E41@psu.edu>
Message-ID: <DM6PR08MB6042F59C85EDA66977827AD0BEBB0@DM6PR08MB6042.namprd08.prod.outlook.com>

On Thu, Sep 05, 2019 at 01:03:16PM +0000, Gray, Gary L wrote:
> That did it! Thank you -- I had forgotten about that.

I have found that scripts are about the best documentation you can 
have. After floundering on anything it can always be reduced to
scripts and then you can grep for comments- slower than apropos
but if you are stuck it may not matter. 

I've encountered a bunch of issues with inconsistent packages
and it helps if I can prepend obsolete ones in the search path
for some projects
or append the path for questionable additions. 

kpse was less than intuitive but once it was reduced to scripts
I could forget the stuff.

I guess typically you want to run latex from any dir
but I made projects that are predominantly one type or
another- say latex or cpp - and then set paths 
optmized for that. This avoided some name collisions
with things like "setup" although I'd imagine there are better
ways to organize things you have flexibility if you
can play with the paths easily. 

fwiw.



> 
> Gary
> 
> > On Sep 5, 2019, at 4:27 AM, Lars Madsen <daleif at math.au.dk> wrote:
> > 
> > does running 
> > 
> > texhash
> > 
> > help?
> > 
> > I do not remember if texmf-local is always searched or needs to have its contents presearched via texhash
> > 
> > There is also an interface for this in the texlive manager (Update filename database)
> > 
> > 
> > /Lars Madsen
> > Institut for Matematik / Department of Mathematics
> > Aarhus Universitet / Aarhus University
> > Mere info: http://au.dk/daleif at math / More information: http://au.dk/en/daleif at math
> > 
> > From: texhax <texhax-bounces+daleif=imf.au.dk at tug.org> on behalf of Gray, Gary L <euler at psu.edu>
> > Sent: 05 September 2019 00:15
> > To: texhax at tug.org <texhax at tug.org>
> > Subject: pdflatex not finding local files in Win 10
> >  
> > I just finished installing TeX Live 2019 in a Windows 10 VM using the .exe installer on this page:
> > 
> > http://tug.org/texlive/acquire-netinstall.html
> > 
> > The install completed successfully, but when I typeset using pdflatex, it isn't finding local files I put in:
> > 
> > C:\texlive\texmf-local\tex\latex\local\
> > 
> > or in:
> > 
> > C:\texlive\texmf-local\tex\latex\
> > 
> > Both of these directories were created by the installer. A fresh install on macOS finds files placed in the corresponding folder on my Library folder. What else do I need to do to get TeX to find files placed there?
> > 
> > Thank you!
> > 
> > -- Gary L. Gray
> 
> 

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From tug-news at tug.org  Fri Sep  6 01:14:42 2019
From: tug-news at tug.org (TeX Users Group)
Date: Thu, 5 Sep 2019 17:14:42 -0600
Subject: Sep19 TUG news: upcoming tugboat, book review, llmk, meetings, ctan
Message-ID: <201909052314.x85NEg8H001697@freefriends.org>

Dear TeXers

August is behind us. The new school year has started in many schools and
universities - probably a good time to introduce the joy of TeX to your
students or classmates (https://tug.org/begin.html). Many new TeX users
get acquainted with it in an academic environment, often through their
teachers or peers.

In that vein, the deadline for articles for the next regular issue of
the TUGboat journal (https://tug.org/TUGboat) is September 30. See
https://tug.org/TUGboat/location.html for author tips, an article
template, and more. We look forward to all submissions.

I am glad to report that one of the projects funded by our development
fund is completed: Takuta Asakuro's llmk (The Light LaTeX Make,
https://github.com/wtsnjp/llmk). Applications for the devfund are
accepted at any time - there is no deadline. Please consult
https://tug.org/tc/devfund/ for details. On the other hand, if you want
to help TeX-related development, but do not have time to spare, you may
want to donate to the fund - or to the general TUG fund - at
https://tug.org/donate.html.

The next TeX events are the 13th ConTeXt Meeting in Belgium, September
16-21 (https://meeting.contextgarden.net/), and GuIT 2019, Turin,
October 26 (https://www.guitex.org/home/meeting).  The latter is the
${2^{2^2}}^\text{th}$ meeting of the Italian TeX Users group, celebrating
Claudio Beccari's 80th birthday.

A new book review is available at https://tug.org/books -- of Nancy
Stock-Allen's biography of noted typeface designer Carol Twombly,
designer of Lithos, Charlemagne, Trajan, and Adobe Caslon. She was also
one of the graduate students at Stanford during the years of Knuth's
digital typography research, which the book goes into in detail.

Finally, the new packages on CTAN (https://ctan.org) this monthinclude:

- clojure-pamphlet, literate programming based on clojure's pamphlet system
- csvmerge, merge TeX code with csv data
- ddphonism, a LaTeX package for twelve-tone matrices, clock diagrams et al.
- glosmathtools, mathematical glossary tools
- matrix-skeleton, PGF/TikZ support to simplify handling multiple matrix nodes
- quantumarticle, document class for submissions to the Quantum journal
- tokcycle, build tools to process tokens from an input stream token by token
- UniFiTh, a class to typeset theses for University of Florence (Italy)
- zblbuild, help with the choice of a BibLaTeX style and options

Happy TeXing!

Boris Veytsman (TUG president - https://tug.org)

From marchywka at hotmail.com  Sat Sep  7 23:24:16 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sat, 7 Sep 2019 21:24:16 +0000
Subject: viewing long pages, evince seems to choke on simple test file
Message-ID: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>


I was playing around with long pages in xdvik and thought I would return 
to things known to work. I made a simple test file, 
cat pagesize.tex | uniq -c
      1 
      1 \newcommand{\mjms}[1]{ }
      1 %\input{mikemailxxx.tex}
      1 %\documentclass[aps,secnumarabic,balancelastpage,amsmath,amssymb,nofootinbib]{revtex4-2}
      1 \documentclass{article}
      1 %\usepackage[a4paper, total={10in, 80in}]{geometry}
      1 %\usepackage[paperheight=80in,height=78in]{geometry}
      1 \usepackage[paperheight=80in,height=120in]{geometry}
      1 
      1 \begin{document}
      1 
      1 %\input{dum_clip.txt}
   1001 \section{test}
      1 
      1 \end{document}


and ran 


 2181  pdflatex --output-format=pdf pagesize.tex 
 2183  pdflatex --output-format=dvi pagesize.tex 
 2193  history | grep pdflatex

to generate pdf and dvi outputs for viewing in evince. 
Neither seemed right although they were more or less similar 
with the first page blank and the second starting
around section 40 test and ending at 318 in dvi
and 249 in the pdf file. The dvi output
starts like as show below ( I modified dviasm to output
a hex op code address ). It does look like page 1 is 
more or less blank but then page 2 is trying to 
start with "1 test." Is there something simple wrong
with my latex source? I have to admit I did not look 
too closely as I had hoped to avoid problems
but thought I may have hit an overlfow somewhere.
If there is some simple thing to change the scale,
the numbers in the preamble look scary for integer math,
that may be all I need to know. 


Thanks.    


./mydviasm.txt pagesize.dvi |  more
[preamble]
id: 2
numerator: 25400000
denominator: 473628672
magnification: 1000
comment: ' TeX output 2019.09.07:1704'

[postamble]
maxv: 7473.810028pt
maxh: 449.879822pt
maxs: 4
pages: 2

[font definitions]
fntdef: cmr10 at 10pt
fntdef: cmbx12 (12pt)  at 14.399994pt

[page 1 0 0 0 0 0 0 0 0 0]
57 xxx: 'papersize=614.295pt,5781.59999pt'
79 down: 7473.810028pt
7e push:
7f   down: -8727.399994pt
84   down: 8697.399994pt
89   down: 30pt
8d   push:
8e     right: 232.377502pt
a8     fnt: cmr10 at 10pt
a9     set: '1'
aa   pop:
ab pop:

[page 2 0 0 0 0 0 0 0 0 0]
da down: 7473.810028pt
df push:
e0   down: -8727.399994pt
e5   down: 8697.399994pt
ea   push:
eb     down: -8662.399994pt
f0     push:
f1       push:
f2         right: 19.875198pt
10c         fnt: cmbx12 (12pt) at 14.399994pt
10d         set: '1'
10e       pop:
10f       right: 44.175171pt
113       set: 'test'
117     pop:
    y: 27.902756pt
11c     push:
11d       push:
11e         right: 19.875198pt
122         set: '2'
123       pop:
124       right: 44.175171pt
128       set: 'test'
12c     pop:
12d     y0:
12e     push:
12f       push:
130         right: 19.875198pt
134         set: '3'
135       pop:
136       right: 44.175171pt
13a       set: 'test'
13e     pop:
13f     y0:
140     push:
141       push:
142         right: 19.875198pt
146         set: '4'
147       pop:
148       right: 44.175171pt
14c       set: 'test'
150     pop:
151     y0:
152     push:
153       push:
154         right: 19.875198pt
158         set: '5'
159       pop:
15a       right: 44.175171pt
15e       set: 'test'
162     pop:
163     y0:
164     push:
165       push:
166         right: 19.875198pt
16a         set: '6'
16b       pop:
16c       right: 44.175171pt
170       set: 'test'
174     pop:
175     y0:
176     push:
177       push:
178         right: 19.875198pt
17c         set: '7'
17d       pop:
17e       right: 44.175171pt
182       set: 'test'
186     pop:
187     y0:
188     push:
189       push:
18a         right: 19.875198pt
18e         set: '8'
18f       pop:
190       right: 44.175171pt
194       set: 'test'
198     pop:
199     y0:
--More--




Thanks.

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From d.p.carlisle at gmail.com  Sun Sep  8 10:08:23 2019
From: d.p.carlisle at gmail.com (David Carlisle)
Date: Sun, 8 Sep 2019 09:08:23 +0100
Subject: viewing long pages, evince seems to choke on simple test file
In-Reply-To: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>

You don't really need to look in the dvi, (la)tex will warn you already in
the log about what is happening.

The main problem here is that a page break is not allowed after a section
heading so the page is massively overfull, if you change that to
1000 lines of

\section{test}zzz

Then you get more reasonable output. The visible page does start  around
section 22, but the geometry package warns

Package geometry Warning: `tmargin' and `bmargin' result in NEGATIVE
(-2890.8pt
).
    `height' should be shortened in length.




On Sat, 7 Sep 2019 at 22:26, Mike Marchywka <marchywka at hotmail.com> wrote:

>
> I was playing around with long pages in xdvik and thought I would return
> to things known to work. I made a simple test file,
> cat pagesize.tex | uniq -c
>       1
>       1 \newcommand{\mjms}[1]{ }
>       1 %\input{mikemailxxx.tex}
>       1
> %\documentclass[aps,secnumarabic,balancelastpage,amsmath,amssymb,nofootinbib]{revtex4-2}
>       1 \documentclass{article}
>       1 %\usepackage[a4paper, total={10in, 80in}]{geometry}
>       1 %\usepackage[paperheight=80in,height=78in]{geometry}
>       1 \usepackage[paperheight=80in,height=120in]{geometry}
>       1
>       1 \begin{document}
>       1
>       1 %\input{dum_clip.txt}
>    1001 \section{test}
>       1
>       1 \end{document}
>
>
> and ran
>
>
>  2181  pdflatex --output-format=pdf pagesize.tex
>  2183  pdflatex --output-format=dvi pagesize.tex
>  2193  history | grep pdflatex
>
> to generate pdf and dvi outputs for viewing in evince.
> Neither seemed right although they were more or less similar
> with the first page blank and the second starting
> around section 40 test and ending at 318 in dvi
> and 249 in the pdf file. The dvi output
> starts like as show below ( I modified dviasm to output
> a hex op code address ). It does look like page 1 is
> more or less blank but then page 2 is trying to
> start with "1 test." Is there something simple wrong
> with my latex source? I have to admit I did not look
> too closely as I had hoped to avoid problems
> but thought I may have hit an overlfow somewhere.
> If there is some simple thing to change the scale,
> the numbers in the preamble look scary for integer math,
> that may be all I need to know.
>
>
> Thanks.
>
>
> ./mydviasm.txt pagesize.dvi |  more
> [preamble]
> id: 2
> numerator: 25400000
> denominator: 473628672
> magnification: 1000
> comment: ' TeX output 2019.09.07:1704'
>
> [postamble]
> maxv: 7473.810028pt
> maxh: 449.879822pt
> maxs: 4
> pages: 2
>
> [font definitions]
> fntdef: cmr10 at 10pt
> fntdef: cmbx12 (12pt)  at 14.399994pt
>
> [page 1 0 0 0 0 0 0 0 0 0]
> 57 xxx: 'papersize=614.295pt,5781.59999pt'
> 79 down: 7473.810028pt
> 7e push:
> 7f   down: -8727.399994pt
> 84   down: 8697.399994pt
> 89   down: 30pt
> 8d   push:
> 8e     right: 232.377502pt
> a8     fnt: cmr10 at 10pt
> a9     set: '1'
> aa   pop:
> ab pop:
>
> [page 2 0 0 0 0 0 0 0 0 0]
> da down: 7473.810028pt
> df push:
> e0   down: -8727.399994pt
> e5   down: 8697.399994pt
> ea   push:
> eb     down: -8662.399994pt
> f0     push:
> f1       push:
> f2         right: 19.875198pt
> 10c         fnt: cmbx12 (12pt) at 14.399994pt
> 10d         set: '1'
> 10e       pop:
> 10f       right: 44.175171pt
> 113       set: 'test'
> 117     pop:
>     y: 27.902756pt
> 11c     push:
> 11d       push:
> 11e         right: 19.875198pt
> 122         set: '2'
> 123       pop:
> 124       right: 44.175171pt
> 128       set: 'test'
> 12c     pop:
> 12d     y0:
> 12e     push:
> 12f       push:
> 130         right: 19.875198pt
> 134         set: '3'
> 135       pop:
> 136       right: 44.175171pt
> 13a       set: 'test'
> 13e     pop:
> 13f     y0:
> 140     push:
> 141       push:
> 142         right: 19.875198pt
> 146         set: '4'
> 147       pop:
> 148       right: 44.175171pt
> 14c       set: 'test'
> 150     pop:
> 151     y0:
> 152     push:
> 153       push:
> 154         right: 19.875198pt
> 158         set: '5'
> 159       pop:
> 15a       right: 44.175171pt
> 15e       set: 'test'
> 162     pop:
> 163     y0:
> 164     push:
> 165       push:
> 166         right: 19.875198pt
> 16a         set: '6'
> 16b       pop:
> 16c       right: 44.175171pt
> 170       set: 'test'
> 174     pop:
> 175     y0:
> 176     push:
> 177       push:
> 178         right: 19.875198pt
> 17c         set: '7'
> 17d       pop:
> 17e       right: 44.175171pt
> 182       set: 'test'
> 186     pop:
> 187     y0:
> 188     push:
> 189       push:
> 18a         right: 19.875198pt
> 18e         set: '8'
> 18f       pop:
> 190       right: 44.175171pt
> 194       set: 'test'
> 198     pop:
> 199     y0:
> --More--
>
>
>
>
> Thanks.
>
> --
>
> mike marchywka
> 306 charles cox
> canton GA 30115
> USA, Earth
> marchywka at hotmail.com
> 404-788-1216
> ORCID: 0000-0001-9237-455X
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190908/be445a5e/attachment.html>

From marchywka at hotmail.com  Sun Sep  8 10:53:12 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sun, 8 Sep 2019 08:53:12 +0000
Subject: viewing long pages, evince seems to choke on simple test file
In-Reply-To: <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>
References: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>
Message-ID: <DM6PR08MB6042345C972F01872A365677BEB40@DM6PR08MB6042.namprd08.prod.outlook.com>

On Sun, Sep 08, 2019 at 09:08:23AM +0100, David Carlisle wrote:
>    You don't really need to look in the dvi, (la)tex will warn you already in the log about what is happening.
>    The main problem here is that a page break is not allowed after a section heading so the page is massively overfull, if you
>    change that to
>    1000 lines of
>    \section{test}zzz
>    Then you get more reasonable output. The visible page does start  around section 22, but the geometry package warns
>    Package geometry Warning: `tmargin' and `bmargin' result in NEGATIVE (-2890.8pt
>    ).
>        `height' should be shortened in length.
> 
>    On Sat, 7 Sep 2019 at 22:26, Mike Marchywka <[mailto:marchywka at hotmail.com]marchywka at hotmail.com> wrote:
> 
>      I was playing around with long pages in xdvik and thought I would return
>      to things known to work. I made a simple test file,
>      cat pagesize.tex | uniq -c
>            1
>            1 \newcommand{\mjms}[1]{ }
>            1 %\input{mikemailxxx.tex}
>            1 %\documentclass[aps,secnumarabic,balancelastpage,amsmath,amssymb,nofootinbib]{revtex4-2}
>            1 \documentclass{article}
>            1 %\usepackage[a4paper, total={10in, 80in}]{geometry}
>            1 %\usepackage[paperheight=80in,height=78in]{geometry}
>            1 \usepackage[paperheight=80in,height=120in]{geometry}

Thanks, I guess commented out the wrong one, 

\usepackage[paperheight=80in,height=78in]{geometry}
%\usepackage[paperheight=80in,height=120in]{geometry}

that and ignoring the output warnings... 
That seems to fix it now. No idea how that happened although there are so
many warnings typically I don't bother reading them any more  :)


>            1
>            1 \begin{document}
>            1
>            1 %\input{dum_clip.txt}
>         1001 \section{test}
>            1
>            1 \end{document}
>      and ran
>       2181  pdflatex --output-format=pdf pagesize.tex
>       2183  pdflatex --output-format=dvi pagesize.tex
>       2193  history | grep pdflatex
>      to generate pdf and dvi outputs for viewing in evince.
>      Neither seemed right although they were more or less similar
>      with the first page blank and the second starting
>      around section 40 test and ending at 318 in dvi
>      and 249 in the pdf file. The dvi output
>      starts like as show below ( I modified dviasm to output
>      a hex op code address ). It does look like page 1 is
>      more or less blank but then page 2 is trying to
>      start with "1 test." Is there something simple wrong
>      with my latex source? I have to admit I did not look
>      too closely as I had hoped to avoid problems
>      but thought I may have hit an overlfow somewhere.
>      If there is some simple thing to change the scale,
>      the numbers in the preamble look scary for integer math,
>      that may be all I need to know.
>      Thanks.
>      ./mydviasm.txt pagesize.dvi |  more
>      [preamble]
>      id: 2
>      numerator: 25400000
>      denominator: 473628672
>      magnification: 1000
>      comment: ' TeX output 2019.09.07:1704'
>      [postamble]
>      maxv: 7473.810028pt
>      maxh: 449.879822pt
>      maxs: 4
>      pages: 2
>      [font definitions]
>      fntdef: cmr10 at 10pt
>      fntdef: cmbx12 (12pt)  at 14.399994pt
>      [page 1 0 0 0 0 0 0 0 0 0]
>      57 xxx: 'papersize=614.295pt,5781.59999pt'
>      79 down: 7473.810028pt
>      7e push:
>      7f   down: -8727.399994pt
>      84   down: 8697.399994pt
>      89   down: 30pt
>      8d   push:
>      8e     right: 232.377502pt
>      a8     fnt: cmr10 at 10pt
>      a9     set: '1'
>      aa   pop:
>      ab pop:
>      [page 2 0 0 0 0 0 0 0 0 0]
>      da down: 7473.810028pt
>      df push:
>      e0   down: -8727.399994pt
>      e5   down: 8697.399994pt
>      ea   push:
>      eb     down: -8662.399994pt
>      f0     push:
>      f1       push:
>      f2         right: 19.875198pt
>      10c         fnt: cmbx12 (12pt) at 14.399994pt
>      10d         set: '1'
>      10e       pop:
>      10f       right: 44.175171pt
>      113       set: 'test'
>      117     pop:
>          y: 27.902756pt
>      11c     push:
>      11d       push:
>      11e         right: 19.875198pt
>      122         set: '2'
>      123       pop:
>      124       right: 44.175171pt
>      128       set: 'test'
>      12c     pop:
>      12d     y0:
>      12e     push:
>      12f       push:
>      130         right: 19.875198pt
>      134         set: '3'
>      135       pop:
>      136       right: 44.175171pt
>      13a       set: 'test'
>      13e     pop:
>      13f     y0:
>      140     push:
>      141       push:
>      142         right: 19.875198pt
>      146         set: '4'
>      147       pop:
>      148       right: 44.175171pt
>      14c       set: 'test'
>      150     pop:
>      151     y0:
>      152     push:
>      153       push:
>      154         right: 19.875198pt
>      158         set: '5'
>      159       pop:
>      15a       right: 44.175171pt
>      15e       set: 'test'
>      162     pop:
>      163     y0:
>      164     push:
>      165       push:
>      166         right: 19.875198pt
>      16a         set: '6'
>      16b       pop:
>      16c       right: 44.175171pt
>      170       set: 'test'
>      174     pop:
>      175     y0:
>      176     push:
>      177       push:
>      178         right: 19.875198pt
>      17c         set: '7'
>      17d       pop:
>      17e       right: 44.175171pt
>      182       set: 'test'
>      186     pop:
>      187     y0:
>      188     push:
>      189       push:
>      18a         right: 19.875198pt
>      18e         set: '8'
>      18f       pop:
>      190       right: 44.175171pt
>      194       set: 'test'
>      198     pop:
>      199     y0:
>      --More--
>      Thanks.
>      --
>      mike marchywka
>      306 charles cox
>      canton GA 30115
>      USA, Earth
>      [mailto:marchywka at hotmail.com]marchywka at hotmail.com
>      404-788-1216
>      ORCID: 0000-0001-9237-455X

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From marchywka at hotmail.com  Mon Sep  9 16:07:37 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 9 Sep 2019 14:07:37 +0000
Subject: viewing long pages, evince seems to choke on simple test file
In-Reply-To: <DM6PR08MB6042345C972F01872A365677BEB40@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>
 <DM6PR08MB6042345C972F01872A365677BEB40@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <DM6PR08MB604224F7E495C832CD27EB5ABEB70@DM6PR08MB6042.namprd08.prod.outlook.com>

On Sun, Sep 08, 2019 at 08:53:12AM +0000, Mike Marchywka wrote:
> On Sun, Sep 08, 2019 at 09:08:23AM +0100, David Carlisle wrote:
> >    You don't really need to look in the dvi, (la)tex will warn you already in the log about what is happening.
[...]
> Thanks, I guess commented out the wrong one, 
> 
> \usepackage[paperheight=80in,height=78in]{geometry}
> %\usepackage[paperheight=80in,height=120in]{geometry}
> 
> that and ignoring the output warnings... 
> That seems to fix it now. No idea how that happened although there are so
> many warnings typically I don't bother reading them any more  :)
> 

I guess there is some upper limit to page size though. I did not investigate
right now but thought someone may now offhand why this is needed.
400in does not seem excessive in terms of normal ranges although certainly
it is an uncommon sheet size. 
Thanks. 
grep geom dummailtemp.tex | grep -v "%"
\usepackage[paperwidth=6in,width=5in,paperheight=400in,height=398in]{geometry}
marchywka at happy:/home/documents/cpp/proj/mikemail$ pdflatex --output-format=dvi dummailtemp.tex 
This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015/Debian) (preloaded format=pdflatex)
 restricted \write18 enabled.
entering extended mode
(./dummailtemp.tex
LaTeX2e <2016/02/01>
Babel <3.9q> and hyphenation patterns for 12 language(s) loaded.
(./mikemail.tex) (/usr/share/texlive/texmf-dist/tex/latex/base/article.cls
Document Class: article 2014/09/29 v1.4h Standard LaTeX document class
(/usr/share/texlive/texmf-dist/tex/latex/base/size10.clo))
(/usr/share/texlive/texmf-dist/tex/latex/geometry/geometry.sty
(/usr/share/texlive/texmf-dist/tex/latex/graphics/keyval.sty)
(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifpdf.sty)
(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifvtex.sty)
(/usr/share/texlive/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
! Dimension too large.
<to be read again> 
                   \relax 
l.994 \ProcessOptionsKV[p]{Gm}
                              %
? q

fwiw, I attached some screen shots of the play code so far. It is kind of
like a low-tech collapsible table of contents but I'm curious to
see what I can do with it or what already exists like this.
Each block defined in the latex source can either be displayed
normally or collapsed as a one word name inside a box. 
There are two documents, the email literature update I hacked up
which consists of a set of about 18 abstracts and pub info and then
a second document which is a collection of notes I hope to turn into
a paper. I don't know if anyone would compose a scientific work out of
post-it notes and tweets but in essence collapsing by paragraph
lets you view it that way. I kind of like it so far but it may just
be the novelty. The view is changed by either a mouse click or a command
line entry that can accept a stem  ( at some point a regex maybe )
and change visibility of all matching blocks.  
I can already envision some useful mouse click commands ( although
that may be all I do as I still can't even figure out how
to inject events into queue to update screen without dummy mouseover lol).

With this granularity of collapsibility, it makes citing and note
taking easier as I think Doug suggested in legal docs paragraph
numbers are helpful.I can collapse most of the clutter except for
what I want to use and then just copy normally with mouse in one
operation or from command line utility, "copy visible paragrphs to clipboard."
 
I guess one thing that may be nice is to include bibtex when copying
to clipboard. In my own docs I include "suggested bibtex" in human
readable form but if the clipboard knew about that it would make
it easier to cite ( maybe there is some latex gui or ide that
does stuff like that ). 

Thanks
-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2019-09-08-161651_1015x594_scrot.png
Type: image/png
Size: 63598 bytes
Desc: 2019-09-08-161651_1015x594_scrot.png
URL: <https://tug.org/pipermail/texhax/attachments/20190909/eb8defa9/attachment-0007.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2019-09-08-161710_1015x594_scrot.png
Type: image/png
Size: 51227 bytes
Desc: 2019-09-08-161710_1015x594_scrot.png
URL: <https://tug.org/pipermail/texhax/attachments/20190909/eb8defa9/attachment-0008.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2019-09-08-161732_1015x594_scrot.png
Type: image/png
Size: 41812 bytes
Desc: 2019-09-08-161732_1015x594_scrot.png
URL: <https://tug.org/pipermail/texhax/attachments/20190909/eb8defa9/attachment-0009.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2019-09-09-065832_1028x553_scrot.png
Type: image/png
Size: 34571 bytes
Desc: 2019-09-09-065832_1028x553_scrot.png
URL: <https://tug.org/pipermail/texhax/attachments/20190909/eb8defa9/attachment-0010.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2019-09-09-070446_1028x553_scrot.png
Type: image/png
Size: 65157 bytes
Desc: 2019-09-09-070446_1028x553_scrot.png
URL: <https://tug.org/pipermail/texhax/attachments/20190909/eb8defa9/attachment-0011.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2019-09-09-070713_1028x566_scrot.png
Type: image/png
Size: 46303 bytes
Desc: 2019-09-09-070713_1028x566_scrot.png
URL: <https://tug.org/pipermail/texhax/attachments/20190909/eb8defa9/attachment-0012.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2019-09-09-071809_1028x566_scrot.png
Type: image/png
Size: 27555 bytes
Desc: 2019-09-09-071809_1028x566_scrot.png
URL: <https://tug.org/pipermail/texhax/attachments/20190909/eb8defa9/attachment-0013.png>

From d.p.carlisle at gmail.com  Mon Sep  9 16:35:21 2019
From: d.p.carlisle at gmail.com (David Carlisle)
Date: Mon, 9 Sep 2019 15:35:21 +0100
Subject: viewing long pages, evince seems to choke on simple test file
In-Reply-To: <DM6PR08MB604224F7E495C832CD27EB5ABEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>
 <DM6PR08MB6042345C972F01872A365677BEB40@DM6PR08MB6042.namprd08.prod.outlook.com>
 <DM6PR08MB604224F7E495C832CD27EB5ABEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <CAEW6iOiqJ8=9io6Z3krqUo+juEOhdcZrdO0pSV8kOheq7rqrTg@mail.gmail.com>

On Mon, 9 Sep 2019 at 15:28, Mike Marchywka <marchywka at hotmail.com> wrote:

> On Sun, Sep 08, 2019 at 08:53:12AM +0000, Mike Marchywka wrote:
> > On Sun, Sep 08, 2019 at 09:08:23AM +0100, David Carlisle wrote:
> > >    You don't really need to look in the dvi, (la)tex will warn you
> already in the log about what is happening.
> [...]
> > Thanks, I guess commented out the wrong one,
> >
> > \usepackage[paperheight=80in,height=78in]{geometry}
> > %\usepackage[paperheight=80in,height=120in]{geometry}
> >
> > that and ignoring the output warnings...
> > That seems to fix it now. No idea how that happened although there are so
> > many warnings typically I don't bother reading them any more  :)
> >
>
> I guess there is some upper limit to page size though. I did not
> investigate
> right now but thought someone may now offhand why this is needed.
> 400in does not seem excessive in terms of normal ranges although certainly
> it is an uncommon sheet size.
> Thanks.
>

400in is around twice TeX's largest dimension.

The TeXBook says:


 \TeX\ will not deal with dimensions whose absolute value is
$\rm2^{30}\,sp$ or more. In other words, the ^{maximum legal dimension} is
slightly less than $16384\pt$. This is a distance of about 18.892 feet
(5.7583 meters), so it won't cramp your style.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190909/dc25c6a1/attachment.html>

From Julius.Muller at gmx.net  Mon Sep  9 16:40:47 2019
From: Julius.Muller at gmx.net (Julius Dittmar)
Date: Mon, 9 Sep 2019 16:40:47 +0200
Subject: viewing long pages, evince seems to choke on simple test file
In-Reply-To: <DM6PR08MB604224F7E495C832CD27EB5ABEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>
 <DM6PR08MB6042345C972F01872A365677BEB40@DM6PR08MB6042.namprd08.prod.outlook.com>
 <DM6PR08MB604224F7E495C832CD27EB5ABEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <3f2f32e6-f386-3a94-4e21-08d98506ba92@gmx.net>

Hi Mike,

Am 09.09.19 um 16:07 schrieb Mike Marchywka:
> I guess there is some upper limit to page size though. I did not investigate
> right now but thought someone may now offhand why this is needed.
> 400in does not seem excessive in terms of normal ranges although certainly
> it is an uncommon sheet size.
> Thanks.

I guess that is due to how dimensions are represented in TeX:
essentially as integer numbers. There's a range to every kind of integer
numbers (in fact, to every kind of numbers) in computers, and that's the
case also here. The unit has been chosen in a way that every normal
paper size (even poster size) can be represented, but not more than that.

Hope that helps,
Julius


From marchywka at hotmail.com  Mon Sep  9 17:07:29 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 9 Sep 2019 15:07:29 +0000
Subject: viewing long pages, evince seems to choke on simple test file
In-Reply-To: <CAEW6iOiqJ8=9io6Z3krqUo+juEOhdcZrdO0pSV8kOheq7rqrTg@mail.gmail.com>
References: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>
 <DM6PR08MB6042345C972F01872A365677BEB40@DM6PR08MB6042.namprd08.prod.outlook.com>
 <DM6PR08MB604224F7E495C832CD27EB5ABEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOiqJ8=9io6Z3krqUo+juEOhdcZrdO0pSV8kOheq7rqrTg@mail.gmail.com>
Message-ID: <DM6PR08MB60429EE06D4402FDC9C46AF6BEB70@DM6PR08MB6042.namprd08.prod.outlook.com>

On Mon, Sep 09, 2019 at 03:35:21PM +0100, David Carlisle wrote:
>    On Mon, 9 Sep 2019 at 15:28, Mike Marchywka <[mailto:marchywka at hotmail.com]marchywka at hotmail.com> wrote:
> 
>      On Sun, Sep 08, 2019 at 08:53:12AM +0000, Mike Marchywka wrote:
>      > On Sun, Sep 08, 2019 at 09:08:23AM +0100, David Carlisle wrote:
>      > >    You don't really need to look in the dvi, (la)tex will warn you already in the log about what is happening.
>      [...]
>      > Thanks, I guess commented out the wrong one,
>      >
>      > \usepackage[paperheight=80in,height=78in]{geometry}
>      > %\usepackage[paperheight=80in,height=120in]{geometry}
>      >
>      > that and ignoring the output warnings...
>      > That seems to fix it now. No idea how that happened although there are so
>      > many warnings typically I don't bother reading them any more  :)
>      >
>      I guess there is some upper limit to page size though. I did not investigate
>      right now but thought someone may now offhand why this is needed.
>      400in does not seem excessive in terms of normal ranges although certainly
>      it is an uncommon sheet size.
>      Thanks.
> 
>    400in is around twice TeX's largest dimension.
>    The TeXBook says:
>     \TeX\ will not deal with dimensions whose absolute value is
>    $\rm2^{30}\,sp$ or more. In other words, the ^{maximum legal dimension} is
>    slightly less than $16384\pt$. This is a distance of about 18.892 feet
>    (5.7583 meters), so it won't cramp your style.

Was there some reason known for this or as the other response suggested this
was back in the day of 32 or 16 bit integers? Personally I like fixed point
and have worked with that before for fast audio decompress and faught floating
point round off enough :) However those huge ints in the preamble seemed
a bit arbitrary and with some rounding maybe could be brought down to
extend range vs epsilon or something. I have been browsing the code
but ignoring dimensional stuff ( I still think a font is just a lut
between bytes and 5x7 bit map although 35 bits is too big for a 32 bit int LOL ).

And you have yet to hear from hoards of angry scroll scribes? Seriously
though the fixed page thing is a bit of a potential issue. Although this
is not map or mask ( for integrated circuit design ) layout and I guess
typesetting does not need huge dynamic range most of the time as you
can page to essentially arbitrary size.  

Thanks.

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From doug at mathemaesthetics.com  Mon Sep  9 19:46:05 2019
From: doug at mathemaesthetics.com (Doug McKenna)
Date: Mon, 9 Sep 2019 11:46:05 -0600 (MDT)
Subject: viewing long pages, evince seems to choke on simple test file
In-Reply-To: <DM6PR08MB60429EE06D4402FDC9C46AF6BEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>
 <DM6PR08MB6042345C972F01872A365677BEB40@DM6PR08MB6042.namprd08.prod.outlook.com>
 <DM6PR08MB604224F7E495C832CD27EB5ABEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOiqJ8=9io6Z3krqUo+juEOhdcZrdO0pSV8kOheq7rqrTg@mail.gmail.com>
 <DM6PR08MB60429EE06D4402FDC9C46AF6BEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <1214146819.8849269.1568051165047.JavaMail.zimbra@mathemaesthetics.com>

Mike Marchywka wrote:

>| Was there some reason known for this
>| or as the other response suggested this
>| was back in the day of 32 or 16 bit integers?

TeX uses 32-bits as the word size of integers, with the upper 16 bits the signed integer part of a fixed point "Dimension" and the lower 16 bits for the fractional part.  But the connection to the real world is that the low-order 16 bits measure 1/65536th of a point, each point being 72.27 per inch.  Had these bits measured 1/10000th of a point, Knuth would have avoided some input/output round-off problems, and would have increased the dynamic range of a Dimension by a factor of 6 or so, with attendant loss of precision.  C'est la vie.

But TeX also artificially prevents a Dimension from using the high-order (non-sign) bit of those 16 bits, so that any two TeX-legal Dimensions can always be added without checking for twos-complement overflow.  So the dynamic range of a Dimension is halved; it's really using a form of [15:16] fixed point arithmetic, which is plus/minus 18.8921 feet.  Worse, there are hacks in TeX's source code (see, e.g., running widths in Rules) that take advantage of using that otherwise "free" bit as a flag (to avoid a second argument to a subroutine by using an otherwise illegal dimension value), which in turn makes changing things messier than otherwise.

On today's 64-bit machines, one (ahem!) might configure a TeX-language interpreter at compile time to use [48:16] fixed-point arithmetic, which would allow a single page to be about 30 million miles long.  Sadly, that unrolled scroll would make it only about 20% of the way to Mars.

Doug McKenna
Mathemaesthetics, Inc.

From reinhard.kotucha at web.de  Tue Sep 10 00:32:37 2019
From: reinhard.kotucha at web.de (Reinhard Kotucha)
Date: Tue, 10 Sep 2019 00:32:37 +0200
Subject: viewing long pages, evince seems to choke on simple test file
In-Reply-To: <1214146819.8849269.1568051165047.JavaMail.zimbra@mathemaesthetics.com>
References: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>
 <DM6PR08MB6042345C972F01872A365677BEB40@DM6PR08MB6042.namprd08.prod.outlook.com>
 <DM6PR08MB604224F7E495C832CD27EB5ABEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOiqJ8=9io6Z3krqUo+juEOhdcZrdO0pSV8kOheq7rqrTg@mail.gmail.com>
 <DM6PR08MB60429EE06D4402FDC9C46AF6BEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
 <1214146819.8849269.1568051165047.JavaMail.zimbra@mathemaesthetics.com>
Message-ID: <23926.54021.516568.735014@gargle.gargle.HOWL>

On 2019-09-09 at 11:46:05 -0600, Doug McKenna wrote:

 > Mike Marchywka wrote:
 >
 > >| Was there some reason known for this
 > >| or as the other response suggested this
 > >| was back in the day of 32 or 16 bit integers?
 >
 > TeX uses 32-bits as the word size of integers, with the upper 16
 > bits the signed integer part of a fixed point "Dimension" and the
 > lower 16 bits for the fractional part.  But the connection to the
 > real world is that the low-order 16 bits measure 1/65536th of a
 > point, each point being 72.27 per inch.  Had these bits measured
 > 1/10000th of a point, Knuth would have avoided some input/output
 > round-off problems, and would have increased the dynamic range of a
 > Dimension by a factor of 6 or so, with attendant loss of precision.
 > C'est la vie.

I don't think that Knuth would have avoided any rounding errors by
using decimal numbers.  Computers still use the binary system
internally.  Rounding errors occur when you convert binary numbers to
decimal and vice versa.  Of course, this is quite confusing to humans.
But keep in mind that even the decimal number 0.1 cannot be
represented in the binary system with a finite amount of binary
digits.

Given that Knuth did not consider printing on toilet paper, his
decision was quite reasonable.  He used floating point numbers at the
beginning but switched to fixed point integer numbers when he noticed
that he got different results on different machines.

Sure, more than 32 bit for dimensions would be quite nice in some
special cases but after all, he wrote TeX in order to write his own
books in the first place.  Much more annoying is the limited range in
Metapost because you often have to do extensive calculations in order
to determine dimensions, hence intermediate results are likely to
cause an overfow.

 > On today's 64-bit machines, one (ahem!) might configure a
 > TeX-language interpreter at compile time to use [48:16] fixed-point
 > arithmetic, which would allow a single page to be about 30 million
 > miles long.  Sadly, that unrolled scroll would make it only about
 > 20% of the way to Mars.

This doesn't make much sense either because PDF (at least 1.4) has similar
limitations.  Only a homemade DVI driver could extend the range, but
it could also scale the page so that the range of TeX's dimensions can
be left as it is.

BTW, there is a nice TUGboat article by Nelson Beebe about different
representations of numbers and their quirks:

  https://tug.org/TUGboat/tb28-3/tb90beebe.pdf

Regards,
  Reinhard

--
------------------------------------------------------------------
Reinhard Kotucha                            Phone: +49-511-3373112
Marschnerstr. 25
D-30167 Hannover                    mailto:reinhard.kotucha at web.de
------------------------------------------------------------------


From marchywka at hotmail.com  Tue Sep 10 01:43:53 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 9 Sep 2019 23:43:53 +0000
Subject: viewing long pages, evince seems to choke on simple test file
In-Reply-To: <23926.54021.516568.735014@gargle.gargle.HOWL>
References: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>
 <DM6PR08MB6042345C972F01872A365677BEB40@DM6PR08MB6042.namprd08.prod.outlook.com>
 <DM6PR08MB604224F7E495C832CD27EB5ABEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOiqJ8=9io6Z3krqUo+juEOhdcZrdO0pSV8kOheq7rqrTg@mail.gmail.com>
 <DM6PR08MB60429EE06D4402FDC9C46AF6BEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
 <1214146819.8849269.1568051165047.JavaMail.zimbra@mathemaesthetics.com>
 <23926.54021.516568.735014@gargle.gargle.HOWL>
Message-ID: <DM6PR08MB6042953E043B3BFFA85F196BBEB70@DM6PR08MB6042.namprd08.prod.outlook.com>

On Tue, Sep 10, 2019 at 12:32:37AM +0200, Reinhard Kotucha wrote:
> On 2019-09-09 at 11:46:05 -0600, Doug McKenna wrote:
> 
>  > Mike Marchywka wrote:
>  >
>  > >| Was there some reason known for this
>  > >| or as the other response suggested this
>  > >| was back in the day of 32 or 16 bit integers?
>  >
>  > TeX uses 32-bits as the word size of integers, with the upper 16
>  > bits the signed integer part of a fixed point "Dimension" and the
>  > lower 16 bits for the fractional part.  But the connection to the
>  > real world is that the low-order 16 bits measure 1/65536th of a
>  > point, each point being 72.27 per inch.  Had these bits measured
>  > 1/10000th of a point, Knuth would have avoided some input/output
>  > round-off problems, and would have increased the dynamic range of a
>  > Dimension by a factor of 6 or so, with attendant loss of precision.
>  > C'est la vie.
> 
> I don't think that Knuth would have avoided any rounding errors by
> using decimal numbers.  Computers still use the binary system
> internally.  Rounding errors occur when you convert binary numbers to
> decimal and vice versa.  Of course, this is quite confusing to humans.
> But keep in mind that even the decimal number 0.1 cannot be
> represented in the binary system with a finite amount of binary
> digits.

Well, you just do the rounding for humans usually.
What exactly are those numerator, denominator, and magnification
in the dvi preamble supposed to do? 
I was going to suggest rationals with scaled page size left to the
final display device to turn into actual dimensions but most typoggraphical
professionals don't like scaling AFAICT. Rationals are nice because they
are exact and it is also easy to print fractions.  With 32bit
numerator and denominator I think it gives you good resolution and
dynamic range compared to just a 64 bit range with fixed 1 bit steps
although maybe someone has looked into it more. This also
can let you maybe defer divisions a little and since 64 bit support
is common now there is little effort in multiplying 32 bit numbers. 

> 
> Given that Knuth did not consider printing on toilet paper, his
> decision was quite reasonable.  He used floating point numbers at the
> beginning but switched to fixed point integer numbers when he noticed
> that he got different results on different machines.
> 
> Sure, more than 32 bit for dimensions would be quite nice in some
> special cases but after all, he wrote TeX in order to write his own
> books in the first place.  Much more annoying is the limited range in
> Metapost because you often have to do extensive calculations in order
> to determine dimensions, hence intermediate results are likely to
> cause an overfow.
> 
>  > On today's 64-bit machines, one (ahem!) might configure a
>  > TeX-language interpreter at compile time to use [48:16] fixed-point
>  > arithmetic, which would allow a single page to be about 30 million
>  > miles long.  Sadly, that unrolled scroll would make it only about
>  > 20% of the way to Mars.
> 
> This doesn't make much sense either because PDF (at least 1.4) has similar
> limitations.  Only a homemade DVI driver could extend the range, but
> it could also scale the page so that the range of TeX's dimensions can
> be left as it is.
> 
> BTW, there is a nice TUGboat article by Nelson Beebe about different
> representations of numbers and their quirks:
> 
>   https://tug.org/TUGboat/tb28-3/tb90beebe.pdf
> 
> Regards,
>   Reinhard
> 
> --
> ------------------------------------------------------------------
> Reinhard Kotucha                            Phone: +49-511-3373112
> Marschnerstr. 25
> D-30167 Hannover                    mailto:reinhard.kotucha at web.de
> ------------------------------------------------------------------

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From doug at mathemaesthetics.com  Tue Sep 10 02:02:15 2019
From: doug at mathemaesthetics.com (Doug McKenna)
Date: Mon, 9 Sep 2019 18:02:15 -0600 (MDT)
Subject: viewing long pages, evince seems to choke on simple test file
In-Reply-To: <23926.54021.516568.735014@gargle.gargle.HOWL>
References: <DM6PR08MB6042100D151EED6E5D0A9858BEB50@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOhch7tVVn4K-F88XkBFx3Cwrk4k-imu4J_=sSxVqh5wxw@mail.gmail.com>
 <DM6PR08MB6042345C972F01872A365677BEB40@DM6PR08MB6042.namprd08.prod.outlook.com>
 <DM6PR08MB604224F7E495C832CD27EB5ABEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
 <CAEW6iOiqJ8=9io6Z3krqUo+juEOhdcZrdO0pSV8kOheq7rqrTg@mail.gmail.com>
 <DM6PR08MB60429EE06D4402FDC9C46AF6BEB70@DM6PR08MB6042.namprd08.prod.outlook.com>
 <1214146819.8849269.1568051165047.JavaMail.zimbra@mathemaesthetics.com>
 <23926.54021.516568.735014@gargle.gargle.HOWL>
Message-ID: <887228244.9017407.1568073735723.JavaMail.zimbra@mathemaesthetics.com>

Rienhard wrote:

>| ...
>| Rounding errors occur when you convert binary
>| numbers to decimal and vice versa.
>| ...


Yes, that's what I meant, and what I think DEK meant when he said something similar to this effect.

Doug McKenna
Mathemaesthetics, Inc.



----- Original Message -----
From: "reinhard kotucha" <reinhard.kotucha at web.de>
To: "doug" <doug at mathemaesthetics.com>
Cc: "Mike Marchywka" <marchywka at hotmail.com>, "texhax" <texhax at tug.org>
Sent: Monday, September 9, 2019 4:32:37 PM
Subject: Re: viewing long pages, evince seems to choke on simple test file

On 2019-09-09 at 11:46:05 -0600, Doug McKenna wrote:

 > Mike Marchywka wrote:
 >
 > >| Was there some reason known for this
 > >| or as the other response suggested this
 > >| was back in the day of 32 or 16 bit integers?
 >
 > TeX uses 32-bits as the word size of integers, with the upper 16
 > bits the signed integer part of a fixed point "Dimension" and the
 > lower 16 bits for the fractional part.  But the connection to the
 > real world is that the low-order 16 bits measure 1/65536th of a
 > point, each point being 72.27 per inch.  Had these bits measured
 > 1/10000th of a point, Knuth would have avoided some input/output
 > round-off problems, and would have increased the dynamic range of a
 > Dimension by a factor of 6 or so, with attendant loss of precision.
 > C'est la vie.

I don't think that Knuth would have avoided any rounding errors by
using decimal numbers.  Computers still use the binary system
internally.  Rounding errors occur when you convert binary numbers to
decimal and vice versa.  Of course, this is quite confusing to humans.
But keep in mind that even the decimal number 0.1 cannot be
represented in the binary system with a finite amount of binary
digits.

Given that Knuth did not consider printing on toilet paper, his
decision was quite reasonable.  He used floating point numbers at the
beginning but switched to fixed point integer numbers when he noticed
that he got different results on different machines.

Sure, more than 32 bit for dimensions would be quite nice in some
special cases but after all, he wrote TeX in order to write his own
books in the first place.  Much more annoying is the limited range in
Metapost because you often have to do extensive calculations in order
to determine dimensions, hence intermediate results are likely to
cause an overfow.

 > On today's 64-bit machines, one (ahem!) might configure a
 > TeX-language interpreter at compile time to use [48:16] fixed-point
 > arithmetic, which would allow a single page to be about 30 million
 > miles long.  Sadly, that unrolled scroll would make it only about
 > 20% of the way to Mars.

This doesn't make much sense either because PDF (at least 1.4) has similar
limitations.  Only a homemade DVI driver could extend the range, but
it could also scale the page so that the range of TeX's dimensions can
be left as it is.

BTW, there is a nice TUGboat article by Nelson Beebe about different
representations of numbers and their quirks:

  https://tug.org/TUGboat/tb28-3/tb90beebe.pdf

Regards,
  Reinhard

--
------------------------------------------------------------------
Reinhard Kotucha                            Phone: +49-511-3373112
Marschnerstr. 25
D-30167 Hannover                    mailto:reinhard.kotucha at web.de
------------------------------------------------------------------

From P.Varaprasad at spi-global.com  Tue Sep 10 15:20:59 2019
From: P.Varaprasad at spi-global.com (Varaprasad, PrakashRao)
Date: Tue, 10 Sep 2019 13:20:59 +0000
Subject: WordTeX LaTeX features
In-Reply-To: <SG2PR03MB281453F2CAE55FE2AD9DB587B6BD0@SG2PR03MB2814.apcprd03.prod.outlook.com>
References: <SG2PR03MB281453F2CAE55FE2AD9DB587B6BD0@SG2PR03MB2814.apcprd03.prod.outlook.com>
Message-ID: <SG2PR03MB2814B5351E27A09CDC49D8A5B6B60@SG2PR03MB2814.apcprd03.prod.outlook.com>

Hi All,

Can anybody suggest for the below.

Thanks
Prasad

From: texhax [mailto:texhax-bounces+p.varaprasad=spi-global.com at tug.org] On Behalf Of Varaprasad, PrakashRao
Sent: Friday, August 30, 2019 8:29 PM
To: texhax at tug.org
Subject: WordTeX LaTeX features

Hi All,

Can anybody suggest wordtex features. We are testing as per the attached document provided, but while copying the latex code into word in this feature some of the latex features are missing.

Thanks
Prasad

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190910/69f7de7d/attachment.html>

From ziegenhagen at gmail.com  Tue Sep 10 20:26:00 2019
From: ziegenhagen at gmail.com (Uwe Ziegenhagen)
Date: Tue, 10 Sep 2019 20:26:00 +0200
Subject: WordTeX LaTeX features
In-Reply-To: <SG2PR03MB2814B5351E27A09CDC49D8A5B6B60@SG2PR03MB2814.apcprd03.prod.outlook.com>
References: <SG2PR03MB281453F2CAE55FE2AD9DB587B6BD0@SG2PR03MB2814.apcprd03.prod.outlook.com>
 <SG2PR03MB2814B5351E27A09CDC49D8A5B6B60@SG2PR03MB2814.apcprd03.prod.outlook.com>
Message-ID: <CAML7JCj38EvP6vdYixt46XTNXf2yEU6=gsZ_-GbGR+=bwBgFbw@mail.gmail.com>

Hi PrakashRao,

you have asked on a TeX-Mailinglist for Features to make MS Word look like
LaTeX. With LaTeX we get the same look but do not have to use Word. So
while there may be scenarios where it can be useful, it is unlikely that
you get much feedback on this list. Why don't you ask on a Word mailinglist?

Uwe

Am Di., 10. Sept. 2019 um 15:22 Uhr schrieb Varaprasad, PrakashRao <
P.Varaprasad at spi-global.com>:

> Hi All,
>
>
>
> Can anybody suggest for the below.
>
>
>
> Thanks
>
> Prasad
>
>
>
> *From:* texhax [mailto:texhax-bounces+p.varaprasad=spi-global.com at tug.org]
> *On Behalf Of *Varaprasad, PrakashRao
> *Sent:* Friday, August 30, 2019 8:29 PM
> *To:* texhax at tug.org
> *Subject:* WordTeX LaTeX features
>
>
>
> Hi All,
>
>
>
> Can anybody suggest wordtex features. We are testing as per the attached
> document provided, but while copying the latex code into word in this
> feature some of the latex features are missing.
>
>
>
> Thanks
>
> Prasad
>
>
>


-- 
Dr. Uwe Ziegenhagen
0179-7476050
<http://www.uweziegenhagen.de>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190910/65705d42/attachment.html>

From dirk.hunniger at googlemail.com  Tue Sep 10 20:32:23 2019
From: dirk.hunniger at googlemail.com (=?UTF-8?Q?Dirk_H=c3=bcnniger?=)
Date: Tue, 10 Sep 2019 20:32:23 +0200
Subject: WordTeX LaTeX features
In-Reply-To: <SG2PR03MB2814B5351E27A09CDC49D8A5B6B60@SG2PR03MB2814.apcprd03.prod.outlook.com>
References: <SG2PR03MB281453F2CAE55FE2AD9DB587B6BD0@SG2PR03MB2814.apcprd03.prod.outlook.com>
 <SG2PR03MB2814B5351E27A09CDC49D8A5B6B60@SG2PR03MB2814.apcprd03.prod.outlook.com>
Message-ID: <3372118e-74d5-7317-ae2f-23508d4187c2@googlemail.com>

Hi,

I am not sure if I got the question right. But it is possible to convert 
latex files to text processor formats using pandoc.

Still there are huge differences between the way LaTeX and a graphical 
text editor, so such a conversion can always only work to a very limited 
extend.

Yours Dirk

On 9/10/19 3:20 PM, Varaprasad, PrakashRao wrote:
>
> Hi All,
>
> Can anybody suggest for the below.
>
> Thanks
>
> Prasad
>
> *From:*texhax 
> [mailto:texhax-bounces+p.varaprasad=spi-global.com at tug.org] *On Behalf 
> Of *Varaprasad, PrakashRao
> *Sent:* Friday, August 30, 2019 8:29 PM
> *To:* texhax at tug.org
> *Subject:* WordTeX LaTeX features
>
> Hi All,
>
> Can anybody suggest wordtex features. We are testing as per the 
> attached document provided, but while copying the latex code into word 
> in this feature some of the latex features are missing.
>
> Thanks
>
> Prasad
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190910/00f276cc/attachment.html>

From alan at alphabyte.co.nz  Tue Sep 10 23:34:27 2019
From: alan at alphabyte.co.nz (Alan Litchfield)
Date: Wed, 11 Sep 2019 09:34:27 +1200
Subject: WordTeX LaTeX features
In-Reply-To: <SG2PR03MB2814B5351E27A09CDC49D8A5B6B60@SG2PR03MB2814.apcprd03.prod.outlook.com>
References: <SG2PR03MB281453F2CAE55FE2AD9DB587B6BD0@SG2PR03MB2814.apcprd03.prod.outlook.com>
 <SG2PR03MB2814B5351E27A09CDC49D8A5B6B60@SG2PR03MB2814.apcprd03.prod.outlook.com>
Message-ID: <12927FD9-F1F2-4635-9569-F6F256D9C973@alphabyte.co.nz>

Looked at the doc when it first came out. It is what we call in this country `taking the pxxx?, or a weak attempt at satire.

I assume this follow up message is an attempt at trolling.

Alan
--
Dr Alan Litchfield
AlphaByte
PO Box 1941
Auckland, New Zealand 1140

> On 11/09/2019, at 01:20, Varaprasad, PrakashRao <P.Varaprasad at spi-global.com> wrote:
> 
> Hi All,
>  
> Can anybody suggest for the below.
>  
> Thanks
> Prasad
> ? <>
> From: texhax [mailto:texhax-bounces+p.varaprasad=spi-global.com at tug.org <mailto:texhax-bounces+p.varaprasad=spi-global.com at tug.org>] On Behalf Of Varaprasad, PrakashRao
> Sent: Friday, August 30, 2019 8:29 PM
> To: texhax at tug.org <mailto:texhax at tug.org>
> Subject: WordTeX LaTeX features
>  
> Hi All,
>  
> Can anybody suggest wordtex features. We are testing as per the attached document provided, but while copying the latex code into word in this feature some of the latex features are missing.
>  
> Thanks
> Prasad

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190911/5ce57025/attachment-0001.html>

From didier at didierverna.net  Thu Sep 12 10:03:36 2019
From: didier at didierverna.net (Didier Verna)
Date: Thu, 12 Sep 2019 10:03:36 +0200
Subject: [Q] TFM files headers
Message-ID: <m28squeyav.fsf@didierverna.net>


  Hello,

I found information on the structure of Xerox PARC headers in .tfm
files. It seems, however, that other kinds of headers exist (for
instance, Adobe fonts such as pagk8y.tfm, as found in TeX Live).

Does anyone know where I can find information about the headers I may
encounter, their structure, and how to distinguish them?

Thanks!

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From peter at silmaril.ie  Thu Sep 12 23:33:33 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Thu, 12 Sep 2019 22:33:33 +0100
Subject: [Q] TFM files headers
In-Reply-To: <m28squeyav.fsf@didierverna.net>
References: <m28squeyav.fsf@didierverna.net>
Message-ID: <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>

On 12/09/2019 09:03, Didier Verna wrote:
> 
>    Hello,
> 
> I found information on the structure of Xerox PARC headers in .tfm
> files. It seems, however, that other kinds of headers exist (for
> instance, Adobe fonts such as pagk8y.tfm, as found in TeX Live).
> 
> Does anyone know where I can find information about the headers I may
> encounter, their structure, and how to distinguish them?

I think details of the file formats is in Knuth's TeX - The Program, but 
if I am wrong I am sure someone has the correct information.

Peter

From rokicki at gmail.com  Thu Sep 12 23:36:10 2019
From: rokicki at gmail.com (Tomas Rokicki)
Date: Thu, 12 Sep 2019 14:36:10 -0700
Subject: [Q] TFM files headers
In-Reply-To: <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
Message-ID: <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>

A google search immediately returns

   https://en.wikipedia.org/wiki/TeX_font_metric

which has the appropriate reference to tftopl as well
as being a pretty easy read itself.

-tom

On Thu, Sep 12, 2019 at 2:33 PM Peter Flynn <peter at silmaril.ie> wrote:

> On 12/09/2019 09:03, Didier Verna wrote:
> >
> >    Hello,
> >
> > I found information on the structure of Xerox PARC headers in .tfm
> > files. It seems, however, that other kinds of headers exist (for
> > instance, Adobe fonts such as pagk8y.tfm, as found in TeX Live).
> >
> > Does anyone know where I can find information about the headers I may
> > encounter, their structure, and how to distinguish them?
>
> I think details of the file formats is in Knuth's TeX - The Program, but
> if I am wrong I am sure someone has the correct information.
>
> Peter
>


-- 
--  http://cube20.org/  --  http://golly.sf.net/  --
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190912/a38be333/attachment.html>

From P.Taylor at rhul.ac.uk  Fri Sep 13 10:15:32 2019
From: P.Taylor at rhul.ac.uk (Taylor, P)
Date: Fri, 13 Sep 2019 08:15:32 +0000
Subject: [Q] TFM files headers
In-Reply-To: <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
Message-ID: <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>

Tomas Rokicki wrote:

A google search immediately returns

   https://en.wikipedia.org/wiki/TeX_font_metric

which has the appropriate reference to tftopl as well as being a pretty easy read itself.

Thank you Tom.  I followed the link and found therein a further link<http://www.tug.org/TUGboat/Articles/tb02-1/tb02fuchstfm.pdf> to a TUGboat article by David Fuchs entitlted What happens when you say "\font A=CMR10"  (note: no slash before "A").  Do you have any idea of which iteration of TeX David was writing, since TeX82 would require "\font \A=CMR10" whilst TeX78 would have required (as David himself notes) "\:A=CMR10".  BNB cc'd as she may know the answer.

Philip Taylor
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190913/e24924d3/attachment.html>

From didier at didierverna.net  Fri Sep 13 11:17:45 2019
From: didier at didierverna.net (Didier Verna)
Date: Fri, 13 Sep 2019 11:17:45 +0200
Subject: [Q] TFM files headers
In-Reply-To: <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk> (P. Taylor's
 message of "Fri, 13 Sep 2019 08:15:32 +0000")
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
Message-ID: <m236h0eerq.fsf@didierverna.net>


Peter Flynn wrote:

> I think details of the file formats is in Knuth's TeX - The Program,
> but if I am wrong I am sure someone has the correct information.

Tomas Rokicki wrote:

> https://en.wikipedia.org/wiki/TeX_font_metric
>
> which has the appropriate reference to tftopl as well as being a
> pretty easy read itself.

Taylor, P wrote:

> I followed the link and found therein a further link to a TUGboat
> article by David Fuchs


  I know all these sources of information. Unfortunately, they don't
  help. They only provide a description of the Xerox PARC header, but
  there's no guarantee that a tfm file will actually use it. For
  example, I found at least one tfm file (from Adobe apparently) that
  seems to also seems to contain a couple of information strings[1], but
  contrary to a PARC header, the strings are not padded with 0s.


Footnotes: 
[1]  I figured that out by reverse-engineering the tfm file.

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From didier at didierverna.net  Fri Sep 13 12:30:37 2019
From: didier at didierverna.net (Didier Verna)
Date: Fri, 13 Sep 2019 12:30:37 +0200
Subject: [Q] TFM files headers
In-Reply-To: <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk> (P. Taylor's
 message of "Fri, 13 Sep 2019 09:52:43 +0000")
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
Message-ID: <m2r24kcwtu.fsf@didierverna.net>

"Taylor, P" <P.Taylor at rhul.ac.uk> wrote:

> Didier Verna wrote:
>
>>    I found at least one tfm file (from Adobe apparently) that seems
>>    to also seems to contain a couple of information strings[1], but
>>    contrary to a PARC header, the strings are not padded with 0s.
>
> Can you post the file, or a link to the file, please ?? If it was not
> generated using MetaFont or PLtoTF, it may not be compliant. Philip
> Taylor

  The file is pagd8y.tfm. It is attached below but it is also available
  in the TeX Live distribution (texmf-dist/fonts/tfm/adobe/ly1/).

  After the two standard header words (checksum / design size), there
  seems to be a PARC-like character coding scheme string of 31 bytes
  ("TeX typewriter and Windows ANSI"), properly advertised with its
  length in the first byte position, but this string isn't padded with
  0s until the 40th byte. Instead, it seems to be immediately followed
  by two other strings ("Y&Y Inc." and "AvantGarDem").

  AFAICT, this file could still be compliant with the TFM format. I
  think this format only mandates the two first header words, and an
  indication of the header's total length. But other than that, I think
  people are free to put whatever they want in the rest of the header.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pagd8y.tfm
Type: application/octet-stream
Size: 5104 bytes
Desc: not available
URL: <https://tug.org/pipermail/texhax/attachments/20190913/b9dccf78/attachment.obj>
-------------- next part --------------


PS: I'm currently testing the robustness of a TFM parser of mine on the
64323 tfm files in the TeX Live 2019 distribution, and there are *lots*
of non compliant (for real) files in there... in particular, many of
them have the wrong length, or min code > max code.

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info

From P.Taylor at rhul.ac.uk  Fri Sep 13 13:05:18 2019
From: P.Taylor at rhul.ac.uk (Taylor, P)
Date: Fri, 13 Sep 2019 11:05:18 +0000
Subject: [Q] TFM files headers
In-Reply-To: <m2r24kcwtu.fsf@didierverna.net>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
Message-ID: <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>

Didier Verna wrote:

>
> PS: I'm currently testing the robustness of a TFM parser of mine on the
> 64323 tfm files in the TeX Live 2019 distribution, and there are *lots*
> of non compliant (for real) files in there... in particular, many of
> them have the wrong length, or min code > max code.
>

What (if anything) does TFtoPL have to say about the files that your 
parser identifies as being non-compliant ?
Philip Taylor


From didier at didierverna.net  Fri Sep 13 13:13:38 2019
From: didier at didierverna.net (Didier Verna)
Date: Fri, 13 Sep 2019 13:13:38 +0200
Subject: [Q] TFM files headers
In-Reply-To: <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk> (P. Taylor's
 message of "Fri, 13 Sep 2019 11:05:18 +0000")
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
Message-ID: <m2impwcuu5.fsf@didierverna.net>

"Taylor, P" <P.Taylor at rhul.ac.uk> wrote:

> What (if anything) does TFtoPL have to say about the files that your
> parser identifies as being non-compliant ? Philip Taylor

  It agrees with me :-D

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From rokicki at gmail.com  Fri Sep 13 18:04:40 2019
From: rokicki at gmail.com (Tomas Rokicki)
Date: Fri, 13 Sep 2019 09:04:40 -0700
Subject: [Q] TFM files headers
In-Reply-To: <m2impwcuu5.fsf@didierverna.net>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
Message-ID: <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>

I also noticed the tfm files with the wrong length (extra stuff on the end).
While this is moderately unfortunate it's also not critical since all the
TFM parsers appear to read the TFM files front to back and just ignore
the junk.

I confirm (with my own TFM parser) that there are 2060 "tfm" files in the
distribution with bc > ec.  They are in the following directories (with
counts
of the "bad" files).  These files may also have other issues (like bad
header lengths).  My suspicion is nobody has ever (successfully) used
any of these fonts.  A cursory test appears to show that TeX cannot load
these fonts either.

  24 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/standard

  12 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/nmin-ngoth

   8 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/jis

   4 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/dvips

1080 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/japanese-otf

 522 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/japanese-otf-uptex

  40 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/jlreq

   1 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/amsfonts/dummy

  24 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/zhmetrics-uptex

 260 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/pxufont

  12 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/hfoldsty

  25 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/morisawa

  40 /usr/local/texlive/2019/texmf-dist/fonts/tfm/uptex-fonts/jis

   8 /usr/local/texlive/2019/texmf-dist/fonts/tfm/uptex-fonts/min

On Fri, Sep 13, 2019 at 4:13 AM Didier Verna <didier at didierverna.net> wrote:

> "Taylor, P" <P.Taylor at rhul.ac.uk> wrote:
>
> > What (if anything) does TFtoPL have to say about the files that your
> > parser identifies as being non-compliant ? Philip Taylor
>
>   It agrees with me :-D
>
> --
> Resistance is futile. You will be jazzimilated.
>
> Lisp, Jazz, A?kido: http://www.didierverna.info
>
>

-- 
--  http://cube20.org/  --  http://golly.sf.net/  --
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190913/dff94585/attachment-0001.html>

From rokicki at gmail.com  Fri Sep 13 18:19:20 2019
From: rokicki at gmail.com (Tomas Rokicki)
Date: Fri, 13 Sep 2019 09:19:20 -0700
Subject: [Q] TFM files headers
In-Reply-To: <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
Message-ID: <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>

Oh, dang, looks like the TFM file format does not require bc <= ec.
The amsfonts/dummy example is loaded by TeX and also accepted
by tftopl.  It does require however that bc <= ec+1 and that ec<256.

The tftopl check reads as follows:

if (bc>ec+1)or(ec>255) then abort('The character code range ',

In TeX we see:

if (bc>ec+1)or(ec>255) then abort;
if bc>255 then {|bc=256| and |ec=255|}
  begin bc:=1; ec:=0;
  end;

That second part is interesting and unexpected; I believe it's there just so
a tfm file that is empty but using bc=256/ec=255 to indicate that, can still
work in an environment where bc and ec are stored in 8-bit bytes.

TeX also explicitly ignores extra stuff at the end:

@ We check to see that the \.{TFM} file doesn't end prematurely; but
no error message is given for files having more than |lf| words.


-tom


On Fri, Sep 13, 2019 at 9:04 AM Tomas Rokicki <rokicki at gmail.com> wrote:

> I also noticed the tfm files with the wrong length (extra stuff on the
> end).
> While this is moderately unfortunate it's also not critical since all the
> TFM parsers appear to read the TFM files front to back and just ignore
> the junk.
>
> I confirm (with my own TFM parser) that there are 2060 "tfm" files in the
> distribution with bc > ec.  They are in the following directories (with
> counts
> of the "bad" files).  These files may also have other issues (like bad
> header lengths).  My suspicion is nobody has ever (successfully) used
> any of these fonts.  A cursory test appears to show that TeX cannot load
> these fonts either.
>
>   24 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/standard
>
>   12 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/nmin-ngoth
>
>    8 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/jis
>
>    4 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/dvips
>
> 1080 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/japanese-otf
>
>  522
> /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/japanese-otf-uptex
>
>   40 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/jlreq
>
>    1 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/amsfonts/dummy
>
>   24 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/zhmetrics-uptex
>
>  260 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/pxufont
>
>   12 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/hfoldsty
>
>   25 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/morisawa
>
>   40 /usr/local/texlive/2019/texmf-dist/fonts/tfm/uptex-fonts/jis
>
>    8 /usr/local/texlive/2019/texmf-dist/fonts/tfm/uptex-fonts/min
>
> On Fri, Sep 13, 2019 at 4:13 AM Didier Verna <didier at didierverna.net>
> wrote:
>
>> "Taylor, P" <P.Taylor at rhul.ac.uk> wrote:
>>
>> > What (if anything) does TFtoPL have to say about the files that your
>> > parser identifies as being non-compliant ? Philip Taylor
>>
>>   It agrees with me :-D
>>
>> --
>> Resistance is futile. You will be jazzimilated.
>>
>> Lisp, Jazz, A?kido: http://www.didierverna.info
>>
>>
>
> --
> --  http://cube20.org/  --  http://golly.sf.net/  --
>


-- 
--  http://cube20.org/  --  http://golly.sf.net/  --
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190913/2f168838/attachment.html>

From h.y.acetaminophen at gmail.com  Fri Sep 13 19:01:33 2019
From: h.y.acetaminophen at gmail.com (Hironobu Yamashita)
Date: Sat, 14 Sep 2019 02:01:33 +0900
Subject: [Q] TFM files headers
In-Reply-To: <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
 <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
Message-ID: <CAJCZBmTDaw0eGwXZEJwMkdUwbhsSmMYmc-F8pA1HjeYaC8KRHA@mail.gmail.com>

Hi Tom,

Some of TFM files you've listed are JFM (Japanese pTeX font metric),
though they have .tfm not .jfm.
All of the below are in JFM format.
We Japanese use those files on a daily basis ;-)

>>   24 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/standard
>>   12 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/nmin-ngoth
>>    8 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/jis
>>    4 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/dvips
>> 1080 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/japanese-otf
>>  522 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/japanese-otf-uptex
>>   40 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/jlreq

>>   24 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/zhmetrics-uptex
>>  260 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/pxufont

>>   25 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/morisawa
>>   40 /usr/local/texlive/2019/texmf-dist/fonts/tfm/uptex-fonts/jis
>>    8 /usr/local/texlive/2019/texmf-dist/fonts/tfm/uptex-fonts/min

You can check whether a .tfm is an ordinary TFM or pTeX JFM by

$ chkdvifont /path/to/something.tfm

Best,
Hironobu

From rokicki at gmail.com  Fri Sep 13 19:06:55 2019
From: rokicki at gmail.com (Tomas Rokicki)
Date: Fri, 13 Sep 2019 10:06:55 -0700
Subject: [Q] TFM files headers
In-Reply-To: <CAJCZBmTDaw0eGwXZEJwMkdUwbhsSmMYmc-F8pA1HjeYaC8KRHA@mail.gmail.com>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
 <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
 <CAJCZBmTDaw0eGwXZEJwMkdUwbhsSmMYmc-F8pA1HjeYaC8KRHA@mail.gmail.com>
Message-ID: <CAGia-=UDAAZ-4jRYWXdWSyiexLOBbCjOHzwUnvETm2RV3MfK_Q@mail.gmail.com>

Thanks!  That explains things then.  Very nice.

On Fri, Sep 13, 2019 at 10:01 AM Hironobu Yamashita <
h.y.acetaminophen at gmail.com> wrote:

> Hi Tom,
>
> Some of TFM files you've listed are JFM (Japanese pTeX font metric),
> though they have .tfm not .jfm.
> All of the below are in JFM format.
> We Japanese use those files on a daily basis ;-)
>
> >>   24 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/standard
> >>   12 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/nmin-ngoth
> >>    8 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/jis
> >>    4 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/dvips
> >> 1080 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/japanese-otf
> >>  522
> /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/japanese-otf-uptex
> >>   40 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/jlreq
>
> >>   24 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/zhmetrics-uptex
> >>  260 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/pxufont
>
> >>   25 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/morisawa
> >>   40 /usr/local/texlive/2019/texmf-dist/fonts/tfm/uptex-fonts/jis
> >>    8 /usr/local/texlive/2019/texmf-dist/fonts/tfm/uptex-fonts/min
>
> You can check whether a .tfm is an ordinary TFM or pTeX JFM by
>
> $ chkdvifont /path/to/something.tfm
>
> Best,
> Hironobu
>


-- 
--  http://cube20.org/  --  http://golly.sf.net/  --
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190913/82c95580/attachment-0001.html>

From doug at mathemaesthetics.com  Fri Sep 13 19:14:38 2019
From: doug at mathemaesthetics.com (Doug McKenna)
Date: Fri, 13 Sep 2019 11:14:38 -0600 (MDT)
Subject: [Q] TFM files headers
In-Reply-To: <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
References: <m28squeyav.fsf@didierverna.net> <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
 <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
Message-ID: <1255282251.307211.1568394878058.JavaMail.zimbra@mathemaesthetics.com>

Here's my take: 

If there are extra 32-bit words past the end of the standard TFM data in the header, there is documentation for a Xerox PARC bunch of info, which starts out with two BCPL identification strings stored in a 40-byte and then a 20-byte slot, respectively. 

A BCPL string starts with a length byte for the remaining bytes in the string. Everything after that number of bytes in each field should be ignored, and therefore can be garbage or nulls. There is no requirement that it be null padding that I recall (or that any TFM parsing code should care about). From the point of view of data integrity, though, within the string a null byte is technically legal, but not a particularly good idea. Also, both 40 and 20 are artificially low values, so a bad length byte could be out of range. Regardless, a null in the legal part of the string will cause problems for any parser that might try to record it as a C string. 

But all of that is only a problem if one is assuming the extra data past what TFM cares about is in that Xerox-added format. There's no way I can discern to tell different private extended formats apart. I don't know about any other documented formats in this extra space, but that doesn't mean there aren't any. 

Doug McKenna 



From: "Tom Rokicki" <rokicki at gmail.com> 
To: "Didier Verna" <didier at didierverna.net> 
Cc: "texhax" <texhax at tug.org> 
Sent: Friday, September 13, 2019 10:19:20 AM 
Subject: Re: [Q] TFM files headers 

Oh, dang, looks like the TFM file format does not require bc <= ec. 
The amsfonts/dummy example is loaded by TeX and also accepted 
by tftopl. It does require however that bc <= ec+1 and that ec<256. 

The tftopl check reads as follows: 
if (bc>ec+1)or(ec>255) then abort('The character code range ', 
In TeX we see: 
if (bc>ec+1)or(ec>255) then abort;
if bc>255 then {|bc=256| and |ec=255|}
  begin bc:=1; ec:=0;
  end; 
That second part is interesting and unexpected; I believe it's there just so 
a tfm file that is empty but using bc=256/ec=255 to indicate that, can still 
work in an environment where bc and ec are stored in 8-bit bytes. 

TeX also explicitly ignores extra stuff at the end: 
@ We check to see that the \.{TFM} file doesn't end prematurely; but
no error message is given for files having more than |lf| words. 

-tom 

On Fri, Sep 13, 2019 at 9:04 AM Tomas Rokicki < [ mailto:rokicki at gmail.com | rokicki at gmail.com ] > wrote: 



I also noticed the tfm files with the wrong length (extra stuff on the end). 
While this is moderately unfortunate it's also not critical since all the 
TFM parsers appear to read the TFM files front to back and just ignore 
the junk. 

I confirm (with my own TFM parser) that there are 2060 "tfm" files in the 
distribution with bc > ec. They are in the following directories (with counts 
of the "bad" files). These files may also have other issues (like bad 
header lengths). My suspicion is nobody has ever (successfully) used 
any of these fonts. A cursory test appears to show that TeX cannot load 
these fonts either. 



24 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/standard 

12 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/nmin-ngoth 

8 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/jis 

4 /usr/local/texlive/2019/texmf-dist/fonts/tfm/ptex-fonts/dvips 

1080 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/japanese-otf 

522 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/japanese-otf-uptex 

40 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/jlreq 

1 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/amsfonts/dummy 

24 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/zhmetrics-uptex 

260 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/pxufont 

12 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/hfoldsty 

25 /usr/local/texlive/2019/texmf-dist/fonts/tfm/public/morisawa 

40 /usr/local/texlive/2019/texmf-dist/fonts/tfm/uptex-fonts/jis 

8 /usr/local/texlive/2019/texmf-dist/fonts/tfm/uptex-fonts/min 

On Fri, Sep 13, 2019 at 4:13 AM Didier Verna < [ mailto:didier at didierverna.net | didier at didierverna.net ] > wrote: 

BQ_BEGIN
"Taylor, P" < [ mailto:P.Taylor at rhul.ac.uk | P.Taylor at rhul.ac.uk ] > wrote: 

> What (if anything) does TFtoPL have to say about the files that your 
> parser identifies as being non-compliant ? Philip Taylor 

It agrees with me :-D 

-- 
Resistance is futile. You will be jazzimilated. 

Lisp, Jazz, A?kido: [ http://www.didierverna.info/ | http://www.didierverna.info ] 






-- 
-- [ http://cube20.org/ | http://cube20.org/ ] -- [ http://golly.sf.net/ | http://golly.sf.net/ ] -- 

BQ_END



-- 
-- [ http://cube20.org/ | http://cube20.org/ ] -- [ http://golly.sf.net/ | http://golly.sf.net/ ] -- 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190913/5151729b/attachment.html>

From bnb at tug.org  Fri Sep 13 19:20:59 2019
From: bnb at tug.org (barbara beeton)
Date: Fri, 13 Sep 2019 19:20:59 +0200 (CEST)
Subject: [Q] TFM files headers
In-Reply-To: <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
Message-ID: <alpine.LRH.2.21.1909131906490.1029@tug.org>

On Fri, 13 Sep 2019, Taylor, P wrote:

> Tomas Rokicki wrote:
>
>       A google search immediately returns
> ? ?https://en.wikipedia.org/wiki/TeX_font_metric
> 
> which has the appropriate reference to tftopl as well as being a
> pretty easy read itself.
> 
> 
> Thank you Tom.? I followed the link and found therein a further link to a
> TUGboat article by David Fuchs entitlted What happens when you say "\font
> A=CMR10"? (note: no slash before "A").? Do you have any idea of which
> iteration of TeX David was writing, since TeX82 would require "\font
> \A=CMR10" whilst TeX78 would have required (as David himself notes)
> "\:A=CMR10".? BNB cc'd as she may know the answer.
> 
> Philip Taylor

(I actually read texhax, so a separate cc isn't necessary.
But anyhow, ...)

The article by David Fuchs is from TUGboat volume 2 (1981),
so TeX was in flux.  In fact, in the first paragraph, there
is this sentence:

   For instance, when you say \font A=CMR10 to TeX (\:A=CMR10
   in the old lingo), ...

so that should settle that question.

I poked around a bit more.  Seeing .../amsfonts/dummy in the
list from Didier, I took a look at that, and it identifies
itself as a null font, for the purpose of syntax checking.
I would expect, therefore, that it is highly nonstandard.

(Almost?) all the other fonts in Didier's list appear to be
Japanese, for use with ptex or similar.  There may be some
other requirements they must meet that I'm not familiar with,
but certainly ptex is rather different in some respects from
the more familiar "western" flavors; details unknown to me.

That's the best I can do.
 						-- bb

From didier at didierverna.net  Fri Sep 13 19:49:36 2019
From: didier at didierverna.net (Didier Verna)
Date: Fri, 13 Sep 2019 19:49:36 +0200
Subject: [Q] TFM files headers
In-Reply-To: <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
 (Tomas Rokicki's message of "Fri, 13 Sep 2019 09:19:20 -0700")
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
 <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
Message-ID: <m2a7b8cci7.fsf@didierverna.net>

Tomas Rokicki <rokicki at gmail.com> wrote:

> Oh, dang, looks like the TFM file format does not require bc <= ec.

The exact rule is bc - 1 <= ec <= 255, with bc = 1 && ec = 0 indicating
0 characters (according to TeX: the Program [539]). As you mention
below, the "bizarre"  bc > 255 thing is indeed not documented in
English, but appears in the code [565].

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From didier at didierverna.net  Fri Sep 13 20:16:44 2019
From: didier at didierverna.net (Didier Verna)
Date: Fri, 13 Sep 2019 20:16:44 +0200
Subject: [Q] TFM files headers
In-Reply-To: <1255282251.307211.1568394878058.JavaMail.zimbra@mathemaesthetics.com>
 (Doug McKenna's message of "Fri, 13 Sep 2019 11:14:38 -0600 (MDT)")
References: <m28squeyav.fsf@didierverna.net> <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
 <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
 <1255282251.307211.1568394878058.JavaMail.zimbra@mathemaesthetics.com>
Message-ID: <m25zlwcb8z.fsf@didierverna.net>

Doug McKenna <doug at mathemaesthetics.com> wrote:

> A BCPL string starts with a length byte for the remaining bytes in the
> string. Everything after that number of bytes in each field should be
> ignored, and therefore can be garbage or nulls. There is no
> requirement that it be null padding that I recall

  David Fuchs'paper in TUGBoat Vol.2 n.1 says otherwise. That's why I
  implemented the check in my parser. But maybe this paper is too old.

  In fact, going back to my initial example (pagd8y.tfm), I know realize
  that if you just ignore the garbage instead of checking that it's a
  bunch of zeros, then the header becomes PARC-compliant.

  Indeed, the character encoding scheme string, which is advertised as
  of length 31, contains:
  - 31,
  - "TeX typewriter and Windows ANSI" which indeed is 31 characters long,
  - 0,
  - "Y&Y Inc" which is 7 characters long.

  In total, we do reach 40... So it looks like someone had fun hiding
  the Y&Y stuff at the end of the string.


> Regardless, a null in the legal part of the string will cause problems
> for any parser that might try to record it as a C string.

  That's why I don't use C ;-)

> But all of that is only a problem if one is assuming the extra data
> past what TFM cares about is in that Xerox-added format. There's no
> way I can discern to tell different private extended formats apart. I
> don't know about any other documented formats in this extra space, but
> that doesn't mean there aren't any.

  Exactly.

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From didier at didierverna.net  Fri Sep 13 20:57:51 2019
From: didier at didierverna.net (Didier Verna)
Date: Fri, 13 Sep 2019 20:57:51 +0200
Subject: [Q] TFM files headers
In-Reply-To: <CAJCZBmTDaw0eGwXZEJwMkdUwbhsSmMYmc-F8pA1HjeYaC8KRHA@mail.gmail.com>
 (Hironobu Yamashita's message of "Sat, 14 Sep 2019 02:01:33 +0900")
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
 <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
 <CAJCZBmTDaw0eGwXZEJwMkdUwbhsSmMYmc-F8pA1HjeYaC8KRHA@mail.gmail.com>
Message-ID: <m21rwkc9cg.fsf@didierverna.net>

Hironobu Yamashita <h.y.acetaminophen at gmail.com> wrote:

> Some of TFM files you've listed are JFM (Japanese pTeX font metric),
> though they have .tfm not .jfm. All of the below are in JFM format. We
> Japanese use those files on a daily basis ;-)

  That could explain some things. How do you distinguish JFM from TFM
  without looking at the file extension (specifically for JFM files
  named .tfm)?

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From doug at mathemaesthetics.com  Fri Sep 13 22:09:19 2019
From: doug at mathemaesthetics.com (Doug McKenna)
Date: Fri, 13 Sep 2019 14:09:19 -0600 (MDT)
Subject: [Q] TFM files headers
In-Reply-To: <m25zlwcb8z.fsf@didierverna.net>
References: <m28squeyav.fsf@didierverna.net> <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
 <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
 <1255282251.307211.1568394878058.JavaMail.zimbra@mathemaesthetics.com>
 <m25zlwcb8z.fsf@didierverna.net>
Message-ID: <274325813.393290.1568405359311.JavaMail.zimbra@mathemaesthetics.com>

Didier wrote:

>| David Fuchs'paper in TUGBoat Vol.2 n.1 says otherwise. That's why I
>| implemented the check in my parser. But maybe this paper is too old.

Agreed, it does say so, and that article was from 1980--81 or so.  So the answer as to whether the remaining space is required to be nulls should be in the source code of pltotf.  And indeed, that's what it does, although the notes in the source code say the nullification of the remaining garbage bytes wasn't added until two years later, in April 1983 (Version 1.3).  Search the WEB source code for "tidy up the remaining bytes", which is commenting on the routine creating a BCPL string.

>| In fact, going back to my initial example (pagd8y.tfm), I know realize
>| that if you just ignore the garbage instead of checking that it's a
>| bunch of zeros, then the header becomes PARC-compliant.

>| Indeed, the character encoding scheme string, which is advertised as
>| of length 31, contains:
>| - 31,
>| - "TeX typewriter and Windows ANSI" which indeed is 31 characters long,
>| - 0,
>| - "Y&Y Inc" which is 7 characters long.

>| In total, we do reach 40... So it looks like someone had fun hiding
>| the Y&Y stuff at the end of the string.

Don't ascribe to cleverness that which can be explained by other simpler means.  It could just as easily be garbage (in readable form) that got copied in with a blockmove for 40 bytes, or some similar brute force code, using a C string as the address of the source bytes (hence that first null byte).

But interestingly, a web (the other web) search for "Y&Y Inc" matches this TeX-related page:

<https://www.tug.org/yandy/dviwindo.htm>

So perhaps this TFM file has something to do with them.


Doug McKenna

From d.p.carlisle at gmail.com  Fri Sep 13 22:19:11 2019
From: d.p.carlisle at gmail.com (David Carlisle)
Date: Fri, 13 Sep 2019 21:19:11 +0100
Subject: [Q] TFM files headers
In-Reply-To: <274325813.393290.1568405359311.JavaMail.zimbra@mathemaesthetics.com>
References: <m28squeyav.fsf@didierverna.net> <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
 <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
 <1255282251.307211.1568394878058.JavaMail.zimbra@mathemaesthetics.com>
 <m25zlwcb8z.fsf@didierverna.net>
 <274325813.393290.1568405359311.JavaMail.zimbra@mathemaesthetics.com>
Message-ID: <CAEW6iOjWVJMqP-Nf2kCPR0WWrMPrM8Cdu+yfT9bTM3EFg6Hp2w@mail.gmail.com>

On Fri, 13 Sep 2019 at 21:11, Doug McKenna <doug at mathemaesthetics.com>
wrote:

>
> But interestingly, a web (the other web) search for "Y&Y Inc" matches this
> TeX-related page:
> So perhaps this TFM file has something to do with them.
>

it certainly does, the original  tfm mentioned was ...8y.tfm

8y (known as LY1 in latex) is Y&Y's "texnansi" encoding.

David



>
> Doug McKenna
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190913/106dde95/attachment.html>

From P.Taylor at rhul.ac.uk  Fri Sep 13 22:56:57 2019
From: P.Taylor at rhul.ac.uk (Taylor, P)
Date: Fri, 13 Sep 2019 20:56:57 +0000
Subject: [Q] TFM files headers
In-Reply-To: <alpine.LRH.2.21.1909131906490.1029@tug.org>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <alpine.LRH.2.21.1909131906490.1029@tug.org>
Message-ID: <107ba034-97a6-f4f7-a9f1-e52172ab6d0e@Rhul.Ac.Uk>

barbara beeton wrote:
On Fri, 13 Sep 2019, Taylor, P wrote:

Tomas Rokicki wrote:

      A google search immediately returns
   https://en.wikipedia.org/wiki/TeX_font_metric

which has the appropriate reference to tftopl as well as being a
pretty easy read itself.

Do you have any idea of which iteration of TeX David was writing, since TeX82 would require "\font
\A=CMR10" whilst TeX78 would have required (as David himself notes)  "\:A=CMR10".
Philip Taylor

The article by David Fuchs is from TUGboat volume 2 (1981),
so TeX was in flux.  In fact, in the first paragraph, there
is this sentence:

  For instance, when you say \font A=CMR10 to TeX (\:A=CMR10 in the old lingo), ...

so that should settle that question.

Well, it didn't settle it for me, which is why I asked !  It was clear that \:A=CMR10 was from TeX78. because the first thing I did on reading that was to take my copy of TeX and MetaFont and look up the syntax of the \font-equiv command, which was exactly as reported by DF as "the old lingo".  But it was (and still is) unclear which version of TeX required/allowed \font A=CMR10 rather than \font \A=CMR10.  Now you say that "TeX was in a state of flux", but this is the first suggestion that I have ever read that TeX did not go direct from TeX78 to TeX82 ? are you saying that there were intermediate (but unnumbered/unnamed) versions, and if so, were they found "in the wild" or only within the safe haven of Leyland Stanford University ? And having declared \font A = CMR10, how did one then use A, and why did words containing "A" not cause trouble ?

Philip Taylor
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190913/93068b54/attachment.html>

From bnb at tug.org  Fri Sep 13 23:10:07 2019
From: bnb at tug.org (barbara beeton)
Date: Fri, 13 Sep 2019 23:10:07 +0200 (CEST)
Subject: [Q] TFM files headers
In-Reply-To: <107ba034-97a6-f4f7-a9f1-e52172ab6d0e@Rhul.Ac.Uk>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <alpine.LRH.2.21.1909131906490.1029@tug.org>
 <107ba034-97a6-f4f7-a9f1-e52172ab6d0e@Rhul.Ac.Uk>
Message-ID: <alpine.LRH.2.21.1909132305250.1029@tug.org>

On Fri, 13 Sep 2019, Taylor, P wrote:

> barbara beeton wrote:
>       On Fri, 13 Sep 2019, Taylor, P wrote:
>
>             Tomas Rokicki wrote:
>
>             ????? A google search immediately returns
>             ? ?https://en.wikipedia.org/wiki/TeX_font_metric
>
>             which has the appropriate reference to tftopl as
>             well as being a
>             pretty easy read itself.
>
>             Do you have any idea of which iteration of TeX David
>             was writing, since TeX82 would require "\font
>             \A=CMR10" whilst TeX78 would have required (as David
>             himself notes)? "\:A=CMR10".?
>             Philip Taylor
>
>       The article by David Fuchs is from TUGboat volume 2 (1981),
>       so TeX was in flux.? In fact, in the first paragraph, there
>       is this sentence:
>
>       ? For instance, when you say \font A=CMR10 to TeX (\:A=CMR10 in
>       the old lingo), ...
>
>       so that should settle that question.
> 
> Well, it didn't settle it for me, which is why I asked !? It was clear that
> \:A=CMR10 was from TeX78. because the first thing I did on reading that was
> to take my copy of TeX and MetaFont and look up the syntax of the
> \font-equiv command, which was exactly as reported by DF as "the old
> lingo".? But it was (and still is) unclear which version of TeX
> required/allowed \font A=CMR10 rather than \font \A=CMR10.? Now you say that
> "TeX was in a state of flux", but this is the first suggestion that I have
> ever read that TeX did not go direct from TeX78 to TeX82 ? are you saying
> that there were intermediate (but unnumbered/unnamed) versions, and if so,
> were they found "in the wild" or only within the safe haven of Leyland
> Stanford University ? And having declared \font A = CMR10, how did one then
> use A, and why did words containing "A" not cause trouble ?

I'm not aware of a version of TeX with that syntax ever got loose.
But if \font were defined to take a single token, then "A" wouldn't
necessarily have to be \catcoded to something other than "letter",
so I don't see any problem with ordinary words, or, indeed, \cs-es
containing that letter.  But I'll think about it some more.
 						-- bb

From P.Taylor at rhul.ac.uk  Fri Sep 13 23:15:59 2019
From: P.Taylor at rhul.ac.uk (Taylor, P)
Date: Fri, 13 Sep 2019 21:15:59 +0000
Subject: [Q] TFM files headers
In-Reply-To: <alpine.LRH.2.21.1909132305250.1029@tug.org>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <alpine.LRH.2.21.1909131906490.1029@tug.org>
 <107ba034-97a6-f4f7-a9f1-e52172ab6d0e@Rhul.Ac.Uk>
 <alpine.LRH.2.21.1909132305250.1029@tug.org>
Message-ID: <5a4f74a3-a639-d13f-d542-a73c9bf91532@Rhul.Ac.Uk>

barbara beeton wrote:

> I'm not aware of a version of TeX with that syntax ever got loose.
> But if \font were defined to take a single token, then "A" wouldn't
> necessarily have to be \catcoded to something other than "letter",
> so I don't see any problem with ordinary words, or, indeed, \cs-es
> containing that letter.? But I'll think about it some more.

I realised that other contemporaneous articles in TUGboat might provide 
an clue, and I now believe that one had to write "\curfont A" in order 
to use the font "A".
** Phil.


From asnd at triumf.ca  Sat Sep 14 03:56:22 2019
From: asnd at triumf.ca (Donald Arseneau)
Date: Sat, 14 Sep 2019 01:56:22 +0000
Subject: [Q] TFM files headers
In-Reply-To: <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>,
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
Message-ID: <YTBPR01MB2624F57DD69DA0D69DD229E4DFB20@YTBPR01MB2624.CANPRD01.PROD.OUTLOOK.COM>

*\catcode `A=\catcode`\~
*\font A=cmr10
*A
* Hello.\par
*\tracingall\showlists

So there are idiosyncrasies with plain-letter named fonts.


Donald Arseneau             TRIUMF CMMS           604-222-1047 x6295

(replying to)

What happens when you say "\font A=CMR10"  (note: no slash before "A").  Do you have any idea of which iteration of TeX David was writing, since TeX82 would require "\font \A=CMR10" whilst TeX78 would have required (as David himself notes) "\:A=CMR10".  BNB cc'd as she may know the answer.

Philip Taylor
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190914/038e60d2/attachment.html>

From P.Taylor at rhul.ac.uk  Sat Sep 14 17:41:15 2019
From: P.Taylor at rhul.ac.uk (Taylor, P)
Date: Sat, 14 Sep 2019 15:41:15 +0000
Subject: [Q] TFM files headers
In-Reply-To: <YTBPR01MB2624F57DD69DA0D69DD229E4DFB20@YTBPR01MB2624.CANPRD01.PROD.OUTLOOK.COM>
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <YTBPR01MB2624F57DD69DA0D69DD229E4DFB20@YTBPR01MB2624.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <a8855ce9-db86-b029-f130-d13a518db484@Rhul.Ac.Uk>

Donald Arseneau wrote:

*\catcode `A=\catcode`\~
*\font A=cmr10
*A
* Hello.\par
*\tracingall\showlists

So there are idiosyncrasies with plain-letter named fonts.

I don't think that one was required to re-catcode (e.g.,) "A" in those days, Donald, in order to use it as a font identifier.  See (for example) http://www.tug.org/TUGboat/tb02-1/tb02mill.pdf

Philip Taylor
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190914/b32d5eaa/attachment.html>

From didier at didierverna.net  Sat Sep 14 18:53:27 2019
From: didier at didierverna.net (Didier Verna)
Date: Sat, 14 Sep 2019 18:53:27 +0200
Subject: [Q] TFM files headers
In-Reply-To: <m21rwkc9cg.fsf@didierverna.net> (Didier Verna's message of "Fri, 
 13 Sep 2019 20:57:51 +0200")
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
 <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
 <CAJCZBmTDaw0eGwXZEJwMkdUwbhsSmMYmc-F8pA1HjeYaC8KRHA@mail.gmail.com>
 <m21rwkc9cg.fsf@didierverna.net>
Message-ID: <m2pnk2bz08.fsf@didierverna.net>

I wrote:

>   That could explain some things. How do you distinguish JFM from TFM
>   without looking at the file extension (specifically for JFM files
>   named .tfm)?

  Replying to myself (I will consult later), I found the answer to that
  in the chkdvifont source code. It seems that OFM files have lf = 0 and
  JFM ones 9 or 11.

  So, after filtering those files out, there are still 628 (around 1%)
  tfm files in TeX Live 2019 that contain excessive data. I wonder
  what's in there...

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From didier at didierverna.net  Sat Sep 14 21:30:56 2019
From: didier at didierverna.net (Didier Verna)
Date: Sat, 14 Sep 2019 21:30:56 +0200
Subject: [Q] TFM files headers
In-Reply-To: <m2pnk2bz08.fsf@didierverna.net> (Didier Verna's message of "Sat, 
 14 Sep 2019 18:53:27 +0200")
References: <m28squeyav.fsf@didierverna.net>
 <909a6f2d-4d76-3ce8-3f46-21a022bd9ebc@silmaril.ie>
 <CAGia-=VJ2twDCOhMqyWrwC1D0se+ZMqcn7xqpjsT-uKzgzammw@mail.gmail.com>
 <85c8c578-570c-42b2-1007-ba46f4c840c4@Rhul.Ac.Uk>
 <m236h0eerq.fsf@didierverna.net>
 <38fdcf98-edd4-cdb1-b6b4-c6d11ea94680@Rhul.Ac.Uk>
 <m2r24kcwtu.fsf@didierverna.net>
 <368dd59c-0adf-5528-c11b-3ca8ee593744@Rhul.Ac.Uk>
 <m2impwcuu5.fsf@didierverna.net>
 <CAGia-=W+qj5-ziLp9nMa5NaB9mfgF3E0w7FeWzC6D1EFDiy7+Q@mail.gmail.com>
 <CAGia-=VVO7keZjOnkTK7=dGhjXVAWhY4AXunHaQfzEiY6yCRJg@mail.gmail.com>
 <CAJCZBmTDaw0eGwXZEJwMkdUwbhsSmMYmc-F8pA1HjeYaC8KRHA@mail.gmail.com>
 <m21rwkc9cg.fsf@didierverna.net> <m2pnk2bz08.fsf@didierverna.net>
Message-ID: <m2lfuqbrpr.fsf@didierverna.net>

I wrote:

> So, after filtering those files out, there are still 628 (around 1%)
> tfm files in TeX Live 2019 that contain excessive data. I wonder
> what's in there...

  Furthermore, if we silently ignore the excess data, that leaves only
  two tfm files in TeX Live 2019 that are invalid for real (they have
  fix word values out of the authorized ]-16,+16[ range):
  ArevSans-Bold.tfm and ArevSans-BoldOblique.tfm.

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From marchywka at hotmail.com  Sat Sep 14 23:51:05 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sat, 14 Sep 2019 21:51:05 +0000
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
Message-ID: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>


In a prior thread I was describing some reasons to prefer latex-like
document "source" over things like html or explicit xml. Someone 
offered the CELT site below as an example of an experiment related
to this topic. In the link in the sample bibtex below, there is a link
to xml described as the "source document", 

%2019-09-14:17:16:49
%autogenerated by toobib 
@www{CELTprojectBriefeucc,
authors = {},
title = {CELT project: A Briefe description of Ireland: made in this year, 1589, By Robert Payne | University College Cork},
url = {http://research.ucc.ie/celt/document/E590001-007},
urldate = {2019-09-14:17:16:49},
year = {}
}

so called "source document":

http://research.ucc.ie/celt/document/E590001-007.xml

While it is quite true that this xml provides good explicit
structure and is "human readable" it does not
quite "flow" like simple latex source code. That is you could read 
most latex source as if it was meant to be understood versus html
or this xml. The latex just provides logical structure without a lot
of verbosity and allows a renderer to define layout info for the latex things.


Anyway, the point in posting this time is to ask about citing web pages.
For most articles intended to be cited, I had ways to scrape bibtex off
the pages containing an abstract- if the link is on the clipboard
the script can usually find a bibtex entry or a doi and call crossref.
However, I need to make some arguments contrasted to "popular" or maybe
news sites or cite commercial products that were mentioned in a work.
Few of these provide bibtex for their pages although plenty have
"share"  features.  AFAICT, even the CELT site did not provide
much in the way of "how to cite" which is odd for their academic
work and indeed confusing as you want to credit their work with
displaying some other classic work. Is there some obvious way
anyone here would create a bibtex entry for the page above, 

 
url = {http://research.ucc.ie/celt/document/E590001-007},

and as an example of the commercial site, for example,


./toobib.h608  m_bib.format()=%2019-09-14:17:45:00
%autogenerated by toobib 
@www{ZincCapsHighPotencylifeextension,
authors = {},
title = {Zinc Caps High Potency, 50 mg 90 capsules | Life Extension    },
url = {https://www.lifeextension.com/vitamins-supplements/item01813/zinc-caps-high-potency},
urldate = {2019-09-14:17:45:00},
year = {}
}

mjm>

?



The bibtex above is what I could scrape from the link using some code I wrote
to do it automatically from the link itself, html fields like "title" and any
"meta" it can find. Eventually I could chase down doi's or other cues, that
is why I went from bash to c++, but hopefully it does not become that big a mess.  
I guess if this worked well it would be nice to let
publishers or site owners use a similar tool to provide bibtex in a "how to cite"
button next to all the sharing stuff. 

Google scholar probably did something like this to create their bibtex but I was
not sure if any of that is public or if other mechanisms exist so I wrote
my own code but it could be quite involved and I'm not even sure how
to use some of the fields. Is there a style guide with this in it somewhere?

Thanks. 



-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From peter at silmaril.ie  Sun Sep 15 12:14:59 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Sun, 15 Sep 2019 11:14:59 +0100
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>


On 14/09/2019 22:51, Mike Marchywka wrote:
> 
> In a prior thread I was describing some reasons to prefer latex-like
> document "source" over things like html or explicit xml. 

I'm not clear what "explicit" XML is (as opposed to what?)

> Someone offered the CELT site below as an example of an experiment
> related to this topic. 

That would be me :-)

> In the link in the sample bibtex below, there is a link to xml
> described as the "source document",

Where did you see http://research.ucc.ie/celt/document/E590001-007 
described as the "source document"?

> %2019-09-14:17:16:49
> %autogenerated by toobib
> @www{CELTprojectBriefeucc,
> authors = {},
> title = {CELT project: A Briefe description of Ireland: made in this year, 1589, By Robert Payne | University College Cork},
> url = {http://research.ucc.ie/celt/document/E590001-007},
> urldate = {2019-09-14:17:16:49},
> year = {}
> }
> 
> so called "source document":

That's some kind of auto-generated bib file about the web page. The CELT
project does not call this a source document. For the source
document you can look in the web page and click on "Header" and then
"Source" where you will find the BiBTeX:

@incollection{E590001-007,
   editor 	 = {Aquilla Smith},
   title 	 = {A Brife description of Ireland: made in this yeere. 1589. 
By Robert Payne. vnto xxv. of his partners for whom he is undertaker 
there. Truely published verbatim, according to his letters, by Nich. 
Gorsan one of the said partners, for that he would his countrymen should 
be partakers of the many good Notes therein conteined. With diuers Notes 
taken out of others the Authoures letters written to his said partners, 
sithenes the first Impression, well worth the reading.},
   booktitle 	 = {Tracts relating to Ireland, printed for the Irish 
Archaeological Society.},
   address 	 = {Dublin},
   publisher 	 = {University Press, Graisberry and Gill},
   date 	 = {1841},
   volume 	 = {1},
   note 	 = {v?viii; 3?14 (separate pagination)}
}

> http://research.ucc.ie/celt/document/E590001-007.xml
> While it is quite true that this xml provides good explicit structure
> and is "human readable" it does not quite "flow" like simple latex
> source code.
I'm not clear what "flow" means in this context. The XML document is an 
an accurate representation of the original book from 1841. It begins 
like this:

     <body>
       <div0 type="description" lang="en">
	<head>A Brife description of Ireland: made in this yeere.
	  1589. By Robert Payne [...]</head>
	<pb n="3"/>
	<div1 type="section" n="1">
	  <p><text type="letter">
	      <body>
		<p>Let not the reportes of those that haue spent all
		  their owne and what they could by any meanes get
		  from others in England, discourage you from
		  Irela<ex>n</ex>d, although they and such others by
		  bad dealinges haue wrought a generall discredite to
		  all English men, in that countrie which are to the
		  Irishe vnknowen.</p>

I'm not sure that there is any other meaningful way to do it: the 
objective of the project is to capture the text and *accurate* structure 
of the original, so there's a divisional container, a heading, a 
pge-break, a numbered sub-container, with a quoted letter with its own 
internal structure, etc.

> That is you could read most latex source as if it was meant to be
> understood versus html or this xml.
Correct. XML is a file storage format. It contains information that 
LaTeX does not have by default (eg nested containers)

> The latex just provides 

...some...

> logical structure without a lot of verbosity 

Correct. XML is for *storing* the metadata ? in this case for posterity 
? it makes no judgment about how you or anyone else will use it.

> and allows a renderer to define layout info for the latex things.

Right. The project could have used LaTeX (it was seriously considered 
back when it was starting in 1989) but wiser heads prevailed.

You can already see in the extract above that an editor has annotated 
her corrections wherever she expanded a word to complete the spelling, 
with the <ex> element type. In print, this would be rendered [n] or 
perhaps an italic n or an underlined n ? that's a formatting decision 
for the publisher. Using XML, you don't specify *how* it looks, only 
that it exists. Scholars need the non-committal format so they can do 
things like studying the scriptorial or linguistic aspects of editions, 
so being able to retrieve all occurrences of editorial interventions in 
their context is important to them, much more so than how to typeset it.

> Anyway, the point in posting this time is to ask about citing web pages.

Use biblatex for formatting, not BiBTeX, because the older formats tend 
not to have the right fields for citing web pages. See also

https://tex.stackexchange.com/questions/3587/how-can-i-use-bibtex-to-cite-a-web-page
https://tex.stackexchange.com/questions/411440/how-cite-a-website-with-bibtex

> For most articles intended to be cited, I had ways to scrape bibtex
> off the pages containing an abstract- if the link is on the
> clipboard the script can usually find a bibtex entry or a doi and
> call crossref.
Right. Scrapers are usually unreliable, even Zotero and Mendeley. Most 
journal pages have a download, often including a .bib file, but even if 
they only have RIS, you can still open that in JabRef and get the data 
saved in BiBTeX format.

> However, I need to make some arguments contrasted to "popular" or
> maybe news sites or cite commercial products that were mentioned in a
> work. Few of these provide bibtex for their pages although plenty
> have "share"  features. 

In those cases the only answer is to copy and paste into JabRef or 
whatever you use to manage your bibliography.

> AFAICT, even the CELT site did not provide much in the way of "how to
> cite" which is odd for their academic work and indeed confusing as
> you want to credit their work with displaying some other classic
> work. 

Yes, it's something missing which is on the list to implement. As I 
said, it's a new format and not everything is in place yet. However, 
very few people would ever need to cite the CELT *web page* itself. They 
would cite the quoted edition (which is why BiBTeX is provided in every 
document), and just add the URL as their link. The CELT editions can be 
treated exactly as the paper editions would be.

> Is there some obvious way anyone here would create a bibtex
> entry for the page above,

At the moment, only manually. But given your impetus, I can bump the 
priority level for providing this up a few notches. It's fairly complex 
because it needs some decisions taking over (eg) which version of the 
title to use, how many of the editors to cite (some documents have 
dozens), etc.

> and as an example of the commercial site, for example,
> 
> ./toobib.h608  m_bib.format()=%2019-09-14:17:45:00
> %autogenerated by toobib
> @www{ZincCapsHighPotencylifeextension,
> authors = {},
> title = {Zinc Caps High Potency, 50 mg 90 capsules | Life Extension    },
> url = {https://www.lifeextension.com/vitamins-supplements/item01813/zinc-caps-high-potency},
> urldate = {2019-09-14:17:45:00},
> year = {}
> }

I would make that something like:

@www{ZincCapsHighPotencylifeextension,
authors = {Life Extension Foundation},
title = {Zinc Caps High Potency, 50 mg 90 capsules},
url = 
{www.lifeextension.com/vitamins-supplements/item01813/zinc-caps-high-potency},
urldate = {2019-09-14T17:45:00},
year = {2019},
address = {Fort Lauderdale, FL}
}

> The bibtex above is what I could scrape from the link using some code I wrote
> to do it automatically from the link itself, html fields like "title" and any
> "meta" it can find. 

Unless the page owner is aware of things like citation, that's probably 
all you'll ever get.

> Eventually I could chase down doi's or other cues, that is why I went
> from bash to c++, but hopefully it does not become that big a mess
I would have stuck with bash because of the huge range of facilities 
designed for text manipulation like tidy and the LTxml2 utilities.

> I guess if this worked well it would be nice to let publishers or 
> site owners use a similar tool to provide bibtex in a "how to cite" 
> button next to all the sharing stuff.

I doubt if they would be interested, to be honest.

> Google scholar probably did something like this to create their 
> bibtex but I was not sure if any of that is public or if other 
> mechanisms exist so I wrote my own code but it could be quite 
> involved and I'm not even sure how to use some of the fields. Is 
> there a style guide with this in it somewhere?

You can ask them :-)

P

From marchywka at hotmail.com  Sun Sep 15 14:56:48 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sun, 15 Sep 2019 12:56:48 +0000
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
Message-ID: <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>

On Sun, Sep 15, 2019 at 11:14:59AM +0100, Peter Flynn wrote:
> 
> On 14/09/2019 22:51, Mike Marchywka wrote:
> > 
> > In a prior thread I was describing some reasons to prefer latex-like
> > document "source" over things like html or explicit xml.
> 
> I'm not clear what "explicit" XML is (as opposed to what?)

Anything that is XML but called something different, mostly things ending in ML  :) 

> 
> > Someone offered the CELT site below as an example of an experiment
> > related to this topic.
> 
> That would be me :-)
> 
> > In the link in the sample bibtex below, there is a link to xml
> > described as the "source document",
> 
> Where did you see http://research.ucc.ie/celt/document/E590001-007 described
> as the "source document"?
>
Bad editing, I meant that if you hit that link and then look at the content,
there is another link featured on the right of the page that looks like this,  

Source document
E590001-007.xml

 
> > %2019-09-14:17:16:49
> > %autogenerated by toobib
> > @www{CELTprojectBriefeucc,
> > authors = {},
> > title = {CELT project: A Briefe description of Ireland: made in this year, 1589, By Robert Payne | University College Cork},
> > url = {http://research.ucc.ie/celt/document/E590001-007},
> > urldate = {2019-09-14:17:16:49},
> > year = {}
> > }
> > 
> > so called "source document":
> 
> That's some kind of auto-generated bib file about the web page. The CELT

yes, because I could not find the citing info on that page ( logically it should
be with the shares but I though it would be on THAT page lol). 

> project does not call this a source document. For the source

If I click the thing called "source document" on the right it goes to the xml,

http://research.ucc.ie/celt/document/E590001-007#front

Source document
E590001-007.xml

and the link copies as 
http://research.ucc.ie/celt/document/E590001-007.xml

> document you can look in the web page and click on "Header" and then
> "Source" where you will find the BiBTeX:
>

Thanks, that is exactly what I needed for this site but I'm not sure
how you could have easily found that- they have one button "share" things
on the other page but you have to dig up the citation. In this case, there are two kinds
of source- the original literature on which the page is based and 
what they apparently also call a "source" as I mentioned above which
is XML for that generates the web page. 

 
> @incollection{E590001-007,
>   editor 	 = {Aquilla Smith},
>   title 	 = {A Brife description of Ireland: made in this yeere. 1589. By
> Robert Payne. vnto xxv. of his partners for whom he is undertaker there.
> Truely published verbatim, according to his letters, by Nich. Gorsan one of
> the said partners, for that he would his countrymen should be partakers of
> the many good Notes therein conteined. With diuers Notes taken out of others
> the Authoures letters written to his said partners, sithenes the first
> Impression, well worth the reading.},
>   booktitle 	 = {Tracts relating to Ireland, printed for the Irish
> Archaeological Society.},
>   address 	 = {Dublin},
>   publisher 	 = {University Press, Graisberry and Gill},
>   date 	 = {1841},
>   volume 	 = {1},
>   note 	 = {v?viii; 3?14 (separate pagination)}
> }
> 
> > http://research.ucc.ie/celt/document/E590001-007.xml
> > While it is quite true that this xml provides good explicit structure
> > and is "human readable" it does not quite "flow" like simple latex
> > source code.
> I'm not clear what "flow" means in this context. The XML document is an an
I had to pick a word for the style- if you try to read it you can't just sit
down and read it you have all the "XML junk" to read around. See beloe but
the latex-like syntax does not imply specific presentation of the info 
it just is better visually organized even before typesetting into a specific
rendition.  

> accurate representation of the original book from 1841. It begins like this:
> 
>     <body>
>       <div0 type="description" lang="en">
> 	<head>A Brife description of Ireland: made in this yeere.
> 	  1589. By Robert Payne [...]</head>
> 	<pb n="3"/>
> 	<div1 type="section" n="1">
> 	  <p><text type="letter">
> 	      <body>
> 		<p>Let not the reportes of those that haue spent all
> 		  their owne and what they could by any meanes get
> 		  from others in England, discourage you from
> 		  Irela<ex>n</ex>d, although they and such others by
> 		  bad dealinges haue wrought a generall discredite to
> 		  all English men, in that countrie which are to the
> 		  Irishe vnknowen.</p>
> 
> I'm not sure that there is any other meaningful way to do it: the objective
> of the project is to capture the text and *accurate* structure of the
> original, so there's a divisional container, a heading, a pge-break, a
> numbered sub-container, with a quoted letter with its own internal
> structure, etc.
> 
> > That is you could read most latex source as if it was meant to be
> > understood versus html or this xml.
> Correct. XML is a file storage format. It contains information that LaTeX
> does not have by default (eg nested containers)
> 
> > The latex just provides
> 
> ...some...
> 
> > logical structure without a lot of verbosity
> 
> Correct. XML is for *storing* the metadata ? in this case for posterity ? it
> makes no judgment about how you or anyone else will use it.
> 
> > and allows a renderer to define layout info for the latex things.
> 
> Right. The project could have used LaTeX (it was seriously considered back
> when it was starting in 1989) but wiser heads prevailed.
> 
> You can already see in the extract above that an editor has annotated her
> corrections wherever she expanded a word to complete the spelling, with the
> <ex> element type. In print, this would be rendered [n] or perhaps an italic
> n or an underlined n ? that's a formatting decision for the publisher. Using
> XML, you don't specify *how* it looks, only that it exists. Scholars need
> the non-committal format so they can do things like studying the scriptorial
> or linguistic aspects of editions, so being able to retrieve all occurrences
> of editorial interventions in their context is important to them, much more
> so than how to typeset it.
>

I understand all of that and mostly just object on the "human readability."
Ideally of course you have some "Source [digial] Document" that contains all the information
about the , well, source document ( the histoical thing you want to make available to 
the world). XML is a flexible well supported thing for anything you can define
as a tree of text. Latex, or maybe even JSON for that matter, AFAICT provide
similar capabilities with varying human readability. There is no reason that
a latex-like document needs to have any formatting stuff- all those commands
can be logical rather than "what it looks like" and you can choose rendering
algorithms when displaying.  

 
> > Anyway, the point in posting this time is to ask about citing web pages.
> 
> Use biblatex for formatting, not BiBTeX, because the older formats tend not

ok, I have to see what is involved as I migrated recently not sure I looked
at bib details. 

> to have the right fields for citing web pages. See also
> 
> https://tex.stackexchange.com/questions/3587/how-can-i-use-bibtex-to-cite-a-web-page
> https://tex.stackexchange.com/questions/411440/how-cite-a-website-with-bibtex
>
I guess this is kind of open yet. Although in the second link it is funny they
mention "plain" style my earlier latex was so old I wrote a plainurl
bst  that included a url lol. 
 
> > For most articles intended to be cited, I had ways to scrape bibtex
> > off the pages containing an abstract- if the link is on the
> > clipboard the script can usually find a bibtex entry or a doi and
> > call crossref.
> Right. Scrapers are usually unreliable, even Zotero and Mendeley. Most
> journal pages have a download, often including a .bib file, but even if they
> only have RIS, you can still open that in JabRef and get the data saved in
> BiBTeX format.
> 
> > However, I need to make some arguments contrasted to "popular" or
> > maybe news sites or cite commercial products that were mentioned in a
> > work. Few of these provide bibtex for their pages although plenty
> > have "share"  features.
> 
> In those cases the only answer is to copy and paste into JabRef or whatever
> you use to manage your bibliography.
> 
> > AFAICT, even the CELT site did not provide much in the way of "how to
> > cite" which is odd for their academic work and indeed confusing as
> > you want to credit their work with displaying some other classic
> > work.
> 
> Yes, it's something missing which is on the list to implement. As I said,

Well, the bibtex you found looks nice but it also seems like a research
task just to find it. I guess if it was on the same page as the share
features( some journals have a cite button near the shares)
 that would be easier but at least it exists. 

> it's a new format and not everything is in place yet. However, very few
> people would ever need to cite the CELT *web page* itself. They would cite
> the quoted edition (which is why BiBTeX is provided in every document), and
> just add the URL as their link. The CELT editions can be treated exactly as
> the paper editions would be.
> 
> > Is there some obvious way anyone here would create a bibtex
> > entry for the page above,
> 
> At the moment, only manually. But given your impetus, I can bump the
> priority level for providing this up a few notches. It's fairly complex
> because it needs some decisions taking over (eg) which version of the title
> to use, how many of the editors to cite (some documents have dozens), etc.
> 
> > and as an example of the commercial site, for example,
> > 
> > ./toobib.h608  m_bib.format()=%2019-09-14:17:45:00
> > %autogenerated by toobib
> > @www{ZincCapsHighPotencylifeextension,
> > authors = {},
> > title = {Zinc Caps High Potency, 50 mg 90 capsules | Life Extension    },
> > url = {https://www.lifeextension.com/vitamins-supplements/item01813/zinc-caps-high-potency},
> > urldate = {2019-09-14:17:45:00},
> > year = {}
> > }
> 
> I would make that something like:
> 
> @www{ZincCapsHighPotencylifeextension,
> authors = {Life Extension Foundation},
> title = {Zinc Caps High Potency, 50 mg 90 capsules},
> url = {www.lifeextension.com/vitamins-supplements/item01813/zinc-caps-high-potency},
> urldate = {2019-09-14T17:45:00},
> year = {2019},
> address = {Fort Lauderdale, FL}
> }
>

I guess it is kind of an almost irrelevant point but I was curious about authors- both
intended content and where to scrape. Probably any reader who wanted to look
would just hit the link and not care how it was written. Ultimately the point of the
bibliography is docuementation and aid to reader.  

 
> > The bibtex above is what I could scrape from the link using some code I wrote
> > to do it automatically from the link itself, html fields like "title" and any
> > "meta" it can find.
> 
> Unless the page owner is aware of things like citation, that's probably all
> you'll ever get.
> 
> > Eventually I could chase down doi's or other cues, that is why I went
> > from bash to c++, but hopefully it does not become that big a mess
> I would have stuck with bash because of the huge range of facilities
> designed for text manipulation like tidy and the LTxml2 utilities.
> 
> > I guess if this worked well it would be nice to let publishers or site
> > owners use a similar tool to provide bibtex in a "how to cite" button
> > next to all the sharing stuff.
> 
> I doubt if they would be interested, to be honest.
Yeah I get that feeling too I guess links or shares are most of the publicicity.

> 
> > Google scholar probably did something like this to create their bibtex
> > but I was not sure if any of that is public or if other mechanisms exist
> > so I wrote my own code but it could be quite involved and I'm not even
> > sure how to use some of the fields. Is there a style guide with this in
> > it somewhere?
> 
> You can ask them :-)
> 
> P

Thanks.

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From didier at didierverna.net  Sun Sep 15 18:26:54 2019
From: didier at didierverna.net (Didier Verna)
Date: Sun, 15 Sep 2019 18:26:54 +0200
Subject: [Q] nonexistent characters
Message-ID: <m24l1dbk4x.fsf@didierverna.net>


  Hello,

I'm a bit confused about the notion of nonexistent characters in a font
loaded from a TFM file. There are two situations in which a character
doesn't exist: if its code is not within [bc,ec], or if it is, but its
metrics are all 0.

In the TFM description, it is explicitly said that a right boundary
character's code may not lie between bc and ec, which I think I
understand, because this character is in fact never typeset.

However, I have found fonts in which some nonexistent characters exist
within [bc,ec], notably with an index to the lig/kern table. I fail to
understand the purpose of these characters. Why would a font have a
nonexistent character, yet part of a ligature or kerning operation? Is
this related to accentuating previous characters, or anything else?

Thanks!

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From marchywka at hotmail.com  Sun Sep 15 23:43:15 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sun, 15 Sep 2019 21:43:15 +0000
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
Message-ID: <DM6PR08MB60429BC59A34D59BC326B96ABE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>

On Sun, Sep 15, 2019 at 11:14:59AM +0100, Peter Flynn wrote:
> 
> 
> Use biblatex for formatting, not BiBTeX, because the older formats tend not

I tried to install it but I'm using revtex4 and probably ran into this problem
( it is loading natbib so I assume same thing but don't have time to track down now),

https://tex.stackexchange.com/questions/375813/issue-with-biblatex-bibhang-already-defined?rq=1


> 
> > 
> document you can look in the web page and click on "Header" and then
> "Source" where you will find the BiBTeX:
> 
> @incollection{E590001-007,
>   editor 	 = {Aquilla Smith},
>   title 	 = {A Brife description of Ireland: made in this yeere. 1589. By
> Robert Payne. vnto xxv. of his partners for whom he is undertaker there.
> Truely published verbatim, according to his letters, by Nich. Gorsan one of
> the said partners, for that he would his countrymen should be partakers of
> the many good Notes therein conteined. With diuers Notes taken out of others
> the Authoures letters written to his said partners, sithenes the first
> Impression, well worth the reading.},
>   booktitle 	 = {Tracts relating to Ireland, printed for the Irish
> Archaeological Society.},
>   address 	 = {Dublin},
>   publisher 	 = {University Press, Graisberry and Gill},
>   date 	 = {1841},
>   volume 	 = {1},
>   note 	 = {v?viii; 3?14 (separate pagination)}
> }

I guess one thing that may be nice is if sites had a meta field for a link to the bibtex for that page.
It looks like I could have scraped for an href to a bib file though :) 
However, every publisher has some different thing if they have it at all although there
seem to be some shared approaches. The celt thing is nice because you just change the extension.
Once you showed me where it is, it was easy to automate the process for that site assuming
they are consistent. With the link on the clipboard, it uses a new celt handler a few lines
long to make the bib url, and then created a commented entry as shown below.
Note also that I added the source url to the bibtex although the code
has become such a mess that is not always the case but in theory I can
clean up any downloaded stuff, run it in a dummy file to make sure bibtex likes
it, and then finally copy to my main bib files.   Once I made a "plainurl.bst"
I wanted to make sure all my entries had a url field ... 

The first command creates file xxx which has presumed bibtex to be validated
along with the comments from the download script.  


marchywka at happy:/home/documents/latex/proj/happyheart$ med2bib -cite > xxxx
danger check that url is inserted into bibtex doh
try guesscelt
@incollection{E590001-007,
% citeurl:  http://research.ucc.ie/celt/document/E590001-007.bib
leaving guesscelt with handled = 1
marchywka at happy:/home/documents/latex/proj/happyheart$ cat xxxx

%  downloaded by med2bib -cite and -exportbib on   Sun Sep 15 17:29:28 EDT 2019
% srcurl:  http://research.ucc.ie/celt/document/E590001-007
% citeurl:  http://research.ucc.ie/celt/document/E590001-007.bib


@incollection{E590001-007,
  editor 	 = {Aquilla Smith},
  title 	 = {A Brife description of Ireland: made in this yeere. 1589. By Robert Payne. vnto xxv. of his partners for whom he is undertaker there. Truely published verbatim, according to his letters, by Nich. Gorsan one of the said partners, for that he would his countrymen should be partakers of the many good Notes therein conteined. With diuers Notes taken out of others the Authoures letters written to his said partners, sithenes the first Impression, well worth the reading.},
  booktitle 	 = {Tracts relating to Ireland, printed for the Irish Archaeological Society.},
  address 	 = {Dublin},
  publisher 	 = {University Press, Graisberry and Gill},
  date 	 = {1841},
  volume 	 = {1},
  note 	 = {v?viii; 3?14 (separate pagination)}
 , url={http://research.ucc.ie/celt/document/E590001-007}}


After that, it leaves a citation thing on the clipboard that I would just
past into the doc I'm editing,

marchywka at happy:/home/documents/latex/proj/happyheart$ \cite{E590001-007}
cite{E590001-007}: command not found


And the reason I gave up on bash for c++ is all the tentative junk on sites
that don't support bibtex. In the bash scripts, I was struggling to manage the
tentative results and back up - I ended up with temp files etc. 
The c++ has data structures for all these
things and most of it just calls bash things. For example stuff like this lol,

m_rdclip="myclip -echo";
m_rdurl="wget ";
m_copy="xclip -in -l 0  -selection clipboard ";

can execute and I can capture the output or feed input from things in containers.
Even before, I could end up with the original page text, a lynx rendered version,
a related pdf file, that converted to txt, etc. Then to make the bibtex
uniform is probably easier with c++ than sed. 
And all these things that call executables now could be linked into the 
c++ code if I needed say a modified lynx or something.
When it failed digging through it was a mess but here I have an integrated
command line thing using readline and there is always gdb which is probably
less dumb than it sounds :) 


-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From peter at silmaril.ie  Sun Sep 15 23:49:47 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Sun, 15 Sep 2019 22:49:47 +0100
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
 <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <2bcde6b2-7187-60a6-c0eb-e062238c4f41@silmaril.ie>

On 15/09/2019 13:56, Mike Marchywka wrote:
[...]
>> I'm not clear what "explicit" XML is (as opposed to what?)
> 
> Anything that is XML but called something different, mostly things
> ending in ML :)

Ah. OK, thanks. They're actually all XML; XML is the name of the 
standard, not an actual vocabulary of tags like HTML or TEI. But yes, 
they do tend end in ML.

> Bad editing, I meant that if you hit that link and then look at the content,
> there is another link featured on the right of the page that looks like this,
> 
> Source document
> E590001-007.xml

My misunderstanding, sorry. And you're right, it's badly phrased. That 
is the source document from which the web page is made (in real time). 
It never occurred to me that it also implies that it is the only source 
of the document. I need to edit that and  make it clearer. Thanks for 
the prompt.

> Thanks, that is exactly what I needed for this site but I'm not sure
> how you could have easily found that- they have one button "share" things
> on the other page but you have to dig up the citation.

The target community for these pages is the Early Irish scholar, and 
they know that certain things are in certain places (CELT has been going 
since 1991) so I think we have been lazy in not getting the pages up to 
date.

>> I'm not clear what "flow" means in this context. 
 >
> I had to pick a word for the style- if you try to read it you can't just sit
> down and read it you have all the "XML junk" to read around. 

That's called "markup" and it's what makes TEI useful. XML was NEVER 
designed to be readable like an unmarked text.

> See below but the latex-like syntax does not imply specific
> presentation of the info it just is better visually organized even
> before typesetting into a specific rendition.

Exactly. You'll see that the XML text has no mention of any rendition at 
all. LaTeX isn't better organized per se, it just uses lighter markup. 
This is why humanities texts are stored in XML, and if you need a PDF or 
a web page, you use XSLT to create a LaTeX or HTML file ? or whatever 
the format du jour is (currently Markdown).

> I understand all of that and mostly just object on the "human readability."

Horses for courses, I think. Personally, I find the XML perfectly 
readable, but then I've been dealing with it for many decades. I also 
find LaTeX perfectly readable, which many users don't.

> [...] AFAICT provide similar capabilities with varying human
> readability. 

If there was any demand for a LaTeX version, we would. So far, no-one 
has asked.

> There is no reason that a latex-like document needs to have any
> formatting stuff- all those commands can be logical rather than "what
> it looks like" and you can choose rendering algorithms when
> displaying.

Mostly, yes. It's pretty trivial to write XSLT to convert the XML to

\documentclass{book}
\usepackage{celt}
\begin{document}
\title{A Brife description of Ireland: made in this yeere.
	  1589. By Robert Payne}
\author{Robert Payne}
\maketitle
\begin{quotation}
Let not the reportes of those that haue spent all
their owne and what they could by any meanes get
from others in England, discourage you from
Irela\textit{n}d, although they and such others by
bad dealinges haue wrought a generall discredite to
all English men, in that countrie which are to the
Irishe vnknowen.\par

(although harder if you want all the preamble). But even LaTeX has a lot 
of excise, and many users object just as much to backslashes and curly 
braces as they do to pointy brackets.

>> Use biblatex for formatting, not BiBTeX, because the older formats tend not
> ok, I have to see what is involved as I migrated recently not sure I looked
> at bib details.

Depends if you want to use one of the many standard citation/reference 
formats, or roll your own.

> I guess this is kind of open yet. Although in the second link it is 
> funny they mention "plain" style my earlier latex was so old I wrote
> a plainurl bst  that included a url lol.
We had to do this before biblatex.

> Well, the bibtex you found looks nice but it also seems like a
> research task just to find it. I guess if it was on the same page as
> the share features( some journals have a cite button near the
> shares) that would be easier but at least it exists.

I also wrote a bash script to do this once. It tries the whois database 
for the site owner, but that's not much use now they have gone all shy 
and are hiding their identities behind their registrar. But if you 
screenscrape what Google returns from a search for the company name 
(insert spaces and add "Inc") it's not hard to get the location.

> I guess it is kind of an almost irrelevant point but I was curious 
> about authors- both intended content and where to scrape. Probably
> any reader who wanted to look would just hit the link and not care
> how it was written. Ultimately the point of the bibliography is
> documentation and aid to reader.

Right, and if you have a specialist URI reference format, you ight or 
might not want to omit the author ? your choice.

> Yeah I get that feeling too I guess links or shares are most of the
> publicity.

I think that's about it.

Peter

From peter at silmaril.ie  Mon Sep 16 00:06:05 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Sun, 15 Sep 2019 23:06:05 +0100
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <DM6PR08MB60429BC59A34D59BC326B96ABE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
 <DM6PR08MB60429BC59A34D59BC326B96ABE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <a8061ea5-764b-4ce9-bd80-7849acf802a2@silmaril.ie>

On 15/09/2019 22:43, Mike Marchywka wrote:
> On Sun, Sep 15, 2019 at 11:14:59AM +0100, Peter Flynn wrote:
>>
>>
>> Use biblatex for formatting, not BiBTeX, because the older formats tend not
> 
> I tried to install it but I'm using revtex4 and probably ran into this problem
> ( it is loading natbib so I assume same thing but don't have time to track down now),

I've never used revtex so perhaps it is built solely on old BiBTeX 
(loading natbib would be a symptom of that). Pity.

> I guess one thing that may be nice is if sites had a meta field for a link to the bibtex for that page.

a) it certainly would

b) they already have: that's what Dublin Core, COinS, and other metadata
    formats are for: embedded in the headers: another things on the cards

c) no-one out there has ever heard of bibtex, so asking for a special
    field for it is a non-starter.

The metadata at [b] can be used by citation-grabbers like Zotero and 
Mendeley to get the data and save it as a .bib entry.

> [...] Note also that I added the source url to the bibtex although the code
> has become such a mess that is not always the case but in theory I can
> clean up any downloaded stuff, run it in a dummy file to make sure bibtex likes
> it, and then finally copy to my main bib files.   Once I made a "plainurl.bst"
> I wanted to make sure all my entries had a url field ...

Yep. But if I add the DC and COinS metadata, all that can be done for 
you by clicking on the icon that Zotero will pop up automatically, and 
saving the entry.

> And the reason I gave up on bash for c++ is all the tentative junk on sites
> that don't support bibtex. In the bash scripts, I was struggling to manage the
> tentative results and back up - I ended up with temp files etc.
> The c++ has data structures for all these

In my case, I'd use one of the automated metadata grabbers and save the 
whole lot as a non-committal XML file. Then convert to BiBTeX or 
whatever format du jour people want (JSON, EndNote, etc).

But the digging for unannotated sites will always be a pain.

Peter

From hmwlfsr at yahoo.com  Mon Sep 16 00:26:35 2019
From: hmwlfsr at yahoo.com (William F Hammond)
Date: Sun, 15 Sep 2019 15:26:35 -0700
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
 (Mike Marchywka's message of "Sun, 15 Sep 2019 12:56:48 +0000")
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
 <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <87muf5xkkk.fsf@yahoo.com>

Mike Marchywka <marchywka at hotmail.com> writes in part,
replying to Peter Flynn:

>> I'm not clear what "explicit" XML is (as opposed to what?)
>
> Anything that is XML but called something different, mostly things ending in ML  :) 

Perhaps you mean a specific XML document type.

> . . .

> I had to pick a word for the style- if you try to read it you can't just sit
> down and read it you have all the "XML junk" to read around. See beloe but
> the latex-like syntax does not imply specific presentation of the info 
> it just is better visually organized even before typesetting into a specific
> rendition.  

It is correct that LaTeX-Like syntax with discipline can
be used to write an instance under an XML document type.
(This is implemented in the GELLMU project.)

A somewhat less-disciplined LaTeX-Like syntax can be used
to write an instance under an SGML document type that is
capable of being automatically transformed to a closely
related XML document type.

Aside from the "comfort" of LaTeX-like notation, in both
cases one big advantage is the possibility of emulating
\newcommand, including \newcommand with arguments, in
pre-processing.  E.g., when writing for HTML

       \newcommand{\href}[2]{\a[href="#1"]{#2}}

Additionally and optionally, in this context an SGML (or
XML) element having a fixed sequence of subelements can be
spawned from a LaTeX-like command having positional
arguments.

                              -- Bill


Email: hmwlfsr at yahoo.com
       gellmu at gmail.com
https://www.facebook.com/william.f.hammond
http://www.albany.edu/~hammond/


From hmwlfsr at yahoo.com  Mon Sep 16 00:26:35 2019
From: hmwlfsr at yahoo.com (William F Hammond)
Date: Sun, 15 Sep 2019 15:26:35 -0700
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
 (Mike Marchywka's message of "Sun, 15 Sep 2019 12:56:48 +0000")
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
 <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <87muf5xkkk.fsf@yahoo.com>

Mike Marchywka <marchywka at hotmail.com> writes in part,
replying to Peter Flynn:

>> I'm not clear what "explicit" XML is (as opposed to what?)
>
> Anything that is XML but called something different, mostly things ending in ML  :) 

Perhaps you mean a specific XML document type.

> . . .

> I had to pick a word for the style- if you try to read it you can't just sit
> down and read it you have all the "XML junk" to read around. See beloe but
> the latex-like syntax does not imply specific presentation of the info 
> it just is better visually organized even before typesetting into a specific
> rendition.  

It is correct that LaTeX-Like syntax with discipline can
be used to write an instance under an XML document type.
(This is implemented in the GELLMU project.)

A somewhat less-disciplined LaTeX-Like syntax can be used
to write an instance under an SGML document type that is
capable of being automatically transformed to a closely
related XML document type.

Aside from the "comfort" of LaTeX-like notation, in both
cases one big advantage is the possibility of emulating
\newcommand, including \newcommand with arguments, in
pre-processing.  E.g., when writing for HTML

       \newcommand{\href}[2]{\a[href="#1"]{#2}}

Additionally and optionally, in this context an SGML (or
XML) element having a fixed sequence of subelements can be
spawned from a LaTeX-like command having positional
arguments.

                              -- Bill


Email: hmwlfsr at yahoo.com
       gellmu at gmail.com
https://www.facebook.com/william.f.hammond
http://www.albany.edu/~hammond/


From hmwlfsr at yahoo.com  Mon Sep 16 00:43:18 2019
From: hmwlfsr at yahoo.com (William F Hammond)
Date: Sun, 15 Sep 2019 15:43:18 -0700
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <2bcde6b2-7187-60a6-c0eb-e062238c4f41@silmaril.ie> (Peter Flynn's
 message of "Sun, 15 Sep 2019 22:49:47 +0100")
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
 <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <2bcde6b2-7187-60a6-c0eb-e062238c4f41@silmaril.ie>
Message-ID: <87imptxjsp.fsf@yahoo.com>

Peter Flynn <peter at silmaril.ie> writes in part:

> . . .
> Mostly, yes. It's pretty trivial to write XSLT to convert the XML to
>
> \documentclass{book}
> \usepackage{celt}
> \begin{document}
> \title{A Brife description of Ireland: made in this yeere.
> 	  1589. By Robert Payne}
> . . .

LaTeX written this way will likely be harder for a human to
read than LaTeX written by a human.  For example, every
instance of \TeX must, absent clumsy look-ahead, be written
as \TeX{}, and every newline in an XML <para> must be
converted to a space with the result that a <para> of, say,
10 lines, will, absent an algorithm for line width control,
come out as a single very long line in translated LaTeX.

My other observation here is that there are libraries in
various well-known computer languages that facilitate
translating SGML or XML document types to other document
types or formats.  I prefer Perl.

                              -- Bill


Email: hmwlfsr at yahoo.com
       gellmu at gmail.com
https://www.facebook.com/william.f.hammond
http://www.albany.edu/~hammond/

From peter at silmaril.ie  Mon Sep 16 10:20:40 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Mon, 16 Sep 2019 09:20:40 +0100
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <87imptxjsp.fsf@yahoo.com>
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
 <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <2bcde6b2-7187-60a6-c0eb-e062238c4f41@silmaril.ie> <87imptxjsp.fsf@yahoo.com>
Message-ID: <ab9df1e0-67d4-a506-e56a-527a8c06e296@silmaril.ie>

On 15/09/2019 23:43, William F Hammond wrote:
> Peter Flynn <peter at silmaril.ie> writes in part:
> 
>> [...]
> LaTeX written this way will likely be harder for a human to read than
> LaTeX written by a human. For example, every instance of \TeX must,
> absent clumsy look-ahead, be written as \TeX{}, and every newline in
> an XML <para> must be converted to a space with the result that a
> <para> of, say, 10 lines, will, absent an algorithm for line width
> control, come out as a single very long line in translated LaTeX.
> 
> My other observation here is that there are libraries in various
> well-known computer languages that facilitate translating SGML or XML
> document types to other document types or formats. I prefer Perl.

This is the normal procedure. I gave up writing raw LaTeX for anything 
except trivial instances nearly 20 years ago when it became clear that 
XML was the best bet for preserving information. So I write in XML ? of 
one kind or another ? and transform it to LaTeX when I want a PDF, or to 
HTML if I want a web site, or Markdown if I want a portable document 
that will work in many different environments. Or even to Word or Libre 
Office, now that it's XML inside, so I can give an editable copy to a 
wordprocessor user.

The reverse is also true: given proper style control, a Word or LO 
document can be converted to LaTeX so you can get decent quality PDF. 
LaTeX is ? in effect ? an API for creating PDFs. Look Mommy No Hands!

So yes, all instances of my &LaTeX; become \LaTeX{}, and I don't bother 
about pretty-printed LaTeX or HTML files, because they never get seen by 
a human, so no-one is going to be bothered by lines 500 characters long 
or more.

There are libraries for most languages, plus the XSLT language which is 
explicitly for XML. You can even do it with the onsgmls parser and 
output ESIS, which you can turn into LaTeX using awk or Perl or Python 
or whatever.

Peter

From marchywka at hotmail.com  Mon Sep 16 11:04:55 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 16 Sep 2019 09:04:55 +0000
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <ab9df1e0-67d4-a506-e56a-527a8c06e296@silmaril.ie>
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
 <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <2bcde6b2-7187-60a6-c0eb-e062238c4f41@silmaril.ie> <87imptxjsp.fsf@yahoo.com>
 <ab9df1e0-67d4-a506-e56a-527a8c06e296@silmaril.ie>
Message-ID: <DM6PR08MB60428439ECA1F7CC78677E4CBE8C0@DM6PR08MB6042.namprd08.prod.outlook.com>

On Mon, Sep 16, 2019 at 09:20:40AM +0100, Peter Flynn wrote:
> On 15/09/2019 23:43, William F Hammond wrote:
> > Peter Flynn <peter at silmaril.ie> writes in part:
> > 
> > > [...]
> > LaTeX written this way will likely be harder for a human to read than
> > LaTeX written by a human. For example, every instance of \TeX must,
> > absent clumsy look-ahead, be written as \TeX{}, and every newline in
> > an XML <para> must be converted to a space with the result that a
> > <para> of, say, 10 lines, will, absent an algorithm for line width
> > control, come out as a single very long line in translated LaTeX.
> > 
> > My other observation here is that there are libraries in various
> > well-known computer languages that facilitate translating SGML or XML
> > document types to other document types or formats. I prefer Perl.
> 
> This is the normal procedure. I gave up writing raw LaTeX for anything
> except trivial instances nearly 20 years ago when it became clear that XML
> was the best bet for preserving information. So I write in XML ? of one kind
> or another ? and transform it to LaTeX when I want a PDF, or to HTML if I
> want a web site, or Markdown if I want a portable document that will work in
> many different environments. Or even to Word or Libre Office, now that it's
> XML inside, so I can give an editable copy to a wordprocessor user.

Yeah if they are equivalent and reversibly convertable it does not
matter much which one the human reads and write. Anyone use JSON like files for anything? 

Originally I was trying to contrast the idea of latex-like emails
with say html. If you wanted to read the stuff that came in over the wire
( ignoring transfer encoding etc lol )  because rendering
was not worth the effort, the latex would likely be easier and then
since it has more logical strcuture you could modify the layout 
as I have been playing with.  

> 
> The reverse is also true: given proper style control, a Word or LO document
> can be converted to LaTeX so you can get decent quality PDF. LaTeX is ? in
> effect ? an API for creating PDFs. Look Mommy No Hands!
> 
> So yes, all instances of my &LaTeX; become \LaTeX{}, and I don't bother
> about pretty-printed LaTeX or HTML files, because they never get seen by a
> human, so no-one is going to be bothered by lines 500 characters long or
> more.
> 
> There are libraries for most languages, plus the XSLT language which is
> explicitly for XML. You can even do it with the onsgmls parser and output
> ESIS, which you can turn into LaTeX using awk or Perl or Python or whatever.
> 
> Peter

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From peter at silmaril.ie  Mon Sep 16 12:02:17 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Mon, 16 Sep 2019 11:02:17 +0100
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <DM6PR08MB60428439ECA1F7CC78677E4CBE8C0@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
 <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <2bcde6b2-7187-60a6-c0eb-e062238c4f41@silmaril.ie> <87imptxjsp.fsf@yahoo.com>
 <ab9df1e0-67d4-a506-e56a-527a8c06e296@silmaril.ie>
 <DM6PR08MB60428439ECA1F7CC78677E4CBE8C0@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <11c2c12b-03dd-5b8a-2647-a155091c7b05@silmaril.ie>

On 16/09/2019 10:04, Mike Marchywka wrote:
> Yeah if they are equivalent and reversibly convertable it does not
> matter much which one the human reads and write. 

The reversibly convertible shouldn't be needed if the master XML file is 
safely preserved. But there are war stories about people who no longer 
have the original, and only the (eg) LaTeX or HTML derivative, and want 
to reverse-engineer the XML.

> Anyone use JSON like files for anything?

You can't use JSON for normal continuous text in Mixed Content. JSON is 
largely unreadable by humans, as it's intended as a feed source for 
programs. But for categorical rectangular data (eg spreadsheets, 
database tables, etc) it's probably more tractable than XML. See the 
article in the XML FAQ at http://xml.silmaril.ie/json.html

> Originally I was trying to contrast the idea of latex-like emails 
> with say html. If you wanted to read the stuff that came in over the
> wire (ignoring transfer encoding etc lol )  because rendering was not
> worth the effort, the latex would likely be easier and then since it
> has more logical strcuture you could modify the layout as I have been
> playing with.

I think mutt can use LaTeX to render emails.

Peter

From hmwlfsr at yahoo.com  Mon Sep 16 19:31:41 2019
From: hmwlfsr at yahoo.com (William F Hammond)
Date: Mon, 16 Sep 2019 10:31:41 -0700
Subject: www type bibtex entries - generating bibtex for webpages + prior
 theme.
In-Reply-To: <DM6PR08MB60428439ECA1F7CC78677E4CBE8C0@DM6PR08MB6042.namprd08.prod.outlook.com>
 (Mike Marchywka's message of "Mon, 16 Sep 2019 09:04:55 +0000")
References: <DM6PR08MB60424C779CA562DFAA42F29EBEB20@DM6PR08MB6042.namprd08.prod.outlook.com>
 <606ed16c-41b9-2f68-6bfc-d94abd01b1db@silmaril.ie>
 <DM6PR08MB6042305579C571BE61CB4B53BE8D0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <2bcde6b2-7187-60a6-c0eb-e062238c4f41@silmaril.ie>
 <87imptxjsp.fsf@yahoo.com>
 <ab9df1e0-67d4-a506-e56a-527a8c06e296@silmaril.ie>
 <DM6PR08MB60428439ECA1F7CC78677E4CBE8C0@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <87blvkxi4i.fsf@yahoo.com>

Mike Marchywka <marchywka at hotmail.com> writes in part:

> Yeah if they are equivalent and reversibly convertable it does not
> matter much which one the human reads and write.  ...

I don't think I've seen candidates for fully reversible
convertability in this thread.   :-)


                           -- Bill



From didier at didierverna.net  Tue Sep 17 17:47:04 2019
From: didier at didierverna.net (Didier Verna)
Date: Tue, 17 Sep 2019 17:47:04 +0200
Subject: About boundary characters
Message-ID: <m1pnjzx6vb.fsf@uzeb.lrde.epita.fr>


  Hello,

I have several questions about boundary characters in the TFM format.

1. if there is a "right boundary character" in a font, it has a code
   (maybe outside [bc,ec]). So far so good. However, the description of
   this format only mentions /a/ left boundary character, and apparently
   no code for it. I don't really understand why. Is it the same as the
   right one (in which case I guess we'd have [word1 B word2] and not
   [word1 R L word2] as I first imagined.

2. I found many fonts in which the right boundary character actually
   exists, and has non zero metrics. On the other hand, the TFM
   description claims that these characters do not appear in the output.
   So why having existing characters as boundary ones?

3. Finally, the right boundary character is specified by a special
   /first/ lig/kern instruction, and the left by a special /last/
   lig/kern instruction. However, nothing is said about the case where
   the lig/kern table is of length 1 (meaning first = last). TFTOPL
   doesn't seem to care. So I wonder if that situation makes any sense
   (I haven't checked for fonts like this yet).

Thanks!

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From karl at freefriends.org  Thu Sep 19 00:42:24 2019
From: karl at freefriends.org (Karl Berry)
Date: Wed, 18 Sep 2019 16:42:24 -0600
Subject: About boundary characters
In-Reply-To: <m1pnjzx6vb.fsf@uzeb.lrde.epita.fr>
Message-ID: <201909182242.x8IMgO46028353@freefriends.org>

Hi Didier,

    I have several questions about boundary characters in the TFM format.

I surmise experimentation is necessary. The "specifications", such as
they are, are insufficient, so far as I can tell. (Since they were added
in the 1989 update, Don had only a tiny amount of space in which to
describe them.)

It's never been clear to me what TeX actually does with boundary
characters (so maybe their metrics do not matter?). I believe that they
are only relevant in the ligkern table, but that's about all I know.
I read the descriptions in the {mf,tex}{book,.web}, as I suppose you
have also, but clarity is not forthcoming. As far as I know there is no
other significant source of information.

Doug, I surmise you may have more knowledge than anyone? But maybe your
re-implementation was too long ago now :).

It would be nice to have a thorough article for TUGboat on boundary
characters.

As for what existing fonts may or may not do with them, (1) it's hard to
say anything without knowing what fonts you are talking about, and (2) I
wouldn't take it too seriously. Maybe the font creators did lots of
experiments and created boundary chars the way they did for specific
reason, but IMHO it's equally likely that they simply followed some
examples, tried to do what they thought made sense, and whatever
happened, happened. --best, karl.

From doug at mathemaesthetics.com  Thu Sep 19 02:21:48 2019
From: doug at mathemaesthetics.com (Doug McKenna)
Date: Wed, 18 Sep 2019 18:21:48 -0600 (MDT)
Subject: About boundary characters
In-Reply-To: <201909182242.x8IMgO46028353@freefriends.org>
References: <201909182242.x8IMgO46028353@freefriends.org>
Message-ID: <880047533.2755423.1568852508262.JavaMail.zimbra@mathemaesthetics.com>

Karl, Didier -

My code faithfully duplicates DEK's algorithm, which his famous comment about "premature optimization" does not apply to, because his code for appending characters to the layout was turned into "post-matured" spaghetti.  I never tried to rewind its clock, so my C code is functionally the same pasta also, though it is easier to read IMNSHO.

Looking at my comments and code, written a few years back during my Vulcan mind-meld with the WEB source, it seems that a boundary character is used to prevent ligatures and kerns from occurring when two or more adjacent characters are in different fonts.

The thing is, there's only one boundary character per TFM font.  Therefore, it kind of by definition has to serve as some kind of generic flag in multiple situations.  There's no express metrics stored for a boundary character per se in the TFM, but if it's a legal character code (between 0 and 255 for TFM), then presumably that character in the font can have metrics, usually of zero width, but not precluded from having non-zero width.

Unfortunately, a character with zero width is formally considered missing from the TFM font, in order to save space by not storing some other bit somewhere in the font data that would declare a character code between |bc| and |ec| as missing (see the char_exists() macro in the WEB source; it tests for positive width).

Because of that little non-orthogonal problem, there's the TFM font's so-called "false" boundary character, which is synthesized when the TFM file is read in.  The false boundary character is the boundary character, unless the boundary character's width is non-zero, in which case the false boundary character is set to a not-a-character value.  The comment in WEB source says it's to prevent "spurious ligatures".  This smells like a hack to me, but perhaps it's elegant.  Again, the problem being solved (I think) is how to introduce a character of zero width into the layout to break a kern or ligature, rather than having it flagged during input as missing from the font before any attempt to append.

DEK uses the phrase "pseudo-ligatures" in a comment, but he never defines the term, and the phrase is not used anywhere else in the TeX code that I can find, so that's not much help.

Anyway, FWIW after a quick flyby of the code.  Because of the complicated nature of the ligature stack and the ligature/kern "program" in the TFM file, I'm probably not explaining stuff going on there very well.  Indeed, the above may be quite wrong.

It seems post-mature optimization is kind of evil too. :-)


Doug McKenna



----- Original Message -----
From: "Karl Berry" <karl at freefriends.org>
To: "Didier Verna" <didier at didierverna.net>
Cc: "texhax" <texhax at tug.org>
Sent: Wednesday, September 18, 2019 4:42:24 PM
Subject: Re: About boundary characters

Hi Didier,

    I have several questions about boundary characters in the TFM format.

I surmise experimentation is necessary. The "specifications", such as
they are, are insufficient, so far as I can tell. (Since they were added
in the 1989 update, Don had only a tiny amount of space in which to
describe them.)

It's never been clear to me what TeX actually does with boundary
characters (so maybe their metrics do not matter?). I believe that they
are only relevant in the ligkern table, but that's about all I know.
I read the descriptions in the {mf,tex}{book,.web}, as I suppose you
have also, but clarity is not forthcoming. As far as I know there is no
other significant source of information.

Doug, I surmise you may have more knowledge than anyone? But maybe your
re-implementation was too long ago now :).

It would be nice to have a thorough article for TUGboat on boundary
characters.

As for what existing fonts may or may not do with them, (1) it's hard to
say anything without knowing what fonts you are talking about, and (2) I
wouldn't take it too seriously. Maybe the font creators did lots of
experiments and created boundary chars the way they did for specific
reason, but IMHO it's equally likely that they simply followed some
examples, tried to do what they thought made sense, and whatever
happened, happened. --best, karl.

From rokicki at gmail.com  Thu Sep 19 02:31:38 2019
From: rokicki at gmail.com (Tomas Rokicki)
Date: Wed, 18 Sep 2019 17:31:38 -0700
Subject: About boundary characters
In-Reply-To: <880047533.2755423.1568852508262.JavaMail.zimbra@mathemaesthetics.com>
References: <201909182242.x8IMgO46028353@freefriends.org>
 <880047533.2755423.1568852508262.JavaMail.zimbra@mathemaesthetics.com>
Message-ID: <CAGia-=VugJ1UUydr4vqbPF1LLFW2c2hqDD7Xu16yfj+5GG=aSw@mail.gmail.com>

A minor correction:  characters *can* have zero width.  A character
with a zero *index* to the width table does not exist, but one of the
other entries in the width table can certainly be zero.

(I don't know if any such characters exist, off-hand.)

-tom

On Wed, Sep 18, 2019 at 5:22 PM Doug McKenna <doug at mathemaesthetics.com>
wrote:

> Karl, Didier -
>
> My code faithfully duplicates DEK's algorithm, which his famous comment
> about "premature optimization" does not apply to, because his code for
> appending characters to the layout was turned into "post-matured"
> spaghetti.  I never tried to rewind its clock, so my C code is functionally
> the same pasta also, though it is easier to read IMNSHO.
>
> Looking at my comments and code, written a few years back during my Vulcan
> mind-meld with the WEB source, it seems that a boundary character is used
> to prevent ligatures and kerns from occurring when two or more adjacent
> characters are in different fonts.
>
> The thing is, there's only one boundary character per TFM font.
> Therefore, it kind of by definition has to serve as some kind of generic
> flag in multiple situations.  There's no express metrics stored for a
> boundary character per se in the TFM, but if it's a legal character code
> (between 0 and 255 for TFM), then presumably that character in the font can
> have metrics, usually of zero width, but not precluded from having non-zero
> width.
>
> Unfortunately, a character with zero width is formally considered missing
> from the TFM font, in order to save space by not storing some other bit
> somewhere in the font data that would declare a character code between |bc|
> and |ec| as missing (see the char_exists() macro in the WEB source; it
> tests for positive width).
>
> Because of that little non-orthogonal problem, there's the TFM font's
> so-called "false" boundary character, which is synthesized when the TFM
> file is read in.  The false boundary character is the boundary character,
> unless the boundary character's width is non-zero, in which case the false
> boundary character is set to a not-a-character value.  The comment in WEB
> source says it's to prevent "spurious ligatures".  This smells like a hack
> to me, but perhaps it's elegant.  Again, the problem being solved (I think)
> is how to introduce a character of zero width into the layout to break a
> kern or ligature, rather than having it flagged during input as missing
> from the font before any attempt to append.
>
> DEK uses the phrase "pseudo-ligatures" in a comment, but he never defines
> the term, and the phrase is not used anywhere else in the TeX code that I
> can find, so that's not much help.
>
> Anyway, FWIW after a quick flyby of the code.  Because of the complicated
> nature of the ligature stack and the ligature/kern "program" in the TFM
> file, I'm probably not explaining stuff going on there very well.  Indeed,
> the above may be quite wrong.
>
> It seems post-mature optimization is kind of evil too. :-)
>
>
> Doug McKenna
>
>
>
> ----- Original Message -----
> From: "Karl Berry" <karl at freefriends.org>
> To: "Didier Verna" <didier at didierverna.net>
> Cc: "texhax" <texhax at tug.org>
> Sent: Wednesday, September 18, 2019 4:42:24 PM
> Subject: Re: About boundary characters
>
> Hi Didier,
>
>     I have several questions about boundary characters in the TFM format.
>
> I surmise experimentation is necessary. The "specifications", such as
> they are, are insufficient, so far as I can tell. (Since they were added
> in the 1989 update, Don had only a tiny amount of space in which to
> describe them.)
>
> It's never been clear to me what TeX actually does with boundary
> characters (so maybe their metrics do not matter?). I believe that they
> are only relevant in the ligkern table, but that's about all I know.
> I read the descriptions in the {mf,tex}{book,.web}, as I suppose you
> have also, but clarity is not forthcoming. As far as I know there is no
> other significant source of information.
>
> Doug, I surmise you may have more knowledge than anyone? But maybe your
> re-implementation was too long ago now :).
>
> It would be nice to have a thorough article for TUGboat on boundary
> characters.
>
> As for what existing fonts may or may not do with them, (1) it's hard to
> say anything without knowing what fonts you are talking about, and (2) I
> wouldn't take it too seriously. Maybe the font creators did lots of
> experiments and created boundary chars the way they did for specific
> reason, but IMHO it's equally likely that they simply followed some
> examples, tried to do what they thought made sense, and whatever
> happened, happened. --best, karl.
>


-- 
--  http://cube20.org/  --  http://golly.sf.net/  --
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190918/e607b48c/attachment.html>

From bnb at tug.org  Thu Sep 19 03:30:50 2019
From: bnb at tug.org (barbara beeton)
Date: Thu, 19 Sep 2019 03:30:50 +0200 (CEST)
Subject: About boundary characters
In-Reply-To: <CAGia-=VugJ1UUydr4vqbPF1LLFW2c2hqDD7Xu16yfj+5GG=aSw@mail.gmail.com>
References: <201909182242.x8IMgO46028353@freefriends.org>
 <880047533.2755423.1568852508262.JavaMail.zimbra@mathemaesthetics.com>
 <CAGia-=VugJ1UUydr4vqbPF1LLFW2c2hqDD7Xu16yfj+5GG=aSw@mail.gmail.com>
Message-ID: <alpine.LRH.2.21.1909190320520.21696@tug.org>

There's one genuine zero-width character that I can think of:
the "\not" character in the cmsy font.  Check it out in the
comprehensive symbols list (p.232 in the version I'm looking at):
   "... like \not, puts a slash over the subsequent mathematical
    symbol."
 						-- bb

On Wed, 18 Sep 2019, Tomas Rokicki wrote:

> A minor correction:? characters *can* have zero width.? A characterwith a
> zero *index* to the width table does not exist, but one of the
> other entries in the width table can certainly be zero.
> 
> (I don't know if any such characters exist, off-hand.)
> 
> -tom
> 
> [...]

From didier at didierverna.net  Thu Sep 19 12:13:55 2019
From: didier at didierverna.net (Didier Verna)
Date: Thu, 19 Sep 2019 12:13:55 +0200
Subject: About boundary characters
In-Reply-To: <880047533.2755423.1568852508262.JavaMail.zimbra@mathemaesthetics.com>
 (Doug McKenna's message of "Wed, 18 Sep 2019 18:21:48 -0600 (MDT)")
References: <201909182242.x8IMgO46028353@freefriends.org>
 <880047533.2755423.1568852508262.JavaMail.zimbra@mathemaesthetics.com>
Message-ID: <m2v9toa90c.fsf@didierverna.net>

Doug McKenna <doug at mathemaesthetics.com> wrote:

> it seems that a boundary character is used to prevent ligatures and
> kerns from occurring when two or more adjacent characters are in
> different fonts.

> There's no express metrics stored for a boundary character per se in
> the TFM, but if it's a legal character code (between 0 and 255 for
> TFM), then presumably that character in the font can have metrics,
> usually of zero width, but not precluded from having non-zero width.

  I found 24602 fonts in TeX Live 2019 with a non-zero width RBC. Here
  are a couple of examples.

Comfortaa-Bold-LGR (looks like it's a real character; it also has an height):
CODE                  = 0
DEPTH                 = 0
EXTENSION-RECIPE      = NIL
HEIGHT                = 339739/1048576
ITALIC-CORRECTION     = 27263/524288
NEXT-LARGER-CHARACTER = NIL
WIDTH                 = 409993/1048576

In this font, there are kerning instructions with both this character at
the left and right position. So I'm wondering whether it is really
appropriate to call it "right" boundary character.

There is one ligature with it at the left position. Wait, the right
boundary character, at the left position?? ;-):
0 . 45
COMPOSITE = 127
DELETE-AFTER  = T
DELETE-BEFORE = T
PASS-OVER     = 0

There is also one ligature with it at the right position. Wait, "don't
delete the RBC", which is not supposed to be typeset anyway??
115 . 0
COMPOSITE     = 99
DELETE-AFTER  = NIL (??)
DELETE-BEFORE = T
PASS-OVER     = 0

This font is for greek. I read something about different forms of
sigmas, which may be related. I still don't see why the RBC would have
an height, unless it is actually typeset in some circumstances (unless
of course, the character metrics doesn't make any sense, or doesn't
really matter).

Apart from that, the vast majority of the other fonts seems to provide
RBCs with widths, but no height or depth. Random example:
tfm/public/poiretone/. These ones have kerning instructions for the RBC.
So now, my suspicion is that even if the boundary characters are not
typeset, their width is taken into account in the output.


> Because of that little non-orthogonal problem, there's the TFM font's
> so-called "false" boundary character, which is synthesized when the
> TFM file is read in. The false boundary character is the boundary
> character, unless the boundary character's width is non-zero, in which
> case the false boundary character is set to a not-a-character value.

  Oh my.

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From didier at didierverna.net  Thu Sep 19 14:21:07 2019
From: didier at didierverna.net (Didier Verna)
Date: Thu, 19 Sep 2019 14:21:07 +0200
Subject: About boundary characters
In-Reply-To: <m2v9toa90c.fsf@didierverna.net> (Didier Verna's message of "Thu, 
 19 Sep 2019 12:13:55 +0200")
References: <201909182242.x8IMgO46028353@freefriends.org>
 <880047533.2755423.1568852508262.JavaMail.zimbra@mathemaesthetics.com>
 <m2v9toa90c.fsf@didierverna.net>
Message-ID: <m2r24ca34c.fsf@didierverna.net>

I wrote:

>   I found 24602 fonts in TeX Live 2019 with a non-zero width RBC. Here
>   are a couple of examples.

  Finally, I found 199 fonts with lig/kern instructions for a "left
boundary character", whatever than means (special last instruction in
the lig/kern array). Looking at the output of tftopl for a couple of
those, it appears that this program lists those instructions under the
(unique) BOUNDARYCHAR label, which happens to also be the right boundary
character. I've tested all the TeX Live fonts, and apparently, there are
no fonts for which a lig/kern program for a left boundary character
would be defined (special /last/ instruction in the lig/kern array)
without also having a definition for a right boundary character (special
/first/ instruction in the lig/kern array).

  Conclusion: I'm almost convinced now that the boundary character is
indeed unique, and that the terminology in TeX: the Program [545],
making a difference between left and right, is misleading.

-- 
Resistance is futile. You will be jazzimilated.

Lisp, Jazz, A?kido: http://www.didierverna.info


From marchywka at hotmail.com  Sun Sep 22 18:50:34 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sun, 22 Sep 2019 16:50:34 +0000
Subject: cleaning up bibtex files. 
Message-ID: <DM6PR08MB6042F8F3293C213B1CCB6218BE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>


I had various versions and bugs in my bibtex downloading scripts
so I wrote some code to go through and clean them up. 
In the process of accumulating them however it looks like there is a lot
of variation in how they are supplied by publishers.

I guess I was curious if there is some prefered format as long as I
have gone to this much effort. My biggest concern was making sure everything
I got off the web was indicated as such with a url and I wanted to preserve
download time to retrace what I was doing. I put all of this in "comments"
but curious if putting it into the bibtex would hurt anything.

In particular, the field values seem to randomly be quoted or braced and
I just made them all braced. Does this lose something?

For example, I output stuff like this,

% programmatically fixed probably bu toobib
% loaded from test2.bib written on 2019-09-22:11:25:04



% srcurl:  https://www.pnas.org/content/pnas/111/28/10257.full.pdf
% citeurl:  http://api.crossref.org/works/10.1073/pnas.1409284111/transform/appl
ication/x-bibtex
% med2bib comment:  handledoi
% date  Wed Feb 6 01:02:49 UTC 2019


@article{Nikoh_2014,
    doi = {10.1073/pnas.1409284111},
    url = {https://doi.org/10.1073\%2Fpnas.1409284111},
    year = {2014},
    month = {jun},
    publisher = {Proceedings of the National Academy of Sciences},
    volume = {111},
    number = {28},
    pages = {10257--10262},
    author = {N. Nikoh and T. Hosokawa and M. Moriyama and K. Oshima and M. Hatt
ori and T. Fukatsu},
    title = {Evolutionary origin of insect-Wolbachia nutritional mutualism},
    journal = {Proceedings of the National Academy of Sciences}
}


@article{KRAMER201895,
    title = {Wolbachia, doxycycline and macrocyclic lactones: New prospects in t
he treatment of canine heartworm disease},
    journal = {Veterinary Parasitology},
    volume = {254},
    pages = {95 - 97},
    year = {2018},
    issn = {0304-4017},
    doi = {https://doi.org/10.1016/j.vetpar.2018.03.005},
    url = {http://www.sciencedirect.com/science/article/pii/S0304401718301055},
    author = {L. Kramer and S. Crosara and G. Gnudi and M. Genchi and C. Mangia 
and A. Viglietti and C. Quintavalla},
    keywords = {, , Doxycycline, Macrocyclic lactones}
}


and an excerpt of the diff output gives almost all of the input, 
often due to a quote to brace change. 
( and I went to a lot of effort to perserve the field order  instead of alpha lol ) 

diff -b test2.bib check2.bib


< title = "Wolbachia, doxycycline and macrocyclic lactones: New prospects in the
 treatment of canine heartworm disease",
< journal = "Veterinary Parasitology",
< volume = "254",
< pages = "95 - 97",
< year = "2018",
< issn = "0304-4017",
< doi = "https://doi.org/10.1016/j.vetpar.2018.03.005",
< url = "http://www.sciencedirect.com/science/article/pii/S0304401718301055",
< author = "L. Kramer and S. Crosara and G. Gnudi and M. Genchi and C. Mangia an
d A. Viglietti and C. Quintavalla",
< keywords = ", , Doxycycline, Macrocyclic lactones"


I would imagine there are other utilities that clean these up but I also wanted to
structure the comments in a custom way although I could just include the
srcurl as a bibtex entry field. 
I started to write a command line interactive fixer and thought if there were other 
common problems I could include all of that now.

Thanks. 



-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From peter at silmaril.ie  Sun Sep 22 19:07:11 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Sun, 22 Sep 2019 18:07:11 +0100
Subject: cleaning up bibtex files.
In-Reply-To: <DM6PR08MB6042F8F3293C213B1CCB6218BE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB6042F8F3293C213B1CCB6218BE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <130c8af5-0760-2e8b-473f-3b03126f9811@silmaril.ie>

On 22/09/2019 17:50, Mike Marchywka wrote:
[...]
> I guess I was curious if there is some preferred format as long as I
> have gone to this much effort. My biggest concern was making sure 
> everything I got off the web was indicated as such with a url and I
> wanted to preserve download time to retrace what I was doing. I put
> all of this in "comments" but curious if putting it into the bibtex
> would hurt anything.

I don't think so, but this is one of many reasons I store all my 
references in DocBook XML, and run an XSLT script to create BiBTeX files 
when I need to. I try to pick "EndNote XML" export format from web site 
and biblio applications wherever possible because I have a script to 
handle that.

That way I *know* everything is named and labelled correctly, and if 
biblatex formatters change how the use fields, I can easily modify the 
script and just regenerate the files. If I had to generate old BiBTeX 
files, I could also do that.

> In particular, the field values seem to randomly be quoted or braced
> and I just made them all braced. Does this lose something?

Not as far as I know. The rule is, if the field value is an integer (eg 
a year) it doesn't need braces, otherwise it does.

Peter

From marchywka at hotmail.com  Sun Sep 22 19:25:27 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sun, 22 Sep 2019 17:25:27 +0000
Subject: cleaning up bibtex files.
In-Reply-To: <130c8af5-0760-2e8b-473f-3b03126f9811@silmaril.ie>
References: <DM6PR08MB6042F8F3293C213B1CCB6218BE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <130c8af5-0760-2e8b-473f-3b03126f9811@silmaril.ie>
Message-ID: <DM6PR08MB60420D98E5C8D28F46ABCC7BBE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>

On Sun, Sep 22, 2019 at 06:07:11PM +0100, Peter Flynn wrote:
> On 22/09/2019 17:50, Mike Marchywka wrote:
> [...]
> > I guess I was curious if there is some preferred format as long as I
> > have gone to this much effort. My biggest concern was making sure
> > everything I got off the web was indicated as such with a url and I
> > wanted to preserve download time to retrace what I was doing. I put
> > all of this in "comments" but curious if putting it into the bibtex
> > would hurt anything.
> 
> I don't think so, but this is one of many reasons I store all my
> references in DocBook XML, and run an XSLT script to create BiBTeX files
> when I need to. I try to pick "EndNote XML" export format from web site
> and biblio applications wherever possible because I have a script to
> handle that.

Maybe I just hate XML-like stuff but right now it would just be another 
level of translation. The bibtex format looks perfectly general
and I can use it as a primary source effectively but just wanted
to check on conventions and details for normal usage. 

This effort also let me write some parsing logic ( although probably
anyone would normally write syntax diagrams and generate the partsing code too )
to see what is going on. 

> 
> That way I *know* everything is named and labelled correctly, and if
> biblatex formatters change how the use fields, I can easily modify the
> script and just regenerate the files. If I had to generate old BiBTeX
> files, I could also do that.
>

My solution here was to presere the download url's as I can just 
take all of them and refetch stuff although many as-received did need
to be cleaned up ( I've had a problem with url encoding of links etc and
that stupid percent thing caused some issues and if xml does not care
about that some other char would make a mess LOL  ).

 I don't think there is more reason to have more confidence in XML
than the bib format once you have set everything up. 

 
> > In particular, the field values seem to randomly be quoted or braced
> > and I just made them all braced. Does this lose something?
> 
> Not as far as I know. The rule is, if the field value is an integer (eg
> a year) it doesn't need braces, otherwise it does.
> 
> Peter

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From peter at silmaril.ie  Sun Sep 22 23:41:54 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Sun, 22 Sep 2019 22:41:54 +0100
Subject: cleaning up bibtex files.
In-Reply-To: <DM6PR08MB60420D98E5C8D28F46ABCC7BBE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB6042F8F3293C213B1CCB6218BE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <130c8af5-0760-2e8b-473f-3b03126f9811@silmaril.ie>
 <DM6PR08MB60420D98E5C8D28F46ABCC7BBE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <6c575816-99c6-0839-8d64-b590a810d7c6@silmaril.ie>

On 22/09/2019 18:25, Mike Marchywka wrote:
[...]
> Maybe I just hate XML-like stuff but right now it would just be
> another level of translation.

Many people do, and yes it is. That's a price I'm prepared to pay for a
file format that can be checked for syntactic verification 
independently.  Plus I'm using this data for more than just biblatex.

> The bibtex format looks perfectly general and I can use it as a
> primary source effectively but just wanted to check on conventions
> and details for normal usage.

These should be in any book on LaTeX that covers BiBTeX/biblatex.

> This effort also let me write some parsing logic (although probably 
> anyone would normally write syntax diagrams and generate the
> parsing code too) to see what is going on.

Always a good exercise. I'm just lazy.

> My solution here was to preseve the download urls as I can just
> take all of them and refetch stuff although many as-received did need
> to be cleaned up (I've had a problem with url encoding of links etc and
> that stupid percent thing caused some issues and if xml does not care
> about that some other char would make a mess LOL).

Browsers are very forgiving of urlencoding errors. Other systems are 
not. XML doesn't care unless you try to resolve the link or specify the 
datatype. Nor does biblatex/BiBTeX AFAIK, but maybe some formatters 
check it.

> I don't think there is more reason to have more confidence in XML
> than the bib format once you have set everything up.

Not really, unless you're using the data for another purpose, like 
running queries on it, or formatting outputs other than LaTeX (eg 
Markdown, HTNL, etc).

Peter

From marchywka at hotmail.com  Mon Sep 23 18:28:55 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 23 Sep 2019 16:28:55 +0000
Subject: cleaning up bibtex files.
In-Reply-To: <6c575816-99c6-0839-8d64-b590a810d7c6@silmaril.ie>
References: <DM6PR08MB6042F8F3293C213B1CCB6218BE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <130c8af5-0760-2e8b-473f-3b03126f9811@silmaril.ie>
 <DM6PR08MB60420D98E5C8D28F46ABCC7BBE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <6c575816-99c6-0839-8d64-b590a810d7c6@silmaril.ie>
Message-ID: <DM6PR08MB604285A578B14FAAF4F2F400BE850@DM6PR08MB6042.namprd08.prod.outlook.com>

On Sun, Sep 22, 2019 at 10:41:54PM +0100, Peter Flynn wrote:
> On 22/09/2019 18:25, Mike Marchywka wrote:
> [...]
> > Maybe I just hate XML-like stuff but right now it would just be
> > another level of translation.
> 
> Many people do, and yes it is. That's a price I'm prepared to pay for a
> file format that can be checked for syntactic verification
> independently.  Plus I'm using this data for more than just biblatex.
> 
> > The bibtex format looks perfectly general and I can use it as a
> > primary source effectively but just wanted to check on conventions
> > and details for normal usage.
> 
> These should be in any book on LaTeX that covers BiBTeX/biblatex.

Thanks, I thought there may be a reference but hard to tell from reality :)

Any idea with the pages here or is this generated incorrectly? Not sure
why this would be right:


% srcurl:  http://www.bioscirep.org/content/ppbioscirep/38/5/BSR20180705.full.pdf
% citeurl:  http://api.crossref.org/works/10.1042/BSR20180705/transform/application/x-bibtex
% med2bib comment:  handlepdf
% date  Fri Feb 8 11:20:23 UTC 2019

@article{Ay_n_N_ez_2018,
        doi = {10.1042/bsr20180705},
        url = {https://doi.org/10.1042\%2Fbsr20180705},
        year = 2018,
        month = {aug},
        publisher = {Portland Press Ltd.},
        volume = {38},
        number = {5},
        pages = {BSR20180705},
        author = {Dolores A. Ay{\'{o}}n-N{\'{u}}{\~{n}}ez and Gladis Fragoso and Ra{\'{u}}l J. Bobes and Juan P. Laclette},
        title = {Plasminogen-binding proteins as an evasion mechanism of the host's innate immunity in infectious diseases},
        journal = {Bioscience Reports}
}


And to check for possible bug in my script I went to get it again,

wget -O xxx -S -v "http://api.crossref.org/works/10.1042/BSR20180705/transform/application/x-bibtex"
--2019-09-23 12:23:32--  http://api.crossref.org/works/10.1042/BSR20180705/transform/application/x-bibtex
Resolving api.crossref.org (api.crossref.org)... 208.254.38.72
Connecting to api.crossref.org (api.crossref.org)|208.254.38.72|:80... connected.
HTTP request sent, awaiting response... 
  HTTP/1.1 200 OK
  Link: <http://dx.doi.org/10.1042/bsr20180705>; rel="canonical", <https://syndication.highwire.org/content/doi/10.1042/BSR20180705>; version="vor"; rel="item", <http://creativecommons.org/licenses/by/4.0/>; rel="license"
  Access-Control-Allow-Origin: *
  Access-Control-Allow-Headers: X-Requested-With
  Content-Length: 492
  Server: http-kit
  Date: Mon, 23 Sep 2019 16:23:32 GMT
  X-Rate-Limit-Limit: 50
  X-Rate-Limit-Interval: 1s
  Connection: close
Length: 492
Saving to: ?xxx?

xxx                           100%[=================================================>]     492  --.-KB/s    in 0s      

2019-09-23 12:23:32 (27.4 MB/s) - ?xxx? saved [492/492]

marchywka at happy:~/junk$ cat xxx
@article{Ay_n_N_ez_2018,
	doi = {10.1042/bsr20180705},
	url = {https://doi.org/10.1042%2Fbsr20180705},
	year = 2018,
	month = {aug},
	publisher = {Portland Press Ltd.},
	volume = {38},
	number = {5},
	pages = {BSR20180705},
	author = {Dolores A. Ay{\'{o}}n-N{\'{u}}{\~{n}}ez and Gladis Fragoso and Ra{\'{u}}l J. Bobes and Juan P. Laclette},
	title = {Plasminogen-binding proteins as an evasion mechanism of the host's innate immunity in infectious diseases},
	journal = {Bioscience Reports}
}marchywka at happy:~/junk$ 


Have I missed something stupid here?
Does this look like a correct " pages" value or problem with publisher or cross ref? 

Thanks. 




-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From Herbert.Voss at fu-berlin.de  Mon Sep 23 18:58:43 2019
From: Herbert.Voss at fu-berlin.de (Herbert Voss)
Date: Mon, 23 Sep 2019 18:58:43 +0200
Subject: cleaning up bibtex files.
In-Reply-To: <DM6PR08MB604285A578B14FAAF4F2F400BE850@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB6042F8F3293C213B1CCB6218BE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <130c8af5-0760-2e8b-473f-3b03126f9811@silmaril.ie>
 <DM6PR08MB60420D98E5C8D28F46ABCC7BBE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <6c575816-99c6-0839-8d64-b590a810d7c6@silmaril.ie>
 <DM6PR08MB604285A578B14FAAF4F2F400BE850@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <3e340bbd-e7ed-12f0-718e-3a53ca8707aa@fu-berlin.de>

Am 23.09.19 um 18:28 schrieb Mike Marchywka:


> marchywka at happy:~/junk$ cat xxx
> @article{Ay_n_N_ez_2018,
> 	doi = {10.1042/bsr20180705},
> 	url = {https://doi.org/10.1042%2Fbsr20180705},
> 	year = 2018,
> 	month = {aug},
> 	publisher = {Portland Press Ltd.},
> 	volume = {38},
> 	number = {5},
> 	pages = {BSR20180705},
> 	author = {Dolores A. Ay{\'{o}}n-N{\'{u}}{\~{n}}ez and Gladis Fragoso and Ra{\'{u}}l J. Bobes and Juan P. Laclette},
> 	title = {Plasminogen-binding proteins as an evasion mechanism of the host's innate immunity in infectious diseases},
> 	journal = {Bioscience Reports}
> }marchywka at happy:~/junk$
> 
> 
> Have I missed something stupid here?
> Does this look like a correct " pages" value or problem with publisher or cross ref?

I have no idea what pages "BSR20180705" means, but it will still be printed:

\documentclass{article}
\usepackage{biblatex,shellesc}
\addbibresource{\jobname.bib}

\begin{document}
\IfFileExists{\jobname.bib}{}{%
   \ShellEscape{	
	/usr/bin/wget -O \jobname.bib -S -v 	
	"http://api.crossref.org/works/10.1042/BSR20180705/transform/application/x-bibtex"}
}
	
\nocite{*}
\printbibliography
\end{document}

lualatex --shell-escape test
biber test
lualatex --shell-escape test


gives the attched output witrh biblatex/biber

Herbert




-------------- next part --------------
A non-text attachment was scrubbed...
Name: Bildschirmfoto vom 2019-09-23 18-56-04.png
Type: image/png
Size: 21179 bytes
Desc: not available
URL: <https://tug.org/pipermail/texhax/attachments/20190923/2bb2ecde/attachment-0001.png>

From P.Taylor at Hellenic-Institute.Uk  Mon Sep 23 19:06:06 2019
From: P.Taylor at Hellenic-Institute.Uk (Philip Taylor)
Date: Mon, 23 Sep 2019 18:06:06 +0100
Subject: cleaning up bibtex files.
In-Reply-To: <3e340bbd-e7ed-12f0-718e-3a53ca8707aa@fu-berlin.de>
References: <DM6PR08MB6042F8F3293C213B1CCB6218BE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <130c8af5-0760-2e8b-473f-3b03126f9811@silmaril.ie>
 <DM6PR08MB60420D98E5C8D28F46ABCC7BBE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <6c575816-99c6-0839-8d64-b590a810d7c6@silmaril.ie>
 <DM6PR08MB604285A578B14FAAF4F2F400BE850@DM6PR08MB6042.namprd08.prod.outlook.com>
 <3e340bbd-e7ed-12f0-718e-3a53ca8707aa@fu-berlin.de>
Message-ID: <64cd34a4-e613-cd2c-ddb5-6a4bfff23f4d@Hellenic-Institute.Uk>

Herbert Voss wrote

> I have no idea what pages "BSR20180705" means, but it will still be 
> printed

It doesn't look like a page-range to me at all, but rather 
<Journal><Year><Month><Day> (or very similar).

Philip Taylor


From marchywka at hotmail.com  Mon Sep 23 19:44:06 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 23 Sep 2019 17:44:06 +0000
Subject: cleaning up bibtex files.
In-Reply-To: <3e340bbd-e7ed-12f0-718e-3a53ca8707aa@fu-berlin.de>
References: <DM6PR08MB6042F8F3293C213B1CCB6218BE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <130c8af5-0760-2e8b-473f-3b03126f9811@silmaril.ie>
 <DM6PR08MB60420D98E5C8D28F46ABCC7BBE8A0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <6c575816-99c6-0839-8d64-b590a810d7c6@silmaril.ie>
 <DM6PR08MB604285A578B14FAAF4F2F400BE850@DM6PR08MB6042.namprd08.prod.outlook.com>
 <3e340bbd-e7ed-12f0-718e-3a53ca8707aa@fu-berlin.de>
Message-ID: <DM6PR08MB6042AC47ECCC942BC07811F1BE850@DM6PR08MB6042.namprd08.prod.outlook.com>

On Mon, Sep 23, 2019 at 06:58:43PM +0200, Herbert Voss wrote:
> Am 23.09.19 um 18:28 schrieb Mike Marchywka:
> 
> 
> > marchywka at happy:~/junk$ cat xxx
> > @article{Ay_n_N_ez_2018,
> > 	doi = {10.1042/bsr20180705},
> > 	url = {https://doi.org/10.1042%2Fbsr20180705},
> > 	year = 2018,
> > 	month = {aug},
> > 	publisher = {Portland Press Ltd.},
> > 	volume = {38},
> > 	number = {5},
> > 	pages = {BSR20180705},
> > 	author = {Dolores A. Ay{\'{o}}n-N{\'{u}}{\~{n}}ez and Gladis Fragoso and Ra{\'{u}}l J. Bobes and Juan P. Laclette},
> > 	title = {Plasminogen-binding proteins as an evasion mechanism of the host's innate immunity in infectious diseases},
> > 	journal = {Bioscience Reports}
> > }marchywka at happy:~/junk$
> > 
> > 
> > Have I missed something stupid here?
> > Does this look like a correct " pages" value or problem with publisher or cross ref?
> 
> I have no idea what pages "BSR20180705" means, but it will still be printed:

Thanks, it never occured to me to try somethng like that for testing bibtex entries :)
Looking at the "srcurl" which I have moved into the main entries now it looks like
the "paper" actually has page numbers starting with "1" although I guess alpha
prefix or suffix is not unacceptable ( I was thinking numeric only ).

I'm not sure if I can reasonably use biblatex with revtex4 documents as it loads
natbib however...

There are a lot of little things from various publishers like CR/LF in the page numbers etc.
AFAICT they compile ok- the pdf looks like the format is right- but it does make it harder
to be sure the bibtex entries are ok. 

> 
> \documentclass{article}
> \usepackage{biblatex,shellesc}
> \addbibresource{\jobname.bib}
> 
> \begin{document}
> \IfFileExists{\jobname.bib}{}{%
>   \ShellEscape{	
> 	/usr/bin/wget -O \jobname.bib -S -v 	
> 	"http://api.crossref.org/works/10.1042/BSR20180705/transform/application/x-bibtex"}
> }
> 	
> \nocite{*}
> \printbibliography
> \end{document}
> 
> lualatex --shell-escape test
> biber test
> lualatex --shell-escape test
> 
> 
> gives the attched output witrh biblatex/biber
> 
> Herbert
> 
> 
> 
> 



-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From marchywka at hotmail.com  Mon Sep 23 21:30:19 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 23 Sep 2019 19:30:19 +0000
Subject: BibTeX formatting recommendations
In-Reply-To: <CMM.0.95.0.1569248217.beebe@gamma.math.utah.edu>
References: <CMM.0.95.0.1569248217.beebe@gamma.math.utah.edu>
Message-ID: <DM6PR08MB6042819284A7028846A442D5BE850@DM6PR08MB6042.namprd08.prod.outlook.com>

On Mon, Sep 23, 2019 at 08:16:57AM -0600, Nelson H. F. Beebe wrote:
> Please have a look at the documents

Sorry I did not see this earlier, hotmail sent it to my junk folder :)

> 
> 	BibTeX Information and Tutorial
> 	
> 	BibTeX meets relational databases
> 
> at links from
> 
> 	http://www.math.utah.edu/pub/tex/doc/
> 
> Our archives here that I have maintained for 25+ years now contain
> more than 1.5 million entries, so I have a lot of experience, and
> definite views on, BibTeX formatting.  There are numerous tools that
> are freely available from
> 
> 	http://www.math.utah.edu/pub
> 
> Look for the ones with bib in their names, notably, bibclean,
> biblabel, biborder, bibsort, and cattobib.

I thought something like this may exist but it is not
uncommon to be better off writing my own similiars.
Now I can see what I missed :) 
Right now, my c++ code probably does a lot of similar things including
integrating my comments into the bibentry when the script did not
insert a url already ( the script did usually include the page
I was looking at and the url it finally found for the bibtex).

I did get caught up on a lot of wierd things in the hunt for
bugs- like assuming page numbers need to be numeric- but
I'm getting a better idea of what is going on ( bibliography
is about the last thing I was going to look at but I was getting
so many and had the scripts started I needed to sanity check to
avoid being unable to find a reference later ).

Thanks.
> 
> There is also extensive emacs editing support in
> 
> 	http://www.math.utah.edu/pub/emacs/
> 
> In particular, emacs functions allow be to generate a new citation
> label in the format produced by biblabel with just two keystrokes.
> 
> -------------------------------------------------------------------------------
> - Nelson H. F. Beebe                    Tel: +1 801 581 5254                  -
> - University of Utah                    FAX: +1 801 581 4148                  -
> - Department of Mathematics, 110 LCB    Internet e-mail: beebe at math.utah.edu  -
> - 155 S 1400 E RM 233                       beebe at acm.org  beebe at computer.org -
> - Salt Lake City, UT 84112-0090, USA    URL: http://www.math.utah.edu/~beebe/ -
> -------------------------------------------------------------------------------

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From trevnat at talktalk.net  Wed Sep 25 13:25:17 2019
From: trevnat at talktalk.net (Trevor Marshall)
Date: Wed, 25 Sep 2019 12:25:17 +0100 (BST)
Subject: Importing a figure
Message-ID: <1450695554.89373.1569410718130@apps.talktalk.co.uk>

Please  can anyone tell me how to import a figure, say as a eps or jpg file generated by OCTAVE or MATLAB?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190925/dae0356b/attachment.html>

From peter at silmaril.ie  Wed Sep 25 16:16:22 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Wed, 25 Sep 2019 15:16:22 +0100
Subject: Fwd: Re: Importing a figure
In-Reply-To: <16d68c68e10.2798.4cd050b9e2734e903149e94ed29c5104@silmaril.ie>
References: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
 <16d68c68e10.2798.4cd050b9e2734e903149e94ed29c5104@silmaril.ie>
Message-ID: <16d68c7b6f0.2798.4cd050b9e2734e903149e94ed29c5104@silmaril.ie>

On 25 September 2019 14:37:00 Trevor Marshall via texhax <texhax at tug.org> 
wrote:
> Please  can anyone tell me how to import a figure, say as a eps or jpg file 
> generated by OCTAVE or MATLAB?
Always Read The Fine Documentation ?

http://latex.silmaril.ie/formattinginformation/figures.html

http://latex.silmaril.ie/formattinginformation/images.html

Peter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190925/411365ce/attachment.html>

From P.Taylor at rhul.ac.uk  Wed Sep 25 16:16:51 2019
From: P.Taylor at rhul.ac.uk (Taylor, P)
Date: Wed, 25 Sep 2019 14:16:51 +0000
Subject: Importing a figure
In-Reply-To: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
References: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
Message-ID: <2a760f14-8084-34d2-b6cd-39321b4bf042@Rhul.Ac.Uk>

Trevor Marshall via texhax wrote:


Please  can anyone tell me how to import a figure, say as a eps or jpg file generated by OCTAVE or MATLAB?

Of EPS files, I have no recent experience, having many years ago abandoned the TeX -> DVI -> EPS route in favour of direct TeX -> PDF.  With the latter, and assuming that you are using XeTeX, then :

    \setbox 0 = \hbox {\XeTeXpicfile somefile.jpg\relax}

will leave an internal representation of the jpeg in \box 0 for subsequent use in your main XeTeX code.  If you are not using XeTeX, then you will have to rely on (e.g.,) the "graphics" package, in which case you will almost certainly have to use LaTeX, 'though you may be able to use the "graphics" package in conjunction with plain (Pdf)TeX if you also use "miniltx".

Philip Taylor

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190925/1a606eab/attachment.html>

From marchywka at hotmail.com  Wed Sep 25 16:42:41 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Wed, 25 Sep 2019 14:42:41 +0000
Subject: Importing a figure
In-Reply-To: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
References: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
Message-ID: <DM6PR08MB60429E169315F5F45BF91067BE870@DM6PR08MB6042.namprd08.prod.outlook.com>

On Wed, Sep 25, 2019 at 12:25:17PM +0100, Trevor Marshall via texhax wrote:
>    Please  can anyone tell me how to import a figure, say as a eps or jpg file generated by OCTAVE or MATLAB?

Curious if this is a plot or not and if you have considered svg? It is just for
my own information, having written a lot of c++ code to support svg after getting
confused with R :) 

Thanks.


> 
> 

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From marchywka at hotmail.com  Wed Sep 25 16:46:10 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Wed, 25 Sep 2019 14:46:10 +0000
Subject: html management and generation packages- do they offer "bibtex"
 generation? :)
Message-ID: <DM6PR08MB60428DC5A4CAD0114AE0F495BE870@DM6PR08MB6042.namprd08.prod.outlook.com>



I was just digging through more html from a somewhat scholarly webpage ( popular audience
but using scientific literature ) that would be nice to cite in a bunch of publication
types I could imagine. It looked like from the comments their pages were generated
by some package ( the name escapes me now but probably these are easy to find or
well known among web people ). Any hope of getting them to make a bibtex button
as easy as a bunch of share buttons? I'm still trying to scrape up bibtex from 
these sites and they would probably be happy if it was easier to credit them.

Also whatever happened to the "webmaster" mail address? Too much spam? LOL.

Thanks.


-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From frainj at gmail.com  Wed Sep 25 19:24:46 2019
From: frainj at gmail.com (John C Frain)
Date: Wed, 25 Sep 2019 18:24:46 +0100
Subject: Importing a figure
In-Reply-To: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
References: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
Message-ID: <CAHrK517403cSnD+NHMhGXRH5ou-qWF6DoTx2n1UcYnk9h1KStw@mail.gmail.com>

If you are using the standard pdflatex program to produce your pdf output
you will need to do something extra to import epd figures.  The graphicx
package and pdflatex only support pdf, jpg and png formats. There should be
no problems including jpg files in your document using the graphicx
package, figure environment, and the includegraphics command.

to include eps files in this scheme you can use the epstopdf program
(included in your tex distribution) to convert your eps file to pdf or
include the epstopdf package in your preamble.  When this is included in
the preamble and the pdflatex program encounters an eps file and no
corresponding pdf it generates the pdf and includes it in your document,
If you amend the eps file you must delete the generated pdf file as
otherwise it will not be regenerated.

Chapter 7 of my LaTeX notes contains more details (
https://econpapers.repec.org/paper/tcdtcduee/tep0214.htm).

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


On Wed, 25 Sep 2019 at 14:36, Trevor Marshall via texhax <texhax at tug.org>
wrote:

> Please  can anyone tell me how to import a figure, say as a eps or jpg
> file generated by OCTAVE or MATLAB?
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190925/42da0f89/attachment-0001.html>

From schneidt at mail.nih.gov  Wed Sep 25 20:22:28 2019
From: schneidt at mail.nih.gov (Schneider, Thomas (NIH/NCI) [E])
Date: Wed, 25 Sep 2019 18:22:28 +0000
Subject: html management and generation packages- do they offer "bibtex"
 generation? :)
In-Reply-To: <DM6PR08MB60428DC5A4CAD0114AE0F495BE870@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB60428DC5A4CAD0114AE0F495BE870@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <A0FE0EDB-16DE-4522-94F1-C03B292291CD@mail.nih.gov>

Mike:

> I was just digging through more html from a somewhat scholarly webpage ( popular audience
> but using scientific literature ) that would be nice to cite in a bunch of publication
> types I could imagine. It looked like from the comments their pages were generated
> by some package ( the name escapes me now but probably these are easy to find or
> well known among web people ). Any hope of getting them to make a bibtex button
> as easy as a bunch of share buttons? I'm still trying to scrape up bibtex from 
> these sites and they would probably be happy if it was easier to credit them.

It will depend entirely on the site.

I use two methods:

1.  https://alum.mit.edu/www/toms/yvp.html

yvp is a script that takes the year, volume and page of a paper and
finds it in PubMed.  Obviously it only works for biomedical papers,
but it can work well.  yvpg GUESSES what is the year, volume and page
in the cut/paste buffer and then calls yvp.  One can use these to go
from a reference at the end of a paper to the PubMed page in a few
seconds.  Given the PubMedID, my mq script makes the bibtex entry.

2.  Google: Just grab everything of the reference; this can give
the PubMed.

> Also whatever happened to the "webmaster" mail address? Too much spam? LOL.

Probably spam ... they will almost always have a way to contact them,
usually a "webmail" which forces one to keep one's own record unless
they allow you to send a copy to yourself.

Tom

  Thomas D. Schneider, Ph.D.
  Senior Investigator
  National Institutes of Health
  National Cancer Institute
  Center for Cancer Research
  RNA Biology Laboratory
  Biological Information Theory Group
  Frederick, Maryland  21702-1201
  schneidt at mail.nih.gov
  https://alum.mit.edu/www/toms



From d.p.carlisle at gmail.com  Wed Sep 25 20:50:11 2019
From: d.p.carlisle at gmail.com (David Carlisle)
Date: Wed, 25 Sep 2019 19:50:11 +0100
Subject: Importing a figure
In-Reply-To: <CAHrK517403cSnD+NHMhGXRH5ou-qWF6DoTx2n1UcYnk9h1KStw@mail.gmail.com>
References: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
 <CAHrK517403cSnD+NHMhGXRH5ou-qWF6DoTx2n1UcYnk9h1KStw@mail.gmail.com>
Message-ID: <CAEW6iOgcgnC2rsRZKKTDmjWxv=KOfn6=sdrmWJ=+3h2v2g0QBQ@mail.gmail.com>

actually you just need graphicx (which calls epstopdf-base behind the
scenes if needed.

On Wed, 25 Sep 2019 at 18:26, John C Frain <frainj at gmail.com> wrote:

>
> If you are using the standard pdflatex program to produce your pdf output
> you will need to do something extra to import epd figures.  The graphicx
> package and pdflatex only support pdf, jpg and png formats. There should be
> no problems including jpg files in your document using the graphicx
> package, figure environment, and the includegraphics command.
>
> to include eps files in this scheme you can use the epstopdf program
> (included in your tex distribution) to convert your eps file to pdf or
> include the epstopdf package in your preamble.  When this is included in
> the preamble and the pdflatex program encounters an eps file and no
> corresponding pdf it generates the pdf and includes it in your document,
> If you amend the eps file you must delete the generated pdf file as
> otherwise it will not be regenerated.
>
> Chapter 7 of my LaTeX notes contains more details (
> https://econpapers.repec.org/paper/tcdtcduee/tep0214.htm).
>
> John C Frain
> 3 Aranleigh Park
> Rathfarnham
> Dublin 14
> Ireland
> www.tcd.ie/Economics/staff/frainj/home.html
> mailto:frainj at tcd.ie
> mailto:frainj at gmail.com
>
>
> On Wed, 25 Sep 2019 at 14:36, Trevor Marshall via texhax <texhax at tug.org>
> wrote:
>
>> Please  can anyone tell me how to import a figure, say as a eps or jpg
>> file generated by OCTAVE or MATLAB?
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190925/0804269e/attachment.html>

From marchywka at hotmail.com  Wed Sep 25 20:50:47 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Wed, 25 Sep 2019 18:50:47 +0000
Subject: html management and generation packages- do they offer "bibtex"
 generation? :)
In-Reply-To: <A0FE0EDB-16DE-4522-94F1-C03B292291CD@mail.nih.gov>
References: <DM6PR08MB60428DC5A4CAD0114AE0F495BE870@DM6PR08MB6042.namprd08.prod.outlook.com>
 <A0FE0EDB-16DE-4522-94F1-C03B292291CD@mail.nih.gov>
Message-ID: <DM6PR08MB60426CCF0C9929B5023BFC46BE870@DM6PR08MB6042.namprd08.prod.outlook.com>

On Wed, Sep 25, 2019 at 06:22:28PM +0000, Schneider, Thomas (NIH/NCI) [E] wrote:
> Mike:
> 
> > I was just digging through more html from a somewhat scholarly webpage ( popular audience
> > but using scientific literature ) that would be nice to cite in a bunch of publication
> > types I could imagine. It looked like from the comments their pages were generated
> > by some package ( the name escapes me now but probably these are easy to find or
> > well known among web people ). Any hope of getting them to make a bibtex button
> > as easy as a bunch of share buttons? I'm still trying to scrape up bibtex from 
> > these sites and they would probably be happy if it was easier to credit them.
> 
> It will depend entirely on the site.

Thanks, but I was wondering if bypassing the site and going to the people who
make popular html generation/mangement packages ( assuming these actually
exist as I understand them to )  would work any better.
I started as you suggest below- first it was taking a pubmed or pmc
link and getting a bibtex from that but it quickly expanded although
I now have bib files segregated as it only fetches the pubmed
entries when citations are discovered while building the pdf :)
Now, I'm going off into ad hoc pages that don't seem to know or
care about citations, just shares, and trying to determine if it is possible
to scrape the html for bibtex entry pieces. If the webmaster  just downloads an open source
asset management thing- maybe they have a bunch of text and images and 
some xml and the package gives the site a "look and feel" or something-
getting the management code to include citations along with share may
be a worthwhile effort. 
I'm not sure most sites would know or care one way of the other, heck with more 
buttons in a share row maybe it looks better no idea. 
fwiw. 
 



> 
> I use two methods:
> 
> 1.  https://alum.mit.edu/www/toms/yvp.html
> 
> yvp is a script that takes the year, volume and page of a paper and
> finds it in PubMed.  Obviously it only works for biomedical papers,
> but it can work well.  yvpg GUESSES what is the year, volume and page
> in the cut/paste buffer and then calls yvp.  One can use these to go
> from a reference at the end of a paper to the PubMed page in a few
> seconds.  Given the PubMedID, my mq script makes the bibtex entry.
> 
> 2.  Google: Just grab everything of the reference; this can give
> the PubMed.
> 
> > Also whatever happened to the "webmaster" mail address? Too much spam? LOL.
> 
> Probably spam ... they will almost always have a way to contact them,
> usually a "webmail" which forces one to keep one's own record unless
> they allow you to send a copy to yourself.
> 
> Tom
> 
>   Thomas D. Schneider, Ph.D.
>   Senior Investigator
>   National Institutes of Health
>   National Cancer Institute
>   Center for Cancer Research
>   RNA Biology Laboratory
>   Biological Information Theory Group
>   Frederick, Maryland  21702-1201
>   schneidt at mail.nih.gov
>   https://alum.mit.edu/www/toms
> 

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From peter at silmaril.ie  Thu Sep 26 13:23:41 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Thu, 26 Sep 2019 12:23:41 +0100
Subject: html management and generation packages- do they offer "bibtex"
 generation? :)
In-Reply-To: <DM6PR08MB60428DC5A4CAD0114AE0F495BE870@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB60428DC5A4CAD0114AE0F495BE870@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <6d429521-e484-5b4b-f2a3-5fb92b58bdb7@silmaril.ie>

On 25/09/2019 15:46, Mike Marchywka wrote:
> I was just digging through more html from a somewhat scholarly
> webpage (popular audience but using scientific literature) that
> would be nice to cite in a bunch of publication types I could
> imagine. It looked like from the comments their pages were generated 
> by some package (the name escapes me now but probably these are easy
> to find or well known among web people). 

Can you find out the name?

> Any hope of getting them to make a bibtex button as easy as a bunch
> of share buttons? 

If it's one of the popular open source content management systems, you 
can write the code for a 'cite' button and contribute it to the project.

You then have to persuade site owners that it's worth their while to add 
the button, and persuade their designers to change their design to 
accommodate it.

Those two are many orders of magnitude harder than actually writing the 
button code.

> I'm still trying to scrape up bibtex from these sites and they would
> probably be happy if it was easier to credit them.

I really doubt if they are interested unless it will make them money.

> Also whatever happened to the "webmaster" mail address? Too much 
> spam? 

That, plus web sites really *HATE* people contacting them. Most nowadays 
hide behind "email forms" which they can ignore, and they hide their 
domain registration behind an anonymous registrar.

Peter

From peter at silmaril.ie  Thu Sep 26 13:26:38 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Thu, 26 Sep 2019 12:26:38 +0100
Subject: Importing a figure
In-Reply-To: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
References: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
Message-ID: <84763f33-37cd-b124-2619-f33335910bd1@silmaril.ie>

On 25/09/2019 12:25, Trevor Marshall via texhax wrote:
> Please? can anyone tell me how to import a figure, say as a eps or jpg 
> file generated by OCTAVE or MATLAB?

And I should have said, NEVER use JPG for diagrams. NEVER.
JPG is for bitmap images like *photographs*.

If your package is old, and can only export EPS, use that and convert it 
to PDF vectors with ps2pdf. Otherwise, export PDF.

Then

From marchywka at hotmail.com  Thu Sep 26 13:42:29 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Thu, 26 Sep 2019 11:42:29 +0000
Subject: html management and generation packages- do they offer "bibtex"
 generation? :)
In-Reply-To: <6d429521-e484-5b4b-f2a3-5fb92b58bdb7@silmaril.ie>
References: <DM6PR08MB60428DC5A4CAD0114AE0F495BE870@DM6PR08MB6042.namprd08.prod.outlook.com>
 <6d429521-e484-5b4b-f2a3-5fb92b58bdb7@silmaril.ie>
Message-ID: <DM6PR08MB6042BD7D1D25AF369A2047FBBE860@DM6PR08MB6042.namprd08.prod.outlook.com>

On Thu, Sep 26, 2019 at 12:23:41PM +0100, Peter Flynn wrote:
> On 25/09/2019 15:46, Mike Marchywka wrote:
> > I was just digging through more html from a somewhat scholarly
> > webpage (popular audience but using scientific literature) that
> > would be nice to cite in a bunch of publication types I could
> > imagine. It looked like from the comments their pages were generated by
> > some package (the name escapes me now but probably these are easy
> > to find or well known among web people).
> 
> Can you find out the name?

According to their html, although IIRC designers used to credited in small
type on bottom of many sites, 

 more xxx | grep -i "genera\|credit\|design"
	<meta name="generator" content="Joomla! - Open Source Content Management" />


> 
> > Any hope of getting them to make a bibtex button as easy as a bunch
> > of share buttons?
> 
> If it's one of the popular open source content management systems, you can
> write the code for a 'cite' button and contribute it to the project.
> 
> You then have to persuade site owners that it's worth their while to add the
> button, and persuade their designers to change their design to accommodate
> it.
> 
> Those two are many orders of magnitude harder than actually writing the
> button code.
> 
> > I'm still trying to scrape up bibtex from these sites and they would
> > probably be happy if it was easier to credit them.
> 
> I really doubt if they are interested unless it will make them money.
> 
> > Also whatever happened to the "webmaster" mail address? Too much spam?
> 
> That, plus web sites really *HATE* people contacting them. Most nowadays
> hide behind "email forms" which they can ignore, and they hide their domain
> registration behind an anonymous registrar.
> 
> Peter

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From peter at silmaril.ie  Thu Sep 26 17:35:34 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Thu, 26 Sep 2019 16:35:34 +0100
Subject: html management and generation packages- do they offer "bibtex"
 generation? :)
In-Reply-To: <DM6PR08MB6042BD7D1D25AF369A2047FBBE860@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB60428DC5A4CAD0114AE0F495BE870@DM6PR08MB6042.namprd08.prod.outlook.com>
 <6d429521-e484-5b4b-f2a3-5fb92b58bdb7@silmaril.ie>
 <DM6PR08MB6042BD7D1D25AF369A2047FBBE860@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <aa52b9a7-d420-8bff-f23c-10ad5d0a71d9@silmaril.ie>

On 26/09/2019 12:42, Mike Marchywka wrote:
> 
> On Thu, Sep 26, 2019 at 12:23:41PM +0100, Peter Flynn wrote:
[...]
>> Can you find out the name?
> 
> According to their html, although IIRC designers used to credited in small
> type on bottom of many sites,
> 
>   more xxx | grep -i "genera\|credit\|design"
> 	<meta name="generator" content="Joomla! - Open Source Content Management" />

OK, that's easy. What I said:

    https://www.joomla.org/contribute-to-joomla.html

Peter

From marchywka at hotmail.com  Thu Sep 26 17:47:10 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Thu, 26 Sep 2019 15:47:10 +0000
Subject: html management and generation packages- do they offer "bibtex"
 generation? :)
In-Reply-To: <aa52b9a7-d420-8bff-f23c-10ad5d0a71d9@silmaril.ie>
References: <DM6PR08MB60428DC5A4CAD0114AE0F495BE870@DM6PR08MB6042.namprd08.prod.outlook.com>
 <6d429521-e484-5b4b-f2a3-5fb92b58bdb7@silmaril.ie>
 <DM6PR08MB6042BD7D1D25AF369A2047FBBE860@DM6PR08MB6042.namprd08.prod.outlook.com>
 <aa52b9a7-d420-8bff-f23c-10ad5d0a71d9@silmaril.ie>
Message-ID: <DM6PR08MB6042EDC74DA708EC2A0FEEC3BE860@DM6PR08MB6042.namprd08.prod.outlook.com>

On Thu, Sep 26, 2019 at 04:35:34PM +0100, Peter Flynn wrote:
> On 26/09/2019 12:42, Mike Marchywka wrote:
> > 
> > On Thu, Sep 26, 2019 at 12:23:41PM +0100, Peter Flynn wrote:
> [...]
> > > Can you find out the name?
> > 
> > According to their html, although IIRC designers used to credited in small
> > type on bottom of many sites,
> > 
> >   more xxx | grep -i "genera\|credit\|design"
> > 	<meta name="generator" content="Joomla! - Open Source Content Management" />
> 
> OK, that's easy. What I said:
> 
>    https://www.joomla.org/contribute-to-joomla.html

I used to work with online advertising but my UI design skills are a bit
well I'm not sure I could help much although maybe I could hack up one of their share
buttons and see what they think.

Actually my next software project was going to be hacking up evince to do
the visibility selection I hacked into xdvik viewer :)
I am scrolling around drafts now thinking the visibility thing would help 
but fixing the code up would take a little concentration.
If I can contain the changes and make a branch maybe it could be distributed :) 

Thanks. 


> 
> Peter

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From borisv at lk.net  Thu Sep 26 19:20:05 2019
From: borisv at lk.net (Boris Veytsman)
Date: Thu, 26 Sep 2019 10:20:05 -0700
Subject: Importing a figure
In-Reply-To: <84763f33-37cd-b124-2619-f33335910bd1@silmaril.ie> (message from
 Peter Flynn on Thu, 26 Sep 2019 12:26:38 +0100)
References: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
 <84763f33-37cd-b124-2619-f33335910bd1@silmaril.ie>
Message-ID: <201909261720.x8QHK5CA031631@bilbo.localnet>

PF> From: Peter Flynn <peter at silmaril.ie>
PF> Date: Thu, 26 Sep 2019 12:26:38 +0100


PF> If your package is old, and can only export EPS, use that and convert it 
PF> to PDF vectors with ps2pdf. Otherwise, export PDF.

AFAIK, modern TeX installations (like TeXLive) will do the conversion
for you automatically.  Just say \includegraphics{file}, and if the
system sees file.eps, it creates the corresponding pdf file.



-- 
Good luck

-Boris

If everything is coming your way then you're in the wrong lane.

From frainj at gmail.com  Thu Sep 26 21:55:42 2019
From: frainj at gmail.com (John C Frain)
Date: Thu, 26 Sep 2019 20:55:42 +0100
Subject: Importing a figure
In-Reply-To: <CAEW6iOgcgnC2rsRZKKTDmjWxv=KOfn6=sdrmWJ=+3h2v2g0QBQ@mail.gmail.com>
References: <1450695554.89373.1569410718130@apps.talktalk.co.uk>
 <CAHrK517403cSnD+NHMhGXRH5ou-qWF6DoTx2n1UcYnk9h1KStw@mail.gmail.com>
 <CAEW6iOgcgnC2rsRZKKTDmjWxv=KOfn6=sdrmWJ=+3h2v2g0QBQ@mail.gmail.com>
Message-ID: <CAHrK514R9A8E81QcvOXu=RH2LgLxqwcjPpx9N3DDUAbDeTz+Xg@mail.gmail.com>

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


On Wed, 25 Sep 2019 at 19:50, David Carlisle <d.p.carlisle at gmail.com> wrote:

> actually you just need graphicx (which calls epstopdf-base behind the
> scenes if needed.
>

Thanks for the clarification.  Obviously I am a bit out of date.

I have used both octave and gretl and should have advised that graphics
files from both of these packages can save graphics output as pdf which can
then be imported directly into pdflatex.  If you have an amended eps file
it is still necessary to remove any earlier pdf files graphics files
generated by the packages graphics and epstopdf_base.  Otherwise, the new
files will not be converted to pdf and the old converted files will be
included in the document.  I am currently using TeX Live 2017 on Windows 10
and the versions of the graphicx and epsto pdf packages that I am using are
set out below.

Package: graphics 2017/06/25 v1.2c Standard LaTeX Graphics (DPC,SPQR)
Package: epstopdf-base 2016/05/15 v2.6 Base part for package epstopdf


>
> On Wed, 25 Sep 2019 at 18:26, John C Frain <frainj at gmail.com> wrote:
>
>>
>> If you are using the standard pdflatex program to produce your pdf output
>> you will need to do something extra to import epd figures.  The graphicx
>> package and pdflatex only support pdf, jpg and png formats. There should be
>> no problems including jpg files in your document using the graphicx
>> package, figure environment, and the includegraphics command.
>>
>> to include eps files in this scheme you can use the epstopdf program
>> (included in your tex distribution) to convert your eps file to pdf or
>> include the epstopdf package in your preamble.  When this is included in
>> the preamble and the pdflatex program encounters an eps file and no
>> corresponding pdf it generates the pdf and includes it in your document,
>> If you amend the eps file you must delete the generated pdf file as
>> otherwise it will not be regenerated.
>>
>> Chapter 7 of my LaTeX notes contains more details (
>> https://econpapers.repec.org/paper/tcdtcduee/tep0214.htm).
>>
>> John C Frain
>> 3 Aranleigh Park
>> Rathfarnham
>> Dublin 14
>> Ireland
>> www.tcd.ie/Economics/staff/frainj/home.html
>> mailto:frainj at tcd.ie
>> mailto:frainj at gmail.com
>>
>>
>> On Wed, 25 Sep 2019 at 14:36, Trevor Marshall via texhax <texhax at tug.org>
>> wrote:
>>
>>> Please  can anyone tell me how to import a figure, say as a eps or jpg
>>> file generated by OCTAVE or MATLAB?
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20190926/83b4bac1/attachment-0001.html>

From marchywka at hotmail.com  Thu Sep 26 22:26:13 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Thu, 26 Sep 2019 20:26:13 +0000
Subject: html management and generation packages- do they offer "bibtex"
 generation? :)
In-Reply-To: <aa52b9a7-d420-8bff-f23c-10ad5d0a71d9@silmaril.ie>
References: <DM6PR08MB60428DC5A4CAD0114AE0F495BE870@DM6PR08MB6042.namprd08.prod.outlook.com>
 <6d429521-e484-5b4b-f2a3-5fb92b58bdb7@silmaril.ie>
 <DM6PR08MB6042BD7D1D25AF369A2047FBBE860@DM6PR08MB6042.namprd08.prod.outlook.com>
 <aa52b9a7-d420-8bff-f23c-10ad5d0a71d9@silmaril.ie>
Message-ID: <DM6PR08MB60429538A21E4E90A2129712BE860@DM6PR08MB6042.namprd08.prod.outlook.com>

On Thu, Sep 26, 2019 at 04:35:34PM +0100, Peter Flynn wrote:
> On 26/09/2019 12:42, Mike Marchywka wrote:
> > 
> > On Thu, Sep 26, 2019 at 12:23:41PM +0100, Peter Flynn wrote:
> [...]
> > > Can you find out the name?
> > 
> > According to their html, although IIRC designers used to credited in small
> > type on bottom of many sites,
> > 
> >   more xxx | grep -i "genera\|credit\|design"
> > 	<meta name="generator" content="Joomla! - Open Source Content Management" />
> 
> OK, that's easy. What I said:
> 
>    https://www.joomla.org/contribute-to-joomla.html


Wow, if you believe the view counts this looks like pretty popular
thing, never see that in the tech literature I browse lol,

https://forum.joomla.org/viewforum.php?f=706

Before posting I did a quick search for "bibtex" and it did not
come up. They warned against promotional links so I 
declined that. Curious to see what happens...

Thanks.

> 
> Peter

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From marchywka at hotmail.com  Sat Sep 28 14:34:49 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sat, 28 Sep 2019 12:34:49 +0000
Subject: bibtex source alternatives, order of preference.
Message-ID: <DM6PR08MB6042BAF156082791F777BFF8BE800@DM6PR08MB6042.namprd08.prod.outlook.com>


Curious if anyone has looked much as prefered sources of bibtex entries.
That is, in many cases I'm finding alternatives at a given publisher web page.
In a couple instances, the publishers provide bibtex via some method
and I went to a lot of effort to find publisher or domain specific ways
to get that from a link to the page. However, when a doi is available
often the crossref entry is cleaner. Anyone had experience with the 
publisher bibtex versus crossref or any comments? 

I guess I can just get all possible versions, it is not that hard,
and put them together with some code merge tool lol.

Thanks. 


-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


