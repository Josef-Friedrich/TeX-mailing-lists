From daw at ucsc.edu  Sun Dec  1 22:08:29 2019
From: daw at ucsc.edu (David Williams)
Date: Sun, 1 Dec 2019 13:08:29 -0800
Subject: bibtex bug/feature request
Message-ID: <1771CCC7-C9CA-4DA4-8B90-4F5BF9F4EA65@ucsc.edu>

Dear TeX Hackers,

As collaborations have grown, so have BibTex entries, and the entry generated by ADS for the paper "Multi-messenger Observations of a Binary Neutron Star Merger? is too long for the current character limit.   The entry can be found here:

https://urldefense.com/v3/__https://ui.adsabs.harvard.edu/abs/2017ApJ...848L..12A/abstract__;!!C5qS4YX3!QCGTY3sgBldIjM_AZw5gS-1DmZ-Y1K2wsGD3wx-Jjcs5e4K8iYJrvhHZL5m4gNc$ 

using the Export Citation link at the left.  For the reference list of NSF proposals, all authors are supposed to be listed.  To do that, the full author list needs to be ingested by BibTex.  (For my immediate purposes, I have truncated the list with ?and others? at a point that fits within the character limit.)

With best regards and in grateful appreciation,
David Williams

-- 
David A. Williams                                    phone  831-459-3032
Santa Cruz Institute for Particle Physics            fax    831-459-5777
University of California
Santa Cruz, CA  95064




From marchywka at hotmail.com  Mon Dec  2 00:44:03 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sun, 1 Dec 2019 23:44:03 +0000
Subject: bibtex bug/feature request
In-Reply-To: <1771CCC7-C9CA-4DA4-8B90-4F5BF9F4EA65@ucsc.edu>
References: <1771CCC7-C9CA-4DA4-8B90-4F5BF9F4EA65@ucsc.edu>
Message-ID: <DM6PR08MB604200A73AFEF8E7E48D8E83BE400@DM6PR08MB6042.namprd08.prod.outlook.com>

On Sun, Dec 01, 2019 at 01:08:29PM -0800, David Williams via texhax wrote:
> Dear TeX Hackers,
> 
> As collaborations have grown, so have BibTex entries, and the entry generated by ADS for the paper "Multi-messenger Observations of a Binary Neutron Star Merger? is too long for the current character limit.   The entry can be found here:
> 
> https://urldefense.com/v3/__https://ui.adsabs.harvard.edu/abs/2017ApJ...848L..12A/abstract__;!!C5qS4YX3!QCGTY3sgBldIjM_AZw5gS-1DmZ-Y1K2wsGD3wx-Jjcs5e4K8iYJrvhHZL5m4gNc$ 
> 
> using the Export Citation link at the left.  For the reference list of NSF proposals, all authors are supposed to be listed.  To do that, the full author list needs to be ingested by BibTex.  (For my immediate purposes, I have truncated the list with ?and others? at a point that fits within the character limit.)

I just tried it with my default test template and got this output. 
b_9.tex
\documentclass{article}
\begin{document}
\nocite{*}
\bibliographystyle{plain}
\bibliography{.temp_med2bib_4}
\end{document}
marchywka at happy:/home/documents/cpp/proj/toobib/junk$ head -n 8 .temp_med2bib_4.bib 

% srcurl:  https://ui.adsabs.harvard.edu/abs/2017ApJ...848L..12A/abstract
% citeurl:  http://api.crossref.org/works/10.3847/2041-8213/aa91c9/transform/application/x-bibtex
% med2bib comment:  handledoi
% date  Sun Dec 1 18:34:25 EST 2019

@article{Abbott_2017,
	doi = {10.3847/2041-8213/aa91c9},



> 
> With best regards and in grateful appreciation,
> David Williams
> 
> -- 
> David A. Williams                                    phone  831-459-3032
> Santa Cruz Institute for Particle Physics            fax    831-459-5777
> University of California
> Santa Cruz, CA  95064
> 
> 
> 

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X
-------------- next part --------------
A non-text attachment was scrubbed...
Name: .temp_med2bib_4.bib
Type: text/x-bibtex
Size: 59177 bytes
Desc: .temp_med2bib_4.bib
URL: <https://tug.org/pipermail/texhax/attachments/20191201/16cdc751/attachment-0001.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: temp_med2bib_9.pdf
Type: application/pdf
Size: 63800 bytes
Desc: temp_med2bib_9.pdf
URL: <https://tug.org/pipermail/texhax/attachments/20191201/16cdc751/attachment-0001.pdf>

From marchywka at hotmail.com  Mon Dec  2 01:16:29 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 2 Dec 2019 00:16:29 +0000
Subject: bibtex bug/feature request
In-Reply-To: <DM6PR08MB604200A73AFEF8E7E48D8E83BE400@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <1771CCC7-C9CA-4DA4-8B90-4F5BF9F4EA65@ucsc.edu>
 <DM6PR08MB604200A73AFEF8E7E48D8E83BE400@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <DM6PR08MB6042EED23057E5B2C20F2287BE430@DM6PR08MB6042.namprd08.prod.outlook.com>

On Sun, Dec 01, 2019 at 11:44:03PM +0000, Mike Marchywka wrote:
> On Sun, Dec 01, 2019 at 01:08:29PM -0800, David Williams via texhax wrote:
> > Dear TeX Hackers,
> > 
> > As collaborations have grown, so have BibTex entries, and the entry generated by ADS for the paper "Multi-messenger Observations of a Binary Neutron Star Merger? is too long for the current character limit.   The entry can be found here:
> > 
> > https://urldefense.com/v3/__https://ui.adsabs.harvard.edu/abs/2017ApJ...848L..12A/abstract__;!!C5qS4YX3!QCGTY3sgBldIjM_AZw5gS-1DmZ-Y1K2wsGD3wx-Jjcs5e4K8iYJrvhHZL5m4gNc$ 
> > 
> > using the Export Citation link at the left.  For the reference list of NSF proposals, all authors are supposed to be listed.  To do that, the full author list needs to be ingested by BibTex.  (For my immediate purposes, I have truncated the list with ?and others? at a point that fits within the character limit.)
> 
> I just tried it with my default test template and got this output. 
> b_9.tex
> \documentclass{article}
> \begin{document}
> \nocite{*}
> \bibliographystyle{plain}
> \bibliography{.temp_med2bib_4}
> \end{document}
> marchywka at happy:/home/documents/cpp/proj/toobib/junk$ head -n 8 .temp_med2bib_4.bib 
> 
> % srcurl:  https://ui.adsabs.harvard.edu/abs/2017ApJ...848L..12A/abstract
> % citeurl:  http://api.crossref.org/works/10.3847/2041-8213/aa91c9/transform/application/x-bibtex
> % med2bib comment:  handledoi
> % date  Sun Dec 1 18:34:25 EST 2019
> 
> @article{Abbott_2017,
> 	doi = {10.3847/2041-8213/aa91c9},

If you look at the attachments on this message, AFAICT it did output something that looks
like you requested with a 7 page citation and authors from A to Z. But
I remember spending a lot of time hacking through the arxiv links to get
bibtex going through some stupid Harvard links. That no longer appears to 
work. If you click on the export citation thing here, 

https://arxiv.org/abs/1710.05833

according to the browser it makes requests to things like doi and crossref arrrghh.

In any case, on the link you sent if the doi scraper got the right DOI
then it should have produced the citation you wanted but I did not check carefully.


> 
> 
> 
> > 
> > With best regards and in grateful appreciation,
> > David Williams
> > 
> > -- 
> > David A. Williams                                    phone  831-459-3032
> > Santa Cruz Institute for Particle Physics            fax    831-459-5777
> > University of California
> > Santa Cruz, CA  95064
> > 
> > 
> > 
> 
> -- 
> 
> mike marchywka
> 306 charles cox
> canton GA 30115
> USA, Earth 
> marchywka at hotmail.com
> 404-788-1216
> ORCID: 0000-0001-9237-455X




-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From karl at freefriends.org  Tue Dec  3 00:44:28 2019
From: karl at freefriends.org (Karl Berry)
Date: Mon, 2 Dec 2019 16:44:28 -0700
Subject: bibtex bug/feature request
In-Reply-To: <1771CCC7-C9CA-4DA4-8B90-4F5BF9F4EA65@ucsc.edu>
Message-ID: <201912022344.xB2NiSD8001098@freefriends.org>

Hi David - indeed, after exporting as indicated from
  https://ui.adsabs.harvard.edu/abs/2017ApJ...848L..12A/abstract

I get the error from bibtex:
  Your field is more than 20000 characters---line 303 of file export-bibtex.bib

with a minimal latex file (using plain.bst).  I assume that's the error
you're seeing also. I'll attach my files for the record.

Unfortunately it looks like the various (semi-)dynamic allocations we
programmed into web2c bibtex didn't catch this particular case; that
20000 appears to be a true compile-time limit :(.

I will increase it and/or make it dynamic for TL'20. If you need a new
binary before that instead of your "and others" workaround, we can
probably make one (to be used manually).

Thanks for the report. --best, karl.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: export-bibtex.bib
Type: application/octet-stream
Size: 80996 bytes
Desc: not available
URL: <https://tug.org/pipermail/texhax/attachments/20191202/40afb552/attachment-0002.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: try.tex
Type: application/octet-stream
Size: 122 bytes
Desc: not available
URL: <https://tug.org/pipermail/texhax/attachments/20191202/40afb552/attachment-0003.obj>

From niranjanvikastambe at gmail.com  Tue Dec  3 07:48:07 2019
From: niranjanvikastambe at gmail.com (=?UTF-8?B?4KSo4KS/4KSw4KSC4KSc4KSo?=)
Date: Tue, 3 Dec 2019 12:18:07 +0530
Subject: Support for Devanagari script in LaTeX
Message-ID: <CAM_DS2nrd218AynEDm1uH5NQvHp81x5dEZFvU_3FHeEtg--Jug@mail.gmail.com>

Hello all,

Let me begin with the primary declaration that I've a very little knowledge
of how TeX works, I have some requests regarding the compiler. Please
correct me if I have understood something wrong.

This <http://www.tug.org/FontCatalogue/> is a link which I found for LaTeX
fonts. This collection does not include Devanagari fonts. Devanagari is a
script which has dedicated Unicode numbers which can be found here
<https://unicode.org/charts/PDF/U0900.pdf>. I've attached three zip files
namely Yashovenu, Yashomudra and Jaini. Yashovenu is a free and open source
font (project link <https://github.com/RajyaMarathiVikasSanstha/Yashovenu>)
which is Sans Serif by style. Yashomudra is the serif version of the same
font. No need to mention that it is also free and open source (project link
<https://github.com/RajyaMarathiVikasSanstha/Yashomudra>). Both of these
fonts are available in all the weights. Jaini is an old style Devanagari
font (again open source, this <https://github.com/EkType/Jaini> is the
project link). Unfortunately this font is not available in all the weights,
but it contains one variant named Jaini-Purva which is an even older style
of Devanagari script.

The point of mentioning all of this is Devanagari is a completely
computer-friendly script. Is it possible to include at least these four
fonts in the TeXLive distribution as the representatives of Devanagari
script? The purpose would be a step towards localization of LaTeX project.
Right now if Devanagari is to be used in LaTeX, one has to load fontspec or
polyglossia or other packages like these and compile the document with
XeLaTeX or LuaLaTeX. Consider this as a feature request for making PdfLaTeX
also able to compile Devanagari characters in input and giving output in
some default Devanagari fonts. (Preferably the attached one.) My idea would
be to have simple commands like *\fontstyle* with following options of
(compulsory) arguments -

   1. "\sansserif" - (Yashovenu)
   2. "\serif" - (Yashomudra)
   3. "\olddeva" - (Jaini)
   4. "\traditionaldeva - (Jaini Purva)

Please let me know if I can help you in any ways. If there are some
technical (or TeXnical) problems, please make me aware of the same. I would
be very happy to work for this small step of localization if needed.

Waiting for your response.

Regards,
Niranjan
Department of Linguistics,
University of Mumbai.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20191203/fc410622/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Yashovenu.zip
Type: application/zip
Size: 2054077 bytes
Desc: not available
URL: <https://tug.org/pipermail/texhax/attachments/20191203/fc410622/attachment-0003.zip>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Yashomudra.zip
Type: application/zip
Size: 2004769 bytes
Desc: not available
URL: <https://tug.org/pipermail/texhax/attachments/20191203/fc410622/attachment-0004.zip>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Jaini.1.001.zip
Type: application/zip
Size: 298111 bytes
Desc: not available
URL: <https://tug.org/pipermail/texhax/attachments/20191203/fc410622/attachment-0005.zip>

From dirk.hunniger at googlemail.com  Tue Dec  3 20:56:24 2019
From: dirk.hunniger at googlemail.com (=?UTF-8?Q?Dirk_H=c3=bcnniger?=)
Date: Tue, 3 Dec 2019 20:56:24 +0100
Subject: Support for Devanagari script in LaTeX
In-Reply-To: <CAM_DS2nrd218AynEDm1uH5NQvHp81x5dEZFvU_3FHeEtg--Jug@mail.gmail.com>
References: <CAM_DS2nrd218AynEDm1uH5NQvHp81x5dEZFvU_3FHeEtg--Jug@mail.gmail.com>
Message-ID: <7c3cd8a5-857a-f466-f210-6c5967041ee4@googlemail.com>

Hi Niranjan,

I ran into similar problems when I wrote my mediawiki2latex programm to 
convert Wikipedia Pages to LaTeX. I faced many different symbols from 
many different languages. Devanagari? was one of them. In the end I now 
use xelatex and many different fonts, and switch between them using 
fontspec commands during the course of the LaTeX document. I am quite 
happy with that solution. My program writes the LaTeX file to disk, and 
while writing it looks for possible fonts for the next character and 
switches the font if necessary. In the early days of my development I 
used pdflatex instead. I generated my own ttf font for the 16 bit 
unicode range by mixing from different existing fonts and recalculated 
the kerning. I could somehow pass that font to pdflatex and get results 
that way, the file are still available on mediawiki2latex sourceforge 
page, but I do not recommend to use them. I suggest to use xelatex 
instead. With the pdflatex approach I remember a limit 256 character per 
"font part", so I also had to do some switching there. It made me 
remember old daisy wheel printers, just that the computer was replacing 
the wheel automatically and I did have to do it by hand.

Yours Dirk

On 12/3/19 7:48 AM, ?????? wrote:
> Hello all,
>
> Let me begin with the primary declaration that I've a very little 
> knowledge of how TeX works, I have some requests regarding the 
> compiler. Please correct me if I have understood something wrong.
>
> This <http://www.tug.org/FontCatalogue/> is a link which I found for 
> LaTeX fonts. This collection does not include Devanagari fonts. 
> Devanagari is a script which has dedicated Unicode numbers which can 
> be found here <https://unicode.org/charts/PDF/U0900.pdf>. I've 
> attached three zip files namely Yashovenu, Yashomudra and Jaini. 
> Yashovenu is a free and open source font (project link 
> <https://github.com/RajyaMarathiVikasSanstha/Yashovenu>) which is Sans 
> Serif by style. Yashomudra is the serif version of the same font. No 
> need to mention that it is also free and open source (project link 
> <https://github.com/RajyaMarathiVikasSanstha/Yashomudra>). Both of 
> these fonts are available in all the weights. Jaini is an old style 
> Devanagari font (again open source, this 
> <https://github.com/EkType/Jaini> is the project link). Unfortunately 
> this font is not available in all the weights, but it contains one 
> variant named Jaini-Purva which is an even older style of Devanagari 
> script.
>
> The point of mentioning all of this is Devanagari is a completely 
> computer-friendly script. Is it possible to include at least these 
> four fonts in the TeXLive distribution as the representatives of 
> Devanagari script? The purpose would be a step towards localization of 
> LaTeX project. Right now if Devanagari is to be used in LaTeX, one has 
> to load fontspec or polyglossia or other packages like these and 
> compile the document with XeLaTeX or LuaLaTeX. Consider this as a 
> feature request for making PdfLaTeX also able to compile Devanagari 
> characters in input and giving output in some default Devanagari 
> fonts. (Preferably the attached one.) My idea would be to have simple 
> commands like *\fontstyle* with following options of (compulsory) 
> arguments -
>
>  1. "\sansserif" - (Yashovenu)
>  2. "\serif" - (Yashomudra)
>  3. "\olddeva" - (Jaini)
>  4. "\traditionaldeva - (Jaini Purva)
>
> Please let me know if I can help you in any ways. If there are some 
> technical (or TeXnical) problems, please make me aware of the same. I 
> would be very happy to work for this small step of localization if needed.
>
> Waiting for your response.
>
> Regards,
> Niranjan
> Department of Linguistics,
> University of Mumbai.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20191203/37c70c43/attachment.html>

From tug-news at tug.org  Wed Dec  4 02:44:46 2019
From: tug-news at tug.org (TeX Users Group)
Date: Tue, 3 Dec 2019 18:44:46 -0700
Subject: Nov19 TUG news: science and twitter, reviews and exhibits, CTAN
Message-ID: <201912040144.xB41ikHQ006668@freefriends.org>

Dear TeXers,

October had a very interesting GuIT meeting
(https://www.guitex.org/home/meeting) in Turin, Italy.  I was not able
to attend, but I enjoyed interesting tweets from the event.

It looks like Twitter has become the social medium of choice for the
sci-tech audience. There are now studies of interaction between
scientists through Twitter. The immediacy of Twitter combined with the
immediacy of preprint servers is well aligned with the fast pace of
knowledge growth. To publish a (TeX-based!) preprint on arXiv and to
tweet about it is the 21st-century equivalent of sending a letter about
your research to Henry Oldenburg or Marin Mersenne in the 17th century.
I am happy that TeX plays an important role in this sequence.

Speaking of Twitter, our handle is @TeXUsersGroup; you may find it
useful to follow it.

In other news:

- Barbara Beeton's review of Hermann Zapf and the World 
  He Designed: A Biography, by Jerry Kelly, is available online at:
  https://tug.org/books/

- Letters & Lives: Typography work of Bigelow & Holmes, an exhibit at
  the Arts Center Gallery of Nazareth College in Rochester, New York,
  USA, will be showing until November 22, 2019.
  https://www2.naz.edu/events/4318/

- TUGboat 40:3 has been sent to the printer; you may find it in your
  mailbox after a couple more weeks. The deadline for submissions for the
  next issue is March 31; as always, any TeX and typography topics are
  welcome.   https://tug.org/TUGboat/

New packages on CTAN in October:
- accessibility, a CTAN-compliant version of the accessibility package
  to generate tagged and structured PDF files;
- bxjatoucs, convert Japanese character code to Unicode;
- circledsteps, typeset circled numbers;
- gindex, a package for formatting indexes;
- imfellflowers, IM Fell Flower OpenType fonts;
- kblocks, easily typeset Control Block Diagrams and Signal Flow Graphs;
- latino-sine-flexione, LaTeX support for Peano's Interlingua;
- pdftex-djgpp, an MSDOS-DJGPP binary of the pdfTeX engine;
- pst-turtle, turtle graphics with PSTricks;
- quiz2socrative, prepare questions for socratic quizzes;
- xkcdcolors, xkcd names of colors.

Happy TeXing!
Boris Veytsman (TUG President)

From tug-news at tug.org  Wed Dec  4 23:03:25 2019
From: tug-news at tug.org (TeX Users Group)
Date: Wed, 4 Dec 2019 15:03:25 -0700
Subject: Dec19 TUG news: donations, devfund, printing history fellowship,
 dek transcript, ctan
Message-ID: <201912042203.xB4M3PhI011830@freefriends.org>

Dear TeXers,

December is upon us.  Have a great holiday season and happy 2020!

I got a number of messages from various non-profit organizations
reminding us that this is the last month to give a 2019 donation.  We
probably would be remiss if we do not join the chorus: TUG donations
are tax deductible (at least in the US), so you may want to donate to us
at https://tug.org/ (just click the "Donate" button).  If you wish to join
us, membership dues are also tax deductible less the value of benefits
($40 with the hard copy of TUGboat and TeX Live or $10 with the electronic
membership option).

Among various projects we spend the money on is the Development Fund.
Here is the list of grantees:  https://tug.org/tc/devfund/grants.html and
the grant application:  https://tug.org/tc/devfund/application.html.
The Development Fund Committee also distributes travel grants related
to development of accessible PDF tools (thanks to the Moore Foundation
for the donation).  You may apply for these grants by sending email
to devfund at tug.org.

Speaking about money, we tweeted recently about the APHA Mark Samuels
Lasner fellowship in printing history; some TeXers might be interested:
https://printinghistory.org/programs/fellowship/

On another topic.  Many of us enjoyed DEK's video interviews of 2006
(https://www.webofstories.com/play/donald.knuth/1).  We recently learned
of an edited transcript of these 97 short videos:
https://github.com/kragen/knuth-interview-2006

New packages on CTAN (https://ctan.org) in November:
- algxpar, support for pseudocode with long lines of code
- chemplants, symbology to draw chemical plants with TikZ
- fontsetup, a front-end to fontspec, for selected fonts with math support
- GFSDidotClassic, the classic version of GFSDidot for Unicode TeX engines
- hvqrurl, a package to insert a QR code in the margin
- letterswitharrows, scalable left and right arrows over mathematical symbols
- lexend, the Lexend fonts for XeLaTeX and LuaLaTeX through fontspec
- NewComputerModern, CM fonts combined with matching non-Latin alphabets
- pinoutikz, printing electronic chip pinouts with TikZ

Happy TeXing!
Boris Veytsman (TUG President)

From marchywka at hotmail.com  Sat Dec  7 12:26:32 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sat, 7 Dec 2019 11:26:32 +0000
Subject: google books bibtex
Message-ID: <DM6PR08MB6042C624DDD76814DD3DCFD2BE5E0@DM6PR08MB6042.namprd08.prod.outlook.com>


Has anyone had problems with the google bibtex entries? I don't often use google scholar bibtex
but rather the publisher. I tried it on this entry, seeing they have a bibtex button,
but got a result like this which seems incomplete, 

% srcurl:  https://books.google.com/books?id=Wi0-AQAAIAAJ&dq=ten+men+to+care+for+one+wounded&source=gbs_navlinks_s
% citeurl:  https://books.google.com/books/download/Transactions_of_the_Annual_Meeting_of_th.bibtex?id=Wi0-AQAAIAAJ&output=bibtex
% med2bib comment:  handlebiblink
% date  Sat Dec 7 06:22:01 EST 2019

@book{association1892transactions,
  title={Transactions of the ... Annual Meeting of the Association of Military Surgeons of the National Guard of the United States},
  author={Association of Military Surgeons of the National Guard of the United States. Meeting},
  lccn={sf86004020},
  series={Association of milit},
  url={https://books.google.com/books?id=Wi0-AQAAIAAJ},
  year={1892},
  publisher={The Association}
}


Is this ok or alternatives?

Thanks.

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From peter at silmaril.ie  Sun Dec  8 17:39:58 2019
From: peter at silmaril.ie (Peter Flynn)
Date: Sun, 8 Dec 2019 16:39:58 +0000
Subject: google books bibtex
In-Reply-To: <DM6PR08MB6042C624DDD76814DD3DCFD2BE5E0@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB6042C624DDD76814DD3DCFD2BE5E0@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <41d0fe02-074e-766e-1d14-98077e421953@silmaril.ie>

On 07/12/2019 11:26, Mike Marchywka wrote:
> 
> Has anyone had problems with the google bibtex entries? 

My experience is that they're entirely machine-generated, so they suffer 
from a lack of source metadata and inaccuracy in its application.

P

From alan at alphabyte.co.nz  Sun Dec  8 20:11:41 2019
From: alan at alphabyte.co.nz (Alan Litchfield)
Date: Mon, 9 Dec 2019 08:11:41 +1300
Subject: google books bibtex
In-Reply-To: <41d0fe02-074e-766e-1d14-98077e421953@silmaril.ie>
References: <DM6PR08MB6042C624DDD76814DD3DCFD2BE5E0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <41d0fe02-074e-766e-1d14-98077e421953@silmaril.ie>
Message-ID: <764E0E63-D13A-4B14-8596-19344F7FF239@alphabyte.co.nz>

I do not rely on them, nor many of the database bibtex entries. I have to instruct my students constantly to repair them before using, but the effort is relatively minor with a text editor.

--
Dr Alan Litchfield
AlphaByte
PO Box 1941
Auckland, New Zealand 1140

> On 9/12/2019, at 05:39, Peter Flynn <peter at silmaril.ie> wrote:
> 
> On 07/12/2019 11:26, Mike Marchywka wrote:
>> Has anyone had problems with the google bibtex entries? 
> 
> My experience is that they're entirely machine-generated, so they suffer from a lack of source metadata and inaccuracy in its application.
> 
> P

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20191209/b3f43983/attachment.html>

From marchywka at hotmail.com  Sun Dec  8 20:28:33 2019
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sun, 8 Dec 2019 19:28:33 +0000
Subject: google books bibtex
In-Reply-To: <764E0E63-D13A-4B14-8596-19344F7FF239@alphabyte.co.nz>
References: <DM6PR08MB6042C624DDD76814DD3DCFD2BE5E0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <41d0fe02-074e-766e-1d14-98077e421953@silmaril.ie>
 <764E0E63-D13A-4B14-8596-19344F7FF239@alphabyte.co.nz>
Message-ID: <DM6PR08MB60422477427D2554FB600ABEBE590@DM6PR08MB6042.namprd08.prod.outlook.com>

On Mon, Dec 09, 2019 at 08:11:41AM +1300, Alan Litchfield wrote:
>    I do not rely on them, nor many of the database bibtex entries. I have to instruct my students constantly to repair them
>    before using, but the effort is relatively minor with a text editor.
>
So far the entries from crossref look good most of the time but getting away from "articles" is another issue. 
Its amazingly distracting though to read literature
and then debug a bibtex entry or script in the middle of a paragraph finally starting to come together :)
Someone earlier claime Zotero had this fixed although I was curious how these things could be fixed
if the info was missing from the available entries. I'm moving my bash script to c++ and now it
will eventually try to get all available for comparison and maybe manual intervention ( similar to a code merge tool
probably lol ). Non-DOI documents are still interesting but I've found enough patterns in the sites it
is getting easier to scrape if the info is there.  
 
>    --
>    Dr Alan Litchfield
>    AlphaByte
>    PO Box 1941
>    Auckland, New Zealand 1140
> 
>    On 9/12/2019, at 05:39, Peter Flynn <[mailto:peter at silmaril.ie]peter at silmaril.ie> wrote:
> 
>    On 07/12/2019 11:26, Mike Marchywka wrote:
> 
>      Has anyone had problems with the google bibtex entries?
> 
>    My experience is that they're entirely machine-generated, so they suffer from a lack of source metadata and inaccuracy in
>    its application.

I can believe that in an old publication there will be problems but there were things like "..." in important
places... IIRC the scholar citations were very minimalist. 



>    P

-- 

mike marchywka
306 charles cox
canton GA 30115
USA, Earth 
marchywka at hotmail.com
404-788-1216
ORCID: 0000-0001-9237-455X


From alan at alphabyte.co.nz  Sun Dec  8 20:57:17 2019
From: alan at alphabyte.co.nz (Alan Litchfield)
Date: Mon, 9 Dec 2019 08:57:17 +1300
Subject: google books bibtex
In-Reply-To: <DM6PR08MB60422477427D2554FB600ABEBE590@DM6PR08MB6042.namprd08.prod.outlook.com>
References: <DM6PR08MB6042C624DDD76814DD3DCFD2BE5E0@DM6PR08MB6042.namprd08.prod.outlook.com>
 <41d0fe02-074e-766e-1d14-98077e421953@silmaril.ie>
 <764E0E63-D13A-4B14-8596-19344F7FF239@alphabyte.co.nz>
 <DM6PR08MB60422477427D2554FB600ABEBE590@DM6PR08MB6042.namprd08.prod.outlook.com>
Message-ID: <9DB69736-C2F1-43B1-8FE7-C9779F293F0B@alphabyte.co.nz>

Agreed, anything not article causes problems.

inproceedings is often problematic, especially where they are coded as articles.

I do not use database filing systems like Zotero and prefer to use an editor. The tags are then easy to navigate and anomalies are more obvious when they are not hidden by a gui. 


--
Dr Alan Litchfield
AlphaByte
PO Box 1941
Auckland, New Zealand 1140

> On 9/12/2019, at 08:28, Mike Marchywka <marchywka at hotmail.com> wrote:
> 
> On Mon, Dec 09, 2019 at 08:11:41AM +1300, Alan Litchfield wrote:
>>   I do not rely on them, nor many of the database bibtex entries. I have to instruct my students constantly to repair them
>>   before using, but the effort is relatively minor with a text editor.
>> 
> So far the entries from crossref look good most of the time but getting away from "articles" is another issue. 
> Its amazingly distracting though to read literature
> and then debug a bibtex entry or script in the middle of a paragraph finally starting to come together :)
> Someone earlier claime Zotero had this fixed although I was curious how these things could be fixed
> if the info was missing from the available entries. I'm moving my bash script to c++ and now it
> will eventually try to get all available for comparison and maybe manual intervention ( similar to a code merge tool
> probably lol ). Non-DOI documents are still interesting but I've found enough patterns in the sites it
> is getting easier to scrape if the info is there.  
> 
>>   --
>>   Dr Alan Litchfield
>>   AlphaByte
>>   PO Box 1941
>>   Auckland, New Zealand 1140
>> 
>>   On 9/12/2019, at 05:39, Peter Flynn <[mailto:peter at silmaril.ie]peter at silmaril.ie> wrote:
>> 
>>   On 07/12/2019 11:26, Mike Marchywka wrote:
>> 
>>     Has anyone had problems with the google bibtex entries?
>> 
>>   My experience is that they're entirely machine-generated, so they suffer from a lack of source metadata and inaccuracy in
>>   its application.
> 
> I can believe that in an old publication there will be problems but there were things like "..." in important
> places... IIRC the scholar citations were very minimalist. 
> 
> 
> 
>>   P
> 
> -- 
> 
> mike marchywka
> 306 charles cox
> canton GA 30115
> USA, Earth 
> marchywka at hotmail.com
> 404-788-1216
> ORCID: 0000-0001-9237-455X

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://tug.org/pipermail/texhax/attachments/20191209/a8d45d44/attachment.html>

From doug at mathemaesthetics.com  Mon Dec  9 02:18:16 2019
From: doug at mathemaesthetics.com (Doug McKenna)
Date: Sun, 8 Dec 2019 18:18:16 -0700 (MST)
Subject: Weird unasked-for file trace in LaTeX
Message-ID: <409188105.19415269.1575854296893.JavaMail.zimbra@mathemaesthetics.com>

I can't tell if this is a bug or by design, but ...

Execute this MWE for the LaTeX format (TeX Live 2017):

  \tracingcommands=3
  \tracingmacros=1
  \tracingonline=1

  \documentclass{article}
  \begin{document}
  Hello, world!
  \end{document}

This sends a whole lot of tracing to the terminal, in which the following lines appear towards the end of it all, when producing the final single page:

  \@arabic #1->\number #1
  #1<-\c at page 
  {\number}
  {the character 1}
  {\hfil}
  {end-group character }}
  {internal vertical mode: \relax}
  {end-group character }}
  {end-group character }}
  [1{/usr/local/texlive/2017/texmf-var/fonts/map/pdftex/updmap/pdftex.map}]
  {\endgroup}

Some sort of a complete file read occurs smack dab in the middle of printing out "[1]".  But notice that \tracingfiles has not been set.

Is this a bug?  Shouldn't that parenthesized file path not be output unless \tracingfiles has been set to 1?

Doug McKenna
Mathemaesthetics, Inc.

From d.p.carlisle at gmail.com  Mon Dec  9 02:43:14 2019
From: d.p.carlisle at gmail.com (David Carlisle)
Date: Mon, 9 Dec 2019 01:43:14 +0000
Subject: Weird unasked-for file trace in LaTeX
In-Reply-To: <409188105.19415269.1575854296893.JavaMail.zimbra@mathemaesthetics.com>
References: <409188105.19415269.1575854296893.JavaMail.zimbra@mathemaesthetics.com>
Message-ID: <CAEW6iOimKnGTUM7DUc3CBKfpAWgEQ3sBxf_5x+nSOS0PeGyCKQ@mail.gmail.com>

The map file line is shown on the terminal by default, even without
your tracing lines the output is


$ pdflatex cc393
This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019)
(preloaded format=pdflatex)
 restricted \write18 enabled.
entering extended mode
(./cc393.tex
LaTeX2e <2019-10-01> patch level 3
(/usr/local/texlive/2019/texmf-dist/tex/latex/base/article.cls
Document Class: article 2019/10/25 v1.4k Standard LaTeX document class
(/usr/local/texlive/2019/texmf-dist/tex/latex/base/size10.clo))
No file cc393.aux.
[1{/usr/local/texlive/2019/texmf-var/fonts/map/pdftex/updmap/pdftex.map}]
(./cc393.aux) )</usr/local/texlive/2019/texmf-dist/fonts/type1/public/amsfonts/
cm/cmr10.pfb>
Output written on cc393.pdf (1 page, 12027 bytes).
Transcript written on cc393.log.

You see the same with the plain TeX

Hello, world!

\bye

It comes between the [ (the start of the output routine) and 1] (page
1 being shipped out) as that i the first time it needs to access the
map file.

You can force it to be loaded earlier, before the [ is output by adding

\pdfmapfile{pdftex.map}

to the top of the file.

David

From tug-news at tug.org  Tue Dec 17 00:45:54 2019
From: tug-news at tug.org (TeX Users Group)
Date: Mon, 16 Dec 2019 16:45:54 -0700
Subject: Dec19 more TUG news: Gudrun Zapf (1918-2019), G21C conference in Paris
Message-ID: <201912162345.xBGNjsDC023122@freefriends.org>

Dear TeXers,

Usually we publish one TUG newsletter monthly.  This special issue
covers two important pieces of news.

1. We are very sad to learn that Gudrun Zapf von Hesse passed this
month. She was a great artist, typographer and calligrapher, and
the colleague, companion, and wife of Hermann Zapf. 

We were proud to call Hermann and Gudrun friends of TUG, and mourn
their passing after long lives of astounding accomplishments.
https://twitter.com/arabictype/status/1205585142934360066

2. Long-time TeXnician extraordinaire Yannis Haralambous has informed us
of an international conference on grapholinguistics next June in Paris,
called G212C 2020:
  https://grafematik2020.sciencesconf.org/
Yannis is among the organizers.

Among the conference topics are typography and many other topics that
may interest TUG members. The submission deadline is January 13, so if
you may be interested in speaking, don't delay.

Sincerely,
Boris Veytsman (TUG President)
https://tug.org

From kwojtus at protonmail.com  Thu Dec 19 12:58:25 2019
From: kwojtus at protonmail.com (Wojtek Kosior)
Date: Thu, 19 Dec 2019 11:58:25 +0000
Subject: Nonfree packages cc-pl, mex,
 pl and hyphen-polish in texlive distribution
Message-ID: <cMcTNFmaL5Re70pOLCgM9ZWYl4pc4n5pAtexF6EiUFx2tiP7mqsENvr63rNuypCa07wgnwn-uNOWKfJmCYGU2YeFl9XiQrZi2uSMJqf2y8M=@protonmail.com>

The following packages:

https://www.ctan.org/pkg/plhyph
https://www.ctan.org/pkg/mex
https://www.ctan.org/pkg/cc-pl
https://www.ctan.org/pkg/pl-mf

are misleadingly marked on CTAN as either being in public domain or being available under the Knuth License. Those packages do, however, use a custom, nonfree license (mex105/mexinfo/mexinfo.eng in the mex package).

>From https://www.tug.org/texlive/copying.html and https://www.ctan.org/pkg/texlive I understand, that such nonfree packages are not supposed to belong to the distribution and were included by mistake (hence I intend this mail to be, to some extent, a bug report).

I found about the nonfree parts in texlive in https://git.hyperbola.info:50100/packages/extra.git/tree/texlive-core/PKGBUILD - this PKGBUILD also treats some other packages as nonfree, which might help track them.


From karl at freefriends.org  Fri Dec 20 00:54:54 2019
From: karl at freefriends.org (Karl Berry)
Date: Thu, 19 Dec 2019 16:54:54 -0700
Subject: Nonfree packages cc-pl, mex,
 pl and hyphen-polish in texlive distribution
In-Reply-To: <cMcTNFmaL5Re70pOLCgM9ZWYl4pc4n5pAtexF6EiUFx2tiP7mqsENvr63rNuypCa07wgnwn-uNOWKfJmCYGU2YeFl9XiQrZi2uSMJqf2y8M=@protonmail.com>
Message-ID: <201912192354.xBJNssLO024777@freefriends.org>

    are misleadingly marked on CTAN

I would not say it's misleading. I'd say it's as intended, but
that the freeness bug was previously incompletely fixed.

    a custom, nonfree license (mex105/mexinfo/mexinfo.eng in the mex package).

Thanks for the report. To the best of my recollection, the intent is for
the "public domain" statement in the 00readme to take precedence over
the crazy license files; that's why the date in 00readme is later
(2003), as that is when Staszek and I (I think) tried to do something
about the non-free-ness.

Anyway, I certainly agree the situation is not made clear. I will write
the package maintainers. --best, karl.


From achirvasub at gmail.com  Mon Dec 30 17:24:07 2019
From: achirvasub at gmail.com (Stuart Little)
Date: Mon, 30 Dec 2019 11:24:07 -0500
Subject: latest tlmgr update removes mktexlsr?
Message-ID: <20191230162407.GA4999@system76-pc.localdomain>

I have vanilla installations of texlive on several Linux machines, obtained as described here[0]. The latest update, which I usually do by

> tlmgr update --self --all

seems to have removed the 'mktexlsr' executable. The output (on all three machines I currently maintain texlive on):

> 
> tlmgr: package repository <repo; they vary between computers> (verified)
> tlmgr: saving backups to ${HOME}/texlive/2019/tlpkg/backups
> [1/5, ??:??/??:??] update: kpathsea.x86_64-linux [40k] (50281 -> 53254) ... done
> [2/5, 00:01/02:45] update: newtx [5242k] (52998 -> 53255) ... done
> [3/5, 00:03/00:03] update: tex4ht [937k] (53251 -> 53257) ... done
> [4/5, 00:04/00:04] update: texlive-docindex [155k] (53237 -> 53253) ... done
> [5/5, 00:04/00:04] update: texlive-scripts [134k] (53242 -> 53253) ... done
> running mktexlsr ...
> 
> tlmgr: mktexlsr failed (status -1), output:
> 
> running updmap-sys ...
> done running updmap-sys.
> tlmgr: package log updated: /root/texlive/2019/texmf-var/web2c/tlmgr.log
> tlmgr: An error has occurred. See above messages. Exiting.
> 

To confirm, I then tried running 'mktexlsr' in a terminal. This used to work *immediately* prior to the update (after it happened twice, I tried 'mktexlsr' *before* the update on the third machine). The result is that the command is not found. I am sure that the texlive binaries are in my path (I can run 'pdflatex' fine for instance, as aregular user). 

As a sanity check, I looked inside

${HOME}/texlive/2019/bin/x86_64-linux/

where the binaries live. The 'mktexlsr' file there is a *broken* link to

../../texmf-dist/scripts/texlive/mktexlsr

---

References:

[0] https://www.tug.org/texlive/quickinstall.html

From JimDiamond at ns.sympatico.ca  Mon Dec 30 18:03:04 2019
From: JimDiamond at ns.sympatico.ca (Jim Diamond)
Date: Mon, 30 Dec 2019 13:03:04 -0400
Subject: latest tlmgr update removes mktexlsr?
In-Reply-To: <20191230162407.GA4999@system76-pc.localdomain>
References: <20191230162407.GA4999@system76-pc.localdomain>
Message-ID: <20191230170304.GA22226@jdiamond-mb.acadiau.ca>

Hi all,

amusingly I was updating TL in one window while reading Stuart's
message.  And, just like Stuart, my mktexlsr disappeared.
Actually, it didn't.  It is now a dangling symlink:

ls -l /usr/local/texlive/2019/bin/x86_64-linux/mktexlsr     
lrwxrwxrwx 1 zsd users 41 Dec 29 15:45 /usr/local/texlive/2019/bin/x86_64-linux/mktexlsr -> ../../texmf-dist/scripts/texlive/mktexlsr

I hope the fix (for the TL distribution) is easy.

Cheers.

                        Jim


On Mon, Dec 30, 2019 at 11:24 (-0500), Stuart Little wrote:

> CAUTION: This email comes from outside Acadia. Verify the sender and use caution with any requests, links or attachments.

> I have vanilla installations of texlive on several Linux machines, obtained as described here[0]. The latest update, which I usually do by

>> tlmgr update --self --all

> seems to have removed the 'mktexlsr' executable. The output (on all three machines I currently maintain texlive on):


>> tlmgr: package repository <repo; they vary between computers> (verified)
>> tlmgr: saving backups to ${HOME}/texlive/2019/tlpkg/backups
>> [1/5, ??:??/??:??] update: kpathsea.x86_64-linux [40k] (50281 -> 53254) ... done
>> [2/5, 00:01/02:45] update: newtx [5242k] (52998 -> 53255) ... done
>> [3/5, 00:03/00:03] update: tex4ht [937k] (53251 -> 53257) ... done
>> [4/5, 00:04/00:04] update: texlive-docindex [155k] (53237 -> 53253) ... done
>> [5/5, 00:04/00:04] update: texlive-scripts [134k] (53242 -> 53253) ... done
>> running mktexlsr ...

>> tlmgr: mktexlsr failed (status -1), output:

>> running updmap-sys ...
>> done running updmap-sys.
>> tlmgr: package log updated: /root/texlive/2019/texmf-var/web2c/tlmgr.log
>> tlmgr: An error has occurred. See above messages. Exiting.


> To confirm, I then tried running 'mktexlsr' in a terminal. This used to work *immediately* prior to the update (after it happened twice, I tried 'mktexlsr' *before* the update on the third machine). The result is that the command is not found. I am sure that the texlive binaries are in my path (I can run 'pdflatex' fine for instance, as aregular user).

> As a sanity check, I looked inside

> ${HOME}/texlive/2019/bin/x86_64-linux/

> where the binaries live. The 'mktexlsr' file there is a *broken* link to

> ../../texmf-dist/scripts/texlive/mktexlsr

> ---

> References:

> [0] https://www.tug.org/texlive/quickinstall.html

From rdtennent at gmail.com  Mon Dec 30 18:44:40 2019
From: rdtennent at gmail.com (Bob Tennent)
Date: Mon, 30 Dec 2019 12:44:40 -0500
Subject: latest tlmgr update removes mktexlsr?
In-Reply-To: <20191230162407.GA4999@system76-pc.localdomain>
References: <20191230162407.GA4999@system76-pc.localdomain>
Message-ID: <20191230174440.wD52rLZdU%rdtennent@gmail.com>

 >|I have vanilla installations of texlive on several Linux machines,
 >|obtained as described here[0]. The latest update, which I usually do by
 >|
 >|> tlmgr update --self --all
 >|
 >|seems to have removed the 'mktexlsr' executable. The output (on all
 >|three machines I currently maintain texlive on):

https://tug.org/pipermail/tex-live/2019-December/044612.html



From karl at freefriends.org  Mon Dec 30 23:23:57 2019
From: karl at freefriends.org (Karl Berry)
Date: Mon, 30 Dec 2019 15:23:57 -0700
Subject: latest tlmgr update removes mktexlsr?
In-Reply-To: <20191230170304.GA22226@jdiamond-mb.acadiau.ca>
Message-ID: <201912302223.xBUMNvai024623@freefriends.org>

    I hope the fix (for the TL distribution) is easy.

Yeah, it was just my brain forgetting one step :(. A fixed update is on
the TL master server now. It requires a --self update. It worked for me,
hope it won't have any new problems. And I hope it makes it around ctan
soon. Sorry again.

Herb asked (off-list) if mktexlsr will remain a symlink after the
correct update. The answer is yes. It should look like this:

bin/x86_64-linux/mktexlsr -> ../../texmf-dist/scripts/texlive/mktexlsr
  where that file should be (modulo owner/group):
-rwxr-xr-x 1 karl root 8209 Dec 29 20:18 mktexlsr

mktexlsr is now part of the texlive.infra package. --good luck to us all, karl.

From achirvasub at gmail.com  Tue Dec 31 15:12:58 2019
From: achirvasub at gmail.com (A.C.)
Date: Tue, 31 Dec 2019 09:12:58 -0500
Subject: latest tlmgr update removes mktexlsr?
In-Reply-To: <201912302223.xBUMNvai024623@freefriends.org>
References: <201912302223.xBUMNvai024623@freefriends.org>
Message-ID: <ACF484A7-1D3C-4C2C-B10D-EE0A936C6D93@gmail.com>

I can confirm that this went through fine just now; 'mktexlsr' is back in place after the latest update.

On December 30, 2019 5:23:57 PM EST, Karl Berry <karl at freefriends.org> wrote:
>    I hope the fix (for the TL distribution) is easy.
>
>Yeah, it was just my brain forgetting one step :(. A fixed update is on
>the TL master server now. It requires a --self update. It worked for
>me,
>hope it won't have any new problems. And I hope it makes it around ctan
>soon. Sorry again.
>
>Herb asked (off-list) if mktexlsr will remain a symlink after the
>correct update. The answer is yes. It should look like this:
>
>bin/x86_64-linux/mktexlsr -> ../../texmf-dist/scripts/texlive/mktexlsr
>  where that file should be (modulo owner/group):
>-rwxr-xr-x 1 karl root 8209 Dec 29 20:18 mktexlsr
>
>mktexlsr is now part of the texlive.infra package. --good luck to us
>all, karl.


