From Jerzy.Ludwichowski at umk.pl  Thu Mar  3 23:27:22 2016
From: Jerzy.Ludwichowski at umk.pl (Jerzy Ludwichowski)
Date: Thu, 3 Mar 2016 23:27:22 +0100
Subject: [texhax] BachoTeX 2016 - call for papers and registrations open
Message-ID: <56D8BA4A.9090705@umk.pl>

Please find below the call for papers for BachoTeX 2016.
To register, please visit http://www.gust.org.pl/bachotex/2016-en.

See you at the conference venue!

--Jerzy Ludwichowski
for the Organizing Commitee


Convergence: TeX, get out of the closet!
========================================

 From 13th until 17th September Warsaw will hold ATyPI's (Association
Typographique Internationale) conference ATypI16 
(http://www.atypi.org/conferences/atypi-warsaw-2016) under
the title ?Convergence?.

GUST and especially its e-foundry team, thanks to Andrzej
Tomaszewski, will participate actively (viz. https://vimeo.com/142911023,
the ATypI16 promotional video, paying extra attention from 1'10'').

This year's BachoTeX alludes to the ATypI16 theme (some BachoTeX
presentations will be later given there) though from a somewhat different
perspective. We want to discuss matters and projects which somehow
would realize the coming-out of TeX from its sort-of a niche. Since
about 5 years a great many tools and publication solutions were
made available with open source licenses.  The up-to now standard of
Corel, Word and InDesign for creating publications is being dropped in
favour of solutions based on HTML, CSS, JS and SVG. A lively open
source life blossoms.

That situation seems to be overlooked by the TeX community. We are
acting a little bit as if on the ?other side? only Windows, Word and
propriety licences and formats with which no inter-operation is
possible were prevailing. In reality the ?other side? has evolved such
that there are many more possibilities for inter-operation than
whenever in the past.

Papers/presentations
====================
Of course we look forward to the normal mix of TeX, MetaPost, ConTeXt,
LaTeX, and friends related presentations. Please not not forget fonts!

Please note the ?Call for TeX Pearls? further down.

The normal channel of offering papers is emailing proposals to the
Program Committee, but before rushing off to the mailer, please
consult the info for authors
(http://www.gust.org.pl/bachotex/2016-en/submissions).

Workshops and tutorials
=======================
The following are in initial planning:
   * making batik pennons (or streamers)
   * calligraphy (practice adorning pennons with glyphs)

Wery welcome are your own proposals for TeX-related tutorials or
introductions. If you have suggestions for tutorials or workshops by
others than yourself or about specific topics, please let us know.

Poster sessions
===============
Participants will be given the opportunity to present their TeX and
typographic results in the form of posters for which we provide
exhibition space.

TeX Pearls
==========

We continue the tradition of the ?Pearls of TeX Programming?.
MetaFont/MetaPost do also fall into that category. Details and
previously collected pearls can be found at
http://www.gust.org.pl/projects/pearls/.

Deadlines and addresses
=======================
The deadline for ?regular? abstracts and other proposals is
March 28th 2016. The deadline for final papers to appear in the
conference materials is April 11th.

Contributions should be send by email to the Program Committee:
prog-2016 at gust dot org dot pl. The PC is chaired by Bogus?aw
Jackowski (b underscore jackowski at gust dot org dot pl).


From ron.fehd.macro.maven at gmail.com  Tue Mar  8 02:20:12 2016
From: ron.fehd.macro.maven at gmail.com (Ron RJF Fehd)
Date: Mon, 7 Mar 2016 20:20:12 -0500
Subject: [texhax] OT: RIP Robert Palladino
Message-ID: <CA+9ODgsWR98KNZ4LFZkpSEEkh222U=j2DQRng9NqOvmPFmZdqw@mail.gmail.com>

NYT obituary for Rev Robert Palladino, scribe who shaped Apple's fonts

http://www.nytimes.com/2016/03/06/arts/design/rev-robert-palladino-83-scribe-who-shaped-apples-fonts.html

R. Fehd  Atlanta
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160307/01483eb1/attachment.html>

From doug at mathemaesthetics.com  Wed Mar  9 03:51:18 2016
From: doug at mathemaesthetics.com (Douglas McKenna)
Date: Tue, 8 Mar 2016 19:51:18 -0700
Subject: [texhax] Spurious kappa1 glyph in cmmi fonts?
Message-ID: <ACA2A638-1607-46F7-A637-D9284B9AC70D@mathemaesthetics.com>

Using the fonttable package, one can get a one-page picture of all 128 glyphs for the TFM character codes in any of the cmmi (Computer Modern Math Italic) fonts, using, i.e., 

%%%%%%%%%%%
\documentclass[11pt]{article}
\usepackage{fonttable}
\begin{document}
\fonttable{cmmi12}
\end{document}
%%%%%%%%%%%

But if one converts the "cmmi" file's corresponding .pfb file to an OpenType font file, and then browses the glyphs in that resultant ".otf" file, there appear to be two extra glyphs that aren't represented in the original TFM font.  The PostScript glyph names associated with these two extra glyphs are "hardspace" and "kappa1".

There are a small number of variant lower case greek glyphs in cmmi whose PostScript names end in "1" (e.g., "psi1", "rho1" , etc.).  The "kappa1" variant glyph, however, is not to be found in the fonttable output.  I can imagine someone went a little too far, realized they'd created something that wasn't in the original font, but left it in anyway so as not to lose the work, because doing so wouldn't cause any problems.

Are these spurious glyphs in the .pfb file left over from some hand conversion back in the day, or is there more method to the madness than I can surmise?  How is it possible to draw this "kappa1" glyph using just a TFM cmmi font?

Doug McKenna
Mathemaesthetics



From news3 at nililand.de  Wed Mar  9 10:23:26 2016
From: news3 at nililand.de (Ulrike Fischer)
Date: Wed, 9 Mar 2016 10:23:26 +0100
Subject: [texhax] Spurious kappa1 glyph in cmmi fonts?
References: <ACA2A638-1607-46F7-A637-D9284B9AC70D@mathemaesthetics.com>
Message-ID: <cbfhsam7k597.dlg@nililand.de>

Am Tue, 8 Mar 2016 19:51:18 -0700 schrieb Douglas McKenna:

> Using the fonttable package, one can get a one-page picture of all 128 glyphs for the TFM character codes in any of the cmmi (Computer Modern Math Italic) fonts, using, i.e., 
> 
> %%%%%%%%%%%
> \documentclass[11pt]{article}
> \usepackage{fonttable}
> \begin{document}
> \fonttable{cmmi12}
> \end{document}
> %%%%%%%%%%%
 
> But if one converts the "cmmi" file's corresponding .pfb file to
> an OpenType font file, and then browses the glyphs in that
> resultant ".otf" file, there appear to be two extra glyphs that
> aren't represented in the original TFM font. 

A pfb can contains hundreds or thousands of glyphs. The fonttable
will only show at most 256. It is quite possible and normal that a
pfb has glyphs not showns by a table.


> Are these spurious glyphs in the .pfb file left over from some
> hand conversion back in the day, or is there more method to the
> madness than I can surmise? 

I have no idea, I also didn't inspect the font to see if they are
really there or if the conversion process simply got confused. 


> How is it possible to draw this
> "kappa1" glyph using just a TFM cmmi font? 

If such a glyph is in the font that you can create an encoding
vector and a tfm to access it. 

-- 
Ulrike Fischer 
http://www.troubleshooting-tex.de/


From bnb at ams.org  Wed Mar  9 14:25:11 2016
From: bnb at ams.org (Barbara Beeton)
Date: Wed, 9 Mar 2016 08:25:11 -0500
Subject: [texhax] Spurious kappa1 glyph in cmmi fonts?
In-Reply-To: <ACA2A638-1607-46F7-A637-D9284B9AC70D@mathemaesthetics.com>
References: <ACA2A638-1607-46F7-A637-D9284B9AC70D@mathemaesthetics.com>
Message-ID: <alpine.LRH.2.00.1603090818210.8391@snort.ams.org>

On Tue, 8 Mar 2016, Douglas McKenna wrote:

    Using the fonttable package, one can get a one-page picture of all
    128 glyphs for the TFM character codes in any of the cmmi
    (Computer Modern Math Italic) fonts, using, i.e.,
    
    %%%%%%%%%%%
    \documentclass[11pt]{article}
    \usepackage{fonttable}
    \begin{document}
    \fonttable{cmmi12}
    \end{document}
    %%%%%%%%%%%
    
    But if one converts the "cmmi" file's corresponding .pfb file to an
    OpenType font file, and then browses the glyphs in that resultant
    ".otf" file, there appear to be two extra glyphs that aren't
    represented in the original TFM font.  The PostScript glyph names
    associated with these two extra glyphs are "hardspace" and "kappa1".

"kappa1" is almost certainly what is also
called \varkappa, and that glyph is in the
msbm font at "7B.  it was never in cmmi,
but was found to be needed and added in a
different font.  (the fonts at that time
were limited to 128 glyphs.)

presumably the choice to add it to the cmmi
.pfb is that it really makes more sense
grouped with the other variant greeks.

    Are these spurious glyphs in the .pfb file left over from some hand
    conversion back in the day, or is there more method to the madness
    than I can surmise?  How is it possible to draw this "kappa1" glyph
    using just a TFM cmmi font?

just use \varkappa from the msbm font;
there should also be a .pfb file for that.
					-- bb


From great123456 at mail.com  Thu Mar 10 06:05:56 2016
From: great123456 at mail.com (great123456 at mail.com)
Date: Thu, 10 Mar 2016 00:05:56 -0500
Subject: [texhax] Multi toc
Message-ID: <20160310000556.26ca9b8f@ulgy_thing>

Hello,
I wanted to create an FAQ that uses multiple TOCs, but I'm not certain
how. I also wanted to reference some of the entries from others.

Here's an example of the desired output:
##################################
			PAGE-X
1: Flowers
2: Rocks

			PAGE-Y
Flowers
1: Perennial
2: Annual
...
			PAGE-Z
Rocks
1: Sedimentary
2: Igneous
   See other cool rocks under <a>3</a>
3: Metamorphic
...
###################################

Thanks, David

From tug-news at tug.org  Sun Mar 13 00:17:12 2016
From: tug-news at tug.org (TeX Users Group)
Date: Sat, 12 Mar 2016 23:17:12 +0000
Subject: [texhax] March 2016 TUG news: Conferences, TUGboat, TeX Live
Message-ID: <201603122317.u2CNHCoc008460@freefriends.org>

Fellow TeX-ers,

Here in Vermont USA, spring is stirring.  The sun is just starting
to feel warm.  Most important, the liquid gold, maple syrup, is
flowing.  Next comes one of our extra seasons, mud season, and after
that spring will arrive.  Now is the right time to dream plans for
the summer.

1) The big news here is the announcement earlier this week that
registration is open for the 2016 Annual Meeting.  You can dream of
Toronto, Canada, from July 25-27, 2016; see
http://www.tug.org/tug2016/.

We expect presentations on a wide variety of topics --- new TeX
developments, publishing, practical use of LaTeX, plain TeX,
ConTeXt, MetaPost, and the rest of the TeX family, or any topic
related to the TeX world. The program list is growing so check the
latest on the web page http://www.tug.org/tug2016/program.html.

Please consider submitting a presentation of your own.  We are
interested in presentations at any level, including tutorials. To
submit, visit http://www.tug.org/tug2016/cfp.html.  The deadline for
abstracts is May 1.

This year we will have three special guests. The first is Chuck
Bigelow, of Bigelow and Holmes, a designer of the Lucida and
Wingdings font families.  The second is Kevin Larson of Microsoft
Advanced Reading Technologies, who has been influential in
improvements to rendering technologies.  The third is Robert
Bringhurst, known to TeXies for his reference *The Elements of
Typographic Style*.

One of the best things about a TUG conference is the informal fun
with other TeX folks.  This year we have arranged a record number of
excursions, including a Typography Excursion (at no additional
charge), a baseball game, Niagara-on-the-Lake and Niagara Falls,
Guelph, and Georgian Bay.  See
http://www.tug.org/tug2016/excursions.html.

We've reserved rooms for conference participants at the Bond Place
Hotel.  The conference page http://www.tug.org/tug2016/ has a link
to make online reservations.  The conference rate is guaranteed
until June 25, 2016.

Don't forget that the TUG Bursary Fund provides assistance for
members of the TeX community who would, for financial reasons,
otherwise be unable to attend.  If this applies to you, do not
hesitate to fill out an application at
https://tug.org/bursary/2016app.html.
 
2) The submission deadline for TUGboat 37:1 is just about today, but
the editors could accept new articles for another few days.
TUGboat is interested in articles over a wide array of subjects that
pertain to TeX and friends.  Especially welcome are tutorials and
introductions.  See https://tug.org/TUGboat/ for more.

3) The TeX Live team report steady progress on the 2016 release. A
tentative release schedule is on the home page
https://tug.org/texlive.  The goal is to have the public release
around the beginning of June.  Thank you to all contributors; more
contributors, including testers, are always welcome; see
https://tug.org/texlive/contribute.html.

4) The 24th yearly GUST BachoTeX conference in 2016 will be held
from April 29 to May 3 in the northeast of Poland.  It certainly
promises to be an intriguing conference (quoting from the call for
papers):

"We want to discuss matters and projects which somehow would realize
the coming-out of TeX from its sort-of a niche. Since about 5 years
a great many tools and publication solutions were made available
with open source licenses.  The up-to now standard of Corel, Word
and InDesign for creating publications is being dropped in favor of
solutions based on HTML, CSS, JS and SVG. A lively open source life
blossoms."

"That situation seems to be overlooked by the TeX community. We are
acting a little bit as if on the `other side' only Windows, Word and
propriety licenses and formats with which no inter-operation is
possible were prevailing. In reality the `other side' has evolved
such that there are many more possibilities for inter-operation than
whenever in the past."

For more, see their page http://www.gust.org.pl/bachotex/2016-en.

5) The 10th International ConTeXt Meeting conference is a bit
further out but still worth keeping an eye on, scheduled for
September 25-October 1, 2016.  It will be in Kalenberg, The
Netherlands, with this year's theme being "Piece of Cake".

6) In closing, a reminder: we continue our 2016
members-bring-members drive.  The TUG membership form at
https://tug.org/join.html contains the question for new members:
"Who invited you to join TUG?" If a new member lists you then you
will receive as a thank-you a postcard made by long-time TUG member
Peter Wilson on his letterpress (or any physical item from the TUG
store).  At the end of 2016, we will hold a drawing and the person
selected will receive a special prize: a limited edition of Manuale
Zapficum, 2009, a tribute to the great typeface designer.  For more
see https://tug.org/membership/.

Happy TeXing,
Jim Hefferon, for the TUG Board

From neal at walfield.org  Mon Mar 14 17:21:29 2016
From: neal at walfield.org (Neal H. Walfield)
Date: Mon, 14 Mar 2016 17:21:29 +0100
Subject: [texhax] highly condensed font in a figure
Message-ID: <87shzt6nee.wl-neal@walfield.org>

Hi,

I need to display a short code listing in a paper that I'm working on.
Since I don't have much space, I figured I'd try to use a highly
condensed font.  I found the following question on stack exchange,
which looked promising:

  https://tex.stackexchange.com/questions/47489/looking-for-monospaced-condensed-font

Unfortunately, it doesn't work for me in a figure (MWE follows).  I
have no idea why and my search engine foo has failed me.  Any ideas?

Thanks in advance!

:) Neal

\documentclass{article}

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{lipsum}

\begin{document}
\ttfamily\lipsum[1]

{\small\fontseries{lc}\selectfont
\lipsum[1]}

\begin{figure}
{\small\fontseries{lc}\selectfont
  \lipsum[1]}
\caption{Figure}
\end{figure}

\end{document}

From pdgessler at gmail.com  Mon Mar 14 17:44:59 2016
From: pdgessler at gmail.com (Paul Gessler)
Date: Mon, 14 Mar 2016 11:44:59 -0500
Subject: [texhax] highly condensed font in a figure
In-Reply-To: <87shzt6nee.wl-neal@walfield.org>
References: <87shzt6nee.wl-neal@walfield.org>
Message-ID: <CAPT88+B1xY7vP6o1vAYfvvxvx8VGTfh4ruD2Wdzx8io4JcOnXg@mail.gmail.com>

Hi Neal,

You just need to re-select \ttfamily inside the figure environment:

\begin{figure}
{\ttfamily\small\fontseries{lc}\selectfont
  \lipsum[1]}
\caption{Figure}
\end{figure}

Without this, the font selected inside the figure reverts to the
normal document font, Latin Modern Roman (lmr), which does not provide
a light condensed (lc) series. Note the font substitution warning
produced:

LaTeX Font Warning: Font shape `T1/lmr/lc/n' undefined
(Font)              using `T1/lmr/m/n' instead on input line 14.

Hope this helps,

PG

On Mon, Mar 14, 2016 at 11:21 AM, Neal H. Walfield <neal at walfield.org> wrote:
> Hi,
>
> I need to display a short code listing in a paper that I'm working on.
> Since I don't have much space, I figured I'd try to use a highly
> condensed font.  I found the following question on stack exchange,
> which looked promising:
>
>   https://tex.stackexchange.com/questions/47489/looking-for-monospaced-condensed-font
>
> Unfortunately, it doesn't work for me in a figure (MWE follows).  I
> have no idea why and my search engine foo has failed me.  Any ideas?
>
> Thanks in advance!
>
> :) Neal
>
> \documentclass{article}
>
> \usepackage[T1]{fontenc}
> \usepackage{lmodern}
> \usepackage{lipsum}
>
> \begin{document}
> \ttfamily\lipsum[1]
>
> {\small\fontseries{lc}\selectfont
> \lipsum[1]}
>
> \begin{figure}
> {\small\fontseries{lc}\selectfont
>   \lipsum[1]}
> \caption{Figure}
> \end{figure}
>
> \end{document}
> _______________________________________________
> TeX FAQ: http://www.tex.ac.uk/faq
> Mailing list archives: http://tug.org/pipermail/texhax/
> More links: http://tug.org/begin.html
>
> Automated subscription management: http://tug.org/mailman/listinfo/texhax
> Human mailing list managers: postmaster at tug.org

From d.p.carlisle at gmail.com  Mon Mar 14 17:45:04 2016
From: d.p.carlisle at gmail.com (David Carlisle)
Date: Mon, 14 Mar 2016 16:45:04 +0000
Subject: [texhax] highly condensed font in a figure
In-Reply-To: <87shzt6nee.wl-neal@walfield.org>
References: <87shzt6nee.wl-neal@walfield.org>
Message-ID: <CAEW6iOjUHQ6bfB2YnZqEMKP0szZCV0ctn2T7C=XvBg8Kn8S2FQ@mail.gmail.com>

For some reason the fd file sets up the "light condensed" font as c not lc so:

\documentclass{article}

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{lipsum}

\begin{document}
\ttfamily\lipsum[1]

{\small\fontseries{c}\selectfont
\lipsum[1]}

\begin{figure}
{\small\ttfamily\fontseries{c}\selectfont
  \lipsum[1]}
\caption{Figure}
\end{figure}

\end{document}

On 14 March 2016 at 16:21, Neal H. Walfield <neal at walfield.org> wrote:
> Hi,
>
> I need to display a short code listing in a paper that I'm working on.
> Since I don't have much space, I figured I'd try to use a highly
> condensed font.  I found the following question on stack exchange,
> which looked promising:
>
>   https://tex.stackexchange.com/questions/47489/looking-for-monospaced-condensed-font
>
> Unfortunately, it doesn't work for me in a figure (MWE follows).  I
> have no idea why and my search engine foo has failed me.  Any ideas?
>
> Thanks in advance!
>
> :) Neal
>
> \documentclass{article}
>
> \usepackage[T1]{fontenc}
> \usepackage{lmodern}
> \usepackage{lipsum}
>
> \begin{document}
> \ttfamily\lipsum[1]
>
> {\small\fontseries{lc}\selectfont
> \lipsum[1]}
>
> \begin{figure}
> {\small\fontseries{lc}\selectfont
>   \lipsum[1]}
> \caption{Figure}
> \end{figure}
>
> \end{document}
> _______________________________________________
> TeX FAQ: http://www.tex.ac.uk/faq
> Mailing list archives: http://tug.org/pipermail/texhax/
> More links: http://tug.org/begin.html
>
> Automated subscription management: http://tug.org/mailman/listinfo/texhax
> Human mailing list managers: postmaster at tug.org



-- 
http://dpcarlisle.blogspot.com/

From d.p.carlisle at gmail.com  Mon Mar 14 17:49:14 2016
From: d.p.carlisle at gmail.com (David Carlisle)
Date: Mon, 14 Mar 2016 16:49:14 +0000
Subject: [texhax] highly condensed font in a figure
In-Reply-To: <CAPT88+B1xY7vP6o1vAYfvvxvx8VGTfh4ruD2Wdzx8io4JcOnXg@mail.gmail.com>
References: <87shzt6nee.wl-neal@walfield.org>
 <CAPT88+B1xY7vP6o1vAYfvvxvx8VGTfh4ruD2Wdzx8io4JcOnXg@mail.gmail.com>
Message-ID: <CAEW6iOhuOUz6813j8KEvZMC2XCgfO4YG9Ma9C0A+V_E5aoVnTA@mail.gmail.com>

Neil, do what Paul said:-)

David

From neal at walfield.org  Mon Mar 14 17:58:32 2016
From: neal at walfield.org (Neal H. Walfield)
Date: Mon, 14 Mar 2016 17:58:32 +0100
Subject: [texhax] highly condensed font in a figure
In-Reply-To: <CAPT88+B1xY7vP6o1vAYfvvxvx8VGTfh4ruD2Wdzx8io4JcOnXg@mail.gmail.com>
References: <87shzt6nee.wl-neal@walfield.org>
 <CAPT88+B1xY7vP6o1vAYfvvxvx8VGTfh4ruD2Wdzx8io4JcOnXg@mail.gmail.com>
Message-ID: <87r3fd6lon.wl-neal@walfield.org>

On Mon, 14 Mar 2016 17:44:59 +0100,
Paul Gessler wrote:
> You just need to re-select \ttfamily inside the figure environment:

Thanks!  This worked for me!

:) Neal

> 
> \begin{figure}
> {\ttfamily\small\fontseries{lc}\selectfont
>   \lipsum[1]}
> \caption{Figure}
> \end{figure}
> 
> Without this, the font selected inside the figure reverts to the
> normal document font, Latin Modern Roman (lmr), which does not provide
> a light condensed (lc) series. Note the font substitution warning
> produced:
> 
> LaTeX Font Warning: Font shape `T1/lmr/lc/n' undefined
> (Font)              using `T1/lmr/m/n' instead on input line 14.
> 
> Hope this helps,
> 
> PG
> 
> On Mon, Mar 14, 2016 at 11:21 AM, Neal H. Walfield <neal at walfield.org> wrote:
> > Hi,
> >
> > I need to display a short code listing in a paper that I'm working on.
> > Since I don't have much space, I figured I'd try to use a highly
> > condensed font.  I found the following question on stack exchange,
> > which looked promising:
> >
> >   https://tex.stackexchange.com/questions/47489/looking-for-monospaced-condensed-font
> >
> > Unfortunately, it doesn't work for me in a figure (MWE follows).  I
> > have no idea why and my search engine foo has failed me.  Any ideas?
> >
> > Thanks in advance!
> >
> > :) Neal
> >
> > \documentclass{article}
> >
> > \usepackage[T1]{fontenc}
> > \usepackage{lmodern}
> > \usepackage{lipsum}
> >
> > \begin{document}
> > \ttfamily\lipsum[1]
> >
> > {\small\fontseries{lc}\selectfont
> > \lipsum[1]}
> >
> > \begin{figure}
> > {\small\fontseries{lc}\selectfont
> >   \lipsum[1]}
> > \caption{Figure}
> > \end{figure}
> >
> > \end{document}
> > _______________________________________________
> > TeX FAQ: http://www.tex.ac.uk/faq
> > Mailing list archives: http://tug.org/pipermail/texhax/
> > More links: http://tug.org/begin.html
> >
> > Automated subscription management: http://tug.org/mailman/listinfo/texhax
> > Human mailing list managers: postmaster at tug.org
> 

From news3 at nililand.de  Mon Mar 14 18:53:32 2016
From: news3 at nililand.de (Ulrike Fischer)
Date: Mon, 14 Mar 2016 18:53:32 +0100
Subject: [texhax] highly condensed font in a figure
References: <87shzt6nee.wl-neal@walfield.org>
Message-ID: <kb3hz79z87y7$.dlg@nililand.de>

Am Mon, 14 Mar 2016 17:21:29 +0100 schrieb Neal H. Walfield:

> Hi,
> 
> I need to display a short code listing in a paper that I'm working on.
> Since I don't have much space, I figured I'd try to use a highly
> condensed font.  I found the following question on stack exchange,
> which looked promising:
> 
>   https://tex.stackexchange.com/questions/47489/looking-for-monospaced-condensed-font
> 
> Unfortunately, it doesn't work for me in a figure (MWE follows).  I
> have no idea why and my search engine foo has failed me.  Any ideas?

The \ttfamily is missing (figure resets the family to \familydefault
which is \rmfamily in your document).

 \begin{figure}
 {\small\ttfamily\fontseries{lc}\selectfont
   \lipsum[1]}
 \caption{Figure}
 \end{figure}




-- 
Ulrike Fischer 
http://www.troubleshooting-tex.de/


From hymie at lactose.homelinux.net  Mon Mar 14 20:01:00 2016
From: hymie at lactose.homelinux.net (hymie!)
Date: Mon, 14 Mar 2016 19:01:00 +0000
Subject: [texhax] CTAN: TeX, not LaTeX
Message-ID: <slrnnee2jc.g1b.hymie@lactose.homelinux.net>

Greetings.

This is probaby the wrong place to ask, but I just don't know where to
start.

I use TeX as my primary text processing language.  I'm trying to get a
little fancy with some of my stuff, and I'm looking at CTAN for
modules that might help.

Most (if not all) of the modules and stuff on CTAN is for LaTeX.

How can I find modules, add-ins, tips, tricks, and such that are
strictly for TeX and not for LaTeX?

--hymie!    http://lactose.homelinux.net/~hymie    hymie at lactose.homelinux.net


From karl at freefriends.org  Tue Mar 15 00:12:40 2016
From: karl at freefriends.org (Karl Berry)
Date: Mon, 14 Mar 2016 23:12:40 +0000
Subject: [texhax] CTAN: TeX, not LaTeX
In-Reply-To: <slrnnee2jc.g1b.hymie@lactose.homelinux.net>
Message-ID: <201603142312.u2ENCeIq024246@freefriends.org>

Hi Hymie,

    This is probaby the wrong place to ask, 

It's fine.

    How can I find modules, add-ins, tips, tricks, and such that are
    strictly for TeX and not for LaTeX?

Some package listings:
http://ctan.org/tex-archive/macros/plain
http://ctan.org/tex-archive/macros/generic
http://ctan.org/topic/plain-ext

Some documentation:
http://ctan.org/topic/tut-plaintex

Those will surely lead to other places ... hope this helps, karl.

From P.Taylor at Rhul.Ac.Uk  Tue Mar 15 11:27:21 2016
From: P.Taylor at Rhul.Ac.Uk (Philip Taylor)
Date: Tue, 15 Mar 2016 10:27:21 +0000
Subject: [texhax] CTAN: TeX, not LaTeX
In-Reply-To: <slrnnee2jc.g1b.hymie@lactose.homelinux.net>
References: <slrnnee2jc.g1b.hymie@lactose.homelinux.net>
Message-ID: <56E7E389.7020603@Rhul.Ac.Uk>



hymie! wrote:
.
> 
> I use TeX as my primary text processing language.  I'm trying to get a
> little fancy with some of my stuff, and I'm looking at CTAN for
> modules that might help.
> 
> Most (if not all) of the modules and stuff on CTAN is for LaTeX.
> 
> How can I find modules, add-ins, tips, tricks, and such that are
> strictly for TeX and not for LaTeX?

I also use plain TeX, but tend to write everything from scratch; if you
can tell me what sort of things you are trying to attempt, I may be able
to offer some ideas.

Philip Taylor

From hymie at lactose.homelinux.net  Tue Mar 15 12:09:56 2016
From: hymie at lactose.homelinux.net (hymie at lactose.homelinux.net)
Date: Tue, 15 Mar 2016 07:09:56 -0400
Subject: [texhax] CTAN: TeX, not LaTeX
In-Reply-To: <56E7E389.7020603@Rhul.Ac.Uk>
References: <slrnnee2jc.g1b.hymie@lactose.homelinux.net>
 <56E7E389.7020603@Rhul.Ac.Uk>
Message-ID: <E1afmrM-0004lC-LQ@lactose.homelinux.net>

Philip Taylor writes:
>
>I also use plain TeX, but tend to write everything from scratch; if you
>can tell me what sort of things you are trying to attempt, I may be able
>to offer some ideas.

Thanks for the offer.

Right now, my obstacle is this:

I have a TeX file that prints 10-up business cards in vboxes 2 inches
high and half-a-page wide.  Unfortunately, it prints them line by line
top to bottom:

\def\bigline{\largeheadfont My Name}
\def\lineone{My address}
\def\linetwo{City State Zip}
\def\linethr{Phone numbers}
\def\linefou{Email address}

\vbox to2truein{
\settabs2\columns
\vfil
\+\hfill\bigline\hfill&\hfill\bigline\hfill&\cr
\+\hfill\lineone\hfill&\hfill\lineone\hfill&\cr
\+\hfill\linetwo\hfill&\hfill\linetwo\hfill&\cr
\+\hfill\linethr\hfill&\hfill\linethr\hfill&\cr
\+\hfill\linefou\hfill&\hfill\linefou\hfill&\cr
\vfil}

And I was trying to figure out a way to print them card by card
sort of like this:

\vbox to2truein{
\settabs2\columns
\vfil
\+\hfill stuff \hfill (newline)
\hfill stuff \hfill (newline)
\hfill stuff \hfill (newline)
\hfill stuff \hfill (newline)
&
\hfill stuff \hfill (newline)
\hfill stuff \hfill (newline)
\hfill stuff \hfill (newline)
\hfill stuff \hfill (newline)
\vfil}

But as far as I can tell, I can't get "settabs" to work in this manner.

Years ago, I used to have a "cassette.tex" file that (I think) created
boxes of text and specifically placed them in specific places.  But
I can't seem to find it.

Anyway, it was my hope that, once I figured out how to do that, I could
use that as a "template" for other similar but more complex stuff.

--hymie!    http://lactose.homelinux.net/~hymie    hymie at lactose.homelinux.net

From luecking at uark.edu  Tue Mar 15 23:00:55 2016
From: luecking at uark.edu (Daniel H. Luecking)
Date: Tue, 15 Mar 2016 22:00:55 +0000
Subject: [texhax] CTAN: TeX, not LaTeX
Message-ID: <94de458dd96c4bd0813e12a7bb1f8fed@ex-mbx4a.uark.edu>

Hymie:

I print mailing lists as follows, 2 \hboxes side-by-side.
\labheight and \labwidth are the dimensions of each card.

\noindent
\hbox to \labwidth{
  \vtop to \labheight{
    \halign{#\hfil\cr
      Jane Doe\cr
      100 Rocky Rd.\cr
      Ice Cream, AR 72777\cr
    }\vss
  }\hss
}\hfil
\hbox to \labwidth{%
  \vtop to\labheight{%
    \halign{#\hfil\cr
      John Edo\cr
      100 Butter Pecan St.\cr
      Ice Cream, AR 72777\cr
    }\vss
  }\hss
}\par

Of course I use some simple macro definitions to shorten this.
I also read the addresses from a file in which each record
Already has the format:
{Jane Doe\cr
100 Rocky Rd.\cr
Ice Cream, AR 72777\cr
}

Good luck,


Daniel H. Luecking, Graduate Coordinator
Dept. of Mathematical Sciences
University of Arkansas
Fayetteville, AR, USA

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160315/af5259d0/attachment-0001.html>

From BD at bdtechconcepts.com  Wed Mar 16 10:07:01 2016
From: BD at bdtechconcepts.com (Brian Dunn)
Date: Wed, 16 Mar 2016 04:07:01 -0500
Subject: [texhax] =?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTML_c?=
	=?utf-8?q?onversion?=
Message-ID: <201603160407.01780.BD@bdtechconcepts.com>

An initial version of the lwarp package is now available for testing.

This is a LaTeX package which causes LaTeX to directly generate HTML tags, 
using pdftotext and a few other utilities to convert the resulting PDF file 
into HTML files.

For more details:
http://bdtechconcepts.com/bdtech-LaTeX-HTML5-Generation-lwarp-package.html


Please let me know of any feedback or suggestions.


Brian


-- 
Brian Dunn
BD Tech Concepts LLC
http://www.BDTechConcepts.com
bd at BDTechConcepts.com

http://www.linkedin.com/in/bdtechconcepts/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160316/64441e53/attachment.html>

From ghaverla at materialisations.com  Thu Mar 17 02:36:14 2016
From: ghaverla at materialisations.com (Gordon Haverland)
Date: Wed, 16 Mar 2016 19:36:14 -0600
Subject: [texhax] TeX, and a GUI called IUP
Message-ID: <20160316193614.7d3426db@newmain.materia>

I don't speak Portuguese or Lua worth a darn.

But, some enterprising soul in Brazil, has put together a GUI called
IUP.  It was meant to operate in a way similar to TeX, it stacks boxes
horizontally and vertically.  The boxes being frames in a GUI.

I believe the original work was C++ and extended to Lua.  Where I ran
across this work, is that it seems to be the newest GUI environment at
CPAN (Perl stuff).  If you want to play with it in Perl, you need to
work at installing the Alien::IUP package first, which has a bunch of
development dependencies.

The Perl documentation and examples are limited.  There seems to be
more in C++ and Lua at a site in Brazil (which has English
documentation, so that idiots like me can get by).

But I wonder, are there examples of this GUI in the wild, that a person
can learn from?  Preferably in Perl.

And second, it may be that some of you texhax, might find this
interesting.

My apologies if this is not close enough to topic.

Gord


From martin at oneiros.de  Thu Mar 17 15:47:09 2016
From: martin at oneiros.de (=?UTF-8?Q?Martin_Schr=C3=B6der?=)
Date: Thu, 17 Mar 2016 15:47:09 +0100
Subject: [texhax]
	=?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTML_c?=
	=?utf-8?q?onversion?=
In-Reply-To: <201603160407.01780.BD@bdtechconcepts.com>
References: <201603160407.01780.BD@bdtechconcepts.com>
Message-ID: <CAP7DCDf==dJYfzAKjyyHBoDyV+iWmSWPT_-eSo30wbaiz+sHEg@mail.gmail.com>

2016-03-16 10:07 GMT+01:00 Brian Dunn <BD at bdtechconcepts.com>:
> http://bdtechconcepts.com/bdtech-LaTeX-HTML5-Generation-lwarp-package.html

Look interesting. Upload it to CTAN, please.

Best
   Martin

From BD at bdtechconcepts.com  Thu Mar 17 19:27:01 2016
From: BD at bdtechconcepts.com (Brian Dunn)
Date: Thu, 17 Mar 2016 13:27:01 -0500
Subject: [texhax]
 =?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTML_c?=
 =?utf-8?q?onversion?=
In-Reply-To: <CAP7DCDf==dJYfzAKjyyHBoDyV+iWmSWPT_-eSo30wbaiz+sHEg@mail.gmail.com>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <CAP7DCDf==dJYfzAKjyyHBoDyV+iWmSWPT_-eSo30wbaiz+sHEg@mail.gmail.com>
Message-ID: <201603171327.01669.BD@bdtechconcepts.com>


> > http://bdtechconcepts.com/bdtech-LaTeX-HTML5-Generation-lwarp-package.html
> Upload it to CTAN, please.

I hope to do so.  I am adding things almost daily, though.

Brian


-- 
Brian Dunn
BD Tech Concepts LLC
http://www.BDTechConcepts.com
bd at BDTechConcepts.com

http://www.linkedin.com/in/bdtechconcepts/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160317/e67493ab/attachment.html>

From uwe.lueck at web.de  Mon Mar 21 01:08:57 2016
From: uwe.lueck at web.de (Uwe Lueck)
Date: Mon, 21 Mar 2016 01:08:57 +0100
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTML_?=
 =?utf-8?q?conversion?=
In-Reply-To: <201603160407.01780.BD@bdtechconcepts.com>
References: <201603160407.01780.BD@bdtechconcepts.com>
Message-ID: <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>

> This is a LaTeX package which causes LaTeX to directly generate HTML tags,
> using pdftotext and a few other utilities to convert the resulting PDF file
> into HTML files.

The approach is interesting, yet if you convert LaTeX to PDF 
and the result to HTML, the meaning of "direct" forbids calling 
this a "direct" generation of HTML. It is just as "direct" as 
the late Eitan Gurari's tex4ht.

I have never used tex4ht, but my impression is that this is the 
most promising way to get HTML from LaTeX. So you should tell
what lwarp offers that tex4ht doesn't.

Now as to "native": There are LaTeX-to-HTML converters that use 
Perl or things like this (Pandoc). For those I could accept 
calling them "direct" conversion, but not "native", as they use 
external software for the conversion rather than the LaTeX 
typesetting system. A problem with this approach is that the 
author's custom macros cannot be processed.

I should not advertise my blog package in the moreyhpe bundle

    http://ctan.org/pkg/morehype

(at present) but the original posting provokes the question 
of what "native" conversion of LaTeX to HTML could be: 
With blog.sty, the source code is actually parsed by LaTeX 
(I consider it so perverse to parse LaTeX source code 
 by non-TeX software), and it "directly" \writes HTML, 
the TeX macros expand to HTML.

Cheers,

    Uwe.


From BD at bdtechconcepts.com  Mon Mar 21 03:22:00 2016
From: BD at bdtechconcepts.com (Brian Dunn)
Date: Sun, 20 Mar 2016 21:22:00 -0500
Subject: [texhax]  lwarp vs. tex4ht
In-Reply-To: <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
Message-ID: <201603202122.00552.BD@bdtechconcepts.com>

On Sunday, March 20, 2016, Uwe Lueck wrote:
> > This is a LaTeX package which causes LaTeX to directly generate HTML
> > tags, using pdftotext and a few other utilities to convert the resulting
> > PDF file into HTML files.
> 
> The approach is interesting, yet if you convert LaTeX to PDF
> and the result to HTML, the meaning of "direct" forbids calling
> this a "direct" generation of HTML. It is just as "direct" as
> the late Eitan Gurari's tex4ht.

The difference being that in the case of lwarp, LaTeX itself is deciding and 
generating the HTML tags.  The only post-processing is the extraction of text 
from PDF, which is then renamed with an .html suffix.  (Also, there is 
additional processing of graphics images by other programs.)

> I have never used tex4ht, but my impression is that this is the
> most promising way to get HTML from LaTeX. So you should tell
> what lwarp offers that tex4ht doesn't.

tex4ht does a reasonable conversion when fed the lwarp test suite.  There are 
some differences in ability and ease of configuration.

Based on a quick review of the tex4ht interpretation of the lwarp test suite, 
differences include:

- xcolor color box and frame box
- HTML entities for various kinds of fixed-width spaces
- epigraphs
- lwarp doesn't do tabular <{} and >{} columns yet, or | vertical rules
- lwarp does prettier booktabs, but cannot do (lr) trimming yet
- they each have different ideas about vertical alignment of tabular rows, but 
LaTeX and HTML have different abilities here, and they do not totally overlap.
- math can be MathML in tex4ht, and is svg with LaTeX copy/paste in lwarp
- sfrac is better in lwarp
- \nameref to a figure gives the section name in tex4ht but the figure caption 
in lwarp
- \pageref provides a useful link in lwarp
- lwarp can do rotatebox, scalebox, and reflectbox (thanks to CSS3), but HTML 
does not adapt the whitespace appropriately, so this is of limited use.
- tex4ht didn't handle a picture environment in an fbox.  Vertical space was 
not provided.  This seems to be true of all the boxes in the test suite.
- texh4 didn't handle an fbox with tikz inside, but I haven't tried very hard 
to get it to work yet.
- tex4ht places footnotes on a separate HTML page ( this may be a 
configuration option).  lwarp places them at the bottom of each section or 
HTML page.
- By default, tex4ht is placing newlist items inline, but I haven't tried to 
change it yet.
- Due to CSS3, lwarp is able to place minipages side-by-side with user-
selectable vertical alignment.
- Also due to CSS3, lwarp is able to use multiple columns, which adapt to page 
width.
- lwarp can float-right the comments in algorithmicx.
- lwarp generates less clutter in the HTML output.  (Where it comes to math, 
they're both pretty bad. Lots of images v.s. lots of MathML.)
- texh4 can generate several kinds of output beyond HTML

The package and test suite are both provided in the .zip file found on the 
website below.


Brian


-- 
Brian Dunn
BD Tech Concepts LLC
http://www.BDTechConcepts.com
bd at BDTechConcepts.com

http://www.linkedin.com/in/bdtechconcepts/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160320/fded283a/attachment-0001.html>

From d.ginev at jacobs-university.de  Mon Mar 21 03:28:44 2016
From: d.ginev at jacobs-university.de (Deyan Ginev)
Date: Sun, 20 Mar 2016 22:28:44 -0400
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTML_?=
 =?utf-8?q?conversion?=
In-Reply-To: <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
Message-ID: <56EF5C5C.4040806@jacobs-university.de>

Dear all,

Since I noticed there is a brief tex -> html discussion going on, let me
add one more perspective here. I'm a contributor to the LaTeXML
conversion project, which I am guessing is the one implied by the
reference to "Perl" in Uwe's last email.


On 20.03.2016 20:08, Uwe Lueck wrote:
>> This is a LaTeX package which causes LaTeX to directly generate HTML tags,
>> using pdftotext and a few other utilities to convert the resulting PDF file
>> into HTML files.
> The approach is interesting, yet if you convert LaTeX to PDF 
> and the result to HTML, the meaning of "direct" forbids calling 
> this a "direct" generation of HTML. It is just as "direct" as 
> the late Eitan Gurari's tex4ht.

Another point to sneak in here is now that libarries such as "pdf.js"
exist, and browsers have native PDF previews via the HTML5 canvas,
having a TeX-near mapping from PDF to HTML may have little added value.
In a way it is only worth the effort if it produces a "better" HTML5
document, where "better" is parametric in the goal the author is trying
to achieve (e.g. eBooks have different requirements than web sites, or
say even more modern - interactive exercise sheets.)

> I have never used tex4ht, but my impression is that this is the 
> most promising way to get HTML from LaTeX. So you should tell
> what lwarp offers that tex4ht doesn't.

Well, that measure of being "promising" depends on the goal you're
trying to achieve...

> Now as to "native": There are LaTeX-to-HTML converters that use 
> Perl or things like this (Pandoc). For those I could accept 
> calling them "direct" conversion, but not "native", as they use 
> external software for the conversion rather than the LaTeX 
> typesetting system.

This seems to be a fair distinction.

>  A problem with this approach is that the 
> author's custom macros cannot be processed.

Well, that's not entirely true. It's definitely true for early stage
reimplementations (such as pandoc), which are quite limited in coverage.
LaTeXML on the other hand already supports an impressive subset of TeX.
A brief illustration could be the classic xii.tex example [1].

It is certainly not complete in coverage yet, with about 61% of
arXiv.org's academic sources converting without issues [2]. But it's
also definitely not a toy project at this stage.

That being said, I find lwarp.sty to be a fascinating project, and the
"Alternatives" section in its manual is a rather on-point overview of
the current solution attempts [3]. Looking at the implementation
details, it seems that much of the inevitable customization is again
present - in order to resolve the "impedance mismatch" between the
printed page and the hypertext webpage, various high level constructs
need to be mapped correctly over to the HTML, before TeX gets to have
its way with them. (I had some more thoughts in that vein in an old blog
post of mine [4]).

I think each conversion process has done significant work in that
direction, and I find myself wishing that we could reuse and exchange
our bindings more effectively between projects.

> I should not advertise my blog package in the moreyhpe bundle
>
>     http://ctan.org/pkg/morehype
>
> (at present) but the original posting provokes the question 
> of what "native" conversion of LaTeX to HTML could be: 
> With blog.sty, the source code is actually parsed by LaTeX 
> (I consider it so perverse to parse LaTeX source code 
>  by non-TeX software), and it "directly" \writes HTML, 
> the TeX macros expand to HTML.

Right, there is a clear difference of perspective there. My view is that
LaTeX's markup should need no further extensions to generate (semantic,
high quality) HTML5, as the alternative increases the already high
learning curve, and makes a highly technical writing experience even
more involved. For me the pain of having to reeducate the entirety of
the latex authoring world to write "web-friendly" latex is a worse
approach than silently offering a solution under the hood. And that is
something I really appreciate in lwarp's current vision, as Brian seems
to be sheltering the authors as much as possible.

I think there is an interesting design problem there, and I am always
curious to see the trade-offs that each of these projects decides on.
I'm curious to learn more about the differences between lwarp and
tex4ht, the amount of work that it took to get to the current stage, and
the estimated difficulty for adding support for new packages. Looking at
lwarp's support list, I see that there is a Tikz -> SVG support already
operational. Is that building on the tex4ht driver for SVG directly?


Wishing everyone a nice week ahead,
Deyan

[1] xii.tex example in the latexml showcase
http://latexml.mathweb.org/editor?demo=xii

[2] arXMLiv conversion status
http://cortex.mathweb.org/corpus/arXMLiv/tex_to_html

Note: And the 61% here are missing a baseline, since it's unclear how
many of these sources run error-free with a stock pdflatex installation.
Apologies for the hanging number.

[3] lwarp 0.12 manual
http://bdtechconcepts.com/portfolio/lwarp_v0_12.pdf

[4] "LaTeX is Dead (long live LaTeX)" blog post
http://prodg.org/blog/latex_today/2015-02-20/LaTeX%20is%20Dead,%20Long%20Live%20LaTeX

>
> Cheers,
>
>     Uwe.
>
> _______________________________________________
> TeX FAQ: http://www.tex.ac.uk/faq
> Mailing list archives: http://tug.org/pipermail/texhax/
> More links: http://tug.org/begin.html
>
> Automated subscription management: http://tug.org/mailman/listinfo/texhax
> Human mailing list managers: postmaster at tug.org


From shubho.roy85 at gmail.com  Mon Mar 21 06:30:57 2016
From: shubho.roy85 at gmail.com (Shubho Roy)
Date: Mon, 21 Mar 2016 11:00:57 +0530
Subject: [texhax] 
	=?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTML_?=
	=?utf-8?q?conversion?=
In-Reply-To: <56EF5C5C.4040806@jacobs-university.de>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
Message-ID: <CAHRhsBrQ9mG=Ju4JT4D77gUc7vcwS7sP9whrNrsDaKc3HvqSmQ@mail.gmail.com>

Can this package be on github?

On Mon, Mar 21, 2016 at 7:58 AM, Deyan Ginev <d.ginev at jacobs-university.de>
wrote:

> Dear all,
>
> Since I noticed there is a brief tex -> html discussion going on, let me
> add one more perspective here. I'm a contributor to the LaTeXML
> conversion project, which I am guessing is the one implied by the
> reference to "Perl" in Uwe's last email.
>
>
> On 20.03.2016 20:08, Uwe Lueck wrote:
> >> This is a LaTeX package which causes LaTeX to directly generate HTML
> tags,
> >> using pdftotext and a few other utilities to convert the resulting PDF
> file
> >> into HTML files.
> > The approach is interesting, yet if you convert LaTeX to PDF
> > and the result to HTML, the meaning of "direct" forbids calling
> > this a "direct" generation of HTML. It is just as "direct" as
> > the late Eitan Gurari's tex4ht.
>
> Another point to sneak in here is now that libarries such as "pdf.js"
> exist, and browsers have native PDF previews via the HTML5 canvas,
> having a TeX-near mapping from PDF to HTML may have little added value.
> In a way it is only worth the effort if it produces a "better" HTML5
> document, where "better" is parametric in the goal the author is trying
> to achieve (e.g. eBooks have different requirements than web sites, or
> say even more modern - interactive exercise sheets.)
>
> > I have never used tex4ht, but my impression is that this is the
> > most promising way to get HTML from LaTeX. So you should tell
> > what lwarp offers that tex4ht doesn't.
>
> Well, that measure of being "promising" depends on the goal you're
> trying to achieve...
>
> > Now as to "native": There are LaTeX-to-HTML converters that use
> > Perl or things like this (Pandoc). For those I could accept
> > calling them "direct" conversion, but not "native", as they use
> > external software for the conversion rather than the LaTeX
> > typesetting system.
>
> This seems to be a fair distinction.
>
> >  A problem with this approach is that the
> > author's custom macros cannot be processed.
>
> Well, that's not entirely true. It's definitely true for early stage
> reimplementations (such as pandoc), which are quite limited in coverage.
> LaTeXML on the other hand already supports an impressive subset of TeX.
> A brief illustration could be the classic xii.tex example [1].
>
> It is certainly not complete in coverage yet, with about 61% of
> arXiv.org's academic sources converting without issues [2]. But it's
> also definitely not a toy project at this stage.
>
> That being said, I find lwarp.sty to be a fascinating project, and the
> "Alternatives" section in its manual is a rather on-point overview of
> the current solution attempts [3]. Looking at the implementation
> details, it seems that much of the inevitable customization is again
> present - in order to resolve the "impedance mismatch" between the
> printed page and the hypertext webpage, various high level constructs
> need to be mapped correctly over to the HTML, before TeX gets to have
> its way with them. (I had some more thoughts in that vein in an old blog
> post of mine [4]).
>
> I think each conversion process has done significant work in that
> direction, and I find myself wishing that we could reuse and exchange
> our bindings more effectively between projects.
>
> > I should not advertise my blog package in the moreyhpe bundle
> >
> >     http://ctan.org/pkg/morehype
> >
> > (at present) but the original posting provokes the question
> > of what "native" conversion of LaTeX to HTML could be:
> > With blog.sty, the source code is actually parsed by LaTeX
> > (I consider it so perverse to parse LaTeX source code
> >  by non-TeX software), and it "directly" \writes HTML,
> > the TeX macros expand to HTML.
>
> Right, there is a clear difference of perspective there. My view is that
> LaTeX's markup should need no further extensions to generate (semantic,
> high quality) HTML5, as the alternative increases the already high
> learning curve, and makes a highly technical writing experience even
> more involved. For me the pain of having to reeducate the entirety of
> the latex authoring world to write "web-friendly" latex is a worse
> approach than silently offering a solution under the hood. And that is
> something I really appreciate in lwarp's current vision, as Brian seems
> to be sheltering the authors as much as possible.
>
> I think there is an interesting design problem there, and I am always
> curious to see the trade-offs that each of these projects decides on.
> I'm curious to learn more about the differences between lwarp and
> tex4ht, the amount of work that it took to get to the current stage, and
> the estimated difficulty for adding support for new packages. Looking at
> lwarp's support list, I see that there is a Tikz -> SVG support already
> operational. Is that building on the tex4ht driver for SVG directly?
>
>
> Wishing everyone a nice week ahead,
> Deyan
>
> [1] xii.tex example in the latexml showcase
> http://latexml.mathweb.org/editor?demo=xii
>
> [2] arXMLiv conversion status
> http://cortex.mathweb.org/corpus/arXMLiv/tex_to_html
>
> Note: And the 61% here are missing a baseline, since it's unclear how
> many of these sources run error-free with a stock pdflatex installation.
> Apologies for the hanging number.
>
> [3] lwarp 0.12 manual
> http://bdtechconcepts.com/portfolio/lwarp_v0_12.pdf
>
> [4] "LaTeX is Dead (long live LaTeX)" blog post
>
> http://prodg.org/blog/latex_today/2015-02-20/LaTeX%20is%20Dead,%20Long%20Live%20LaTeX
>
> >
> > Cheers,
> >
> >     Uwe.
> >
> > _______________________________________________
> > TeX FAQ: http://www.tex.ac.uk/faq
> > Mailing list archives: http://tug.org/pipermail/texhax/
> > More links: http://tug.org/begin.html
> >
> > Automated subscription management:
> http://tug.org/mailman/listinfo/texhax
> > Human mailing list managers: postmaster at tug.org
>
> _______________________________________________
> TeX FAQ: http://www.tex.ac.uk/faq
> Mailing list archives: http://tug.org/pipermail/texhax/
> More links: http://tug.org/begin.html
>
> Automated subscription management: http://tug.org/mailman/listinfo/texhax
> Human mailing list managers: postmaster at tug.org
>



-- 
Shubho Roy
National Institute of Public Finance and Policy
18/2 Satsang Vihar Marg,
Special Institutional Area,
New Delhi 110067.
[Near JNU East Gate]

Mobile:- +91-9716479606
Location:- http://goo.gl/ICCjh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160321/011bfde5/attachment-0001.html>

From haines at histomat.net  Mon Mar 21 15:31:57 2016
From: haines at histomat.net (Haines Brown)
Date: Mon, 21 Mar 2016 10:31:57 -0400
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native__LaTeX_to_HTML?=
 =?utf-8?q?_conversion?=
In-Reply-To: <201603160407.01780.BD@bdtechconcepts.com>
References: <201603160407.01780.BD@bdtechconcepts.com>
Message-ID: <20160321143157.GF13251@engels.historicalmaterialism.info>

Having struggled unsuccessfully until now to convert a biblatex
style=historian article to .doc (via .html and otherwise), I certainly
have interest in the lwarp package.

I'm very inexpert in these matters, but I simply copied lwarp.sty into
the directory holding my article tex files, added the line to my
preamble,

 \usepackage[warpHTML]{lwarp} %

When I compile I get error:

  ERROR: LaTeX Error: Command \CaptionSeparator already defined.
  --- TeX said ---
               Or name \end... illegal, see p.192 of the manual.

Sounds like a problem easily resolved, but don't know how to go about
it. 

From jagathar at gmail.com  Mon Mar 21 16:39:40 2016
From: jagathar at gmail.com (Jagath AR)
Date: Mon, 21 Mar 2016 21:09:40 +0530
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTML_?=
 =?utf-8?q?conversion?=
In-Reply-To: <20160321143157.GF13251@engels.historicalmaterialism.info>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <20160321143157.GF13251@engels.historicalmaterialism.info>
Message-ID: <CANRay2C=rYSLwU65cGc9MWY5z733r_uepK29WsYrQv3+8Z-hJw@mail.gmail.com>

Hi Haines,
The problem is due to the following definition in the style file:

\providecommand{\CaptionSeparator}{:}

For the time being, you could comment this line in the package and try once
more.

Regards
Jagath

On 21 March 2016 at 20:01, Haines Brown <haines at histomat.net> wrote:

> Having struggled unsuccessfully until now to convert a biblatex
> style=historian article to .doc (via .html and otherwise), I certainly
> have interest in the lwarp package.
>
> I'm very inexpert in these matters, but I simply copied lwarp.sty into
> the directory holding my article tex files, added the line to my
> preamble,
>
>  \usepackage[warpHTML]{lwarp} %
>
> When I compile I get error:
>
>   ERROR: LaTeX Error: Command \CaptionSeparator already defined.
>   --- TeX said ---
>                Or name \end... illegal, see p.192 of the manual.
>
> Sounds like a problem easily resolved, but don't know how to go about
> it.
> _______________________________________________
> TeX FAQ: http://www.tex.ac.uk/faq
> Mailing list archives: http://tug.org/pipermail/texhax/
> More links: http://tug.org/begin.html
>
> Automated subscription management: http://tug.org/mailman/listinfo/texhax
> Human mailing list managers: postmaster at tug.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160321/340ac49e/attachment.html>

From BD at bdtechconcepts.com  Mon Mar 21 17:53:01 2016
From: BD at bdtechconcepts.com (Brian Dunn)
Date: Mon, 21 Mar 2016 11:53:01 -0500
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTML_?=
 =?utf-8?q?conversion?=
In-Reply-To: <56EF5C5C.4040806@jacobs-university.de>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
Message-ID: <201603211153.01961.BD@bdtechconcepts.com>

On Sunday, March 20, 2016, Deyan Ginev wrote:
> Looking at the implementation
> details, it seems that much of the inevitable customization is again
> present - in order to resolve the "impedance mismatch" between the
> printed page and the hypertext webpage, various high level constructs
> need to be mapped correctly over to the HTML

CSS3 brings extra capability in some areas.

The question of where to intercept the code is an interesting one.  It would 
be desirable to use as much of the existing code as possible in the core and 
commonly-used packages, patching only at a low level where necessary, but so 
much of what LaTeX does is irrelevant to HTML output, and so many packages 
patch each other, that the result can be a mess.  For this reason, many 
packages are "emulated" at the user-interface level.  As time went on, I found 
reason to more closely match lower-level data structures in order to re-use 
some existing code.  Floats are an example; using the existing data structure 
allows the cleveref package to work as-is, even though the high-level float 
code is emulated.  Using \CaptionSeparator from babel is another example.


> the amount of work that it took to get to the current stage

I describe it in the manual  as a large number of small technical challenges.  
The first version was LaTeX to Asciidoc, allowing Asciidoc to handle many of 
the low-level details.  Asciidoc is one of the most complete markup languages, 
but of course still had limitations in what could be done.

> the estimated difficulty for adding support for new packages.

Text-related packages may very well work as-is or with minor patches.  In 
fact, I have not yet made bibliography citations into hyperlinks, for example, 
but they do appear in the text as-is.  Anything with graphics can be embedded 
inside a "lateximage", which will appear as an SVG image in the HTML result.  
See the math environments as an example.  (Described in more detail a few 
paragraphs below.)

The real work goes into adapting necessary features, but which in LaTeX 
include a lot of underlying code which has to be re-interpreted for HTML.  
Floats are a big example, but so is something like algorithmic.  \hfill and 
friends are not easily translated, so some patching with CSS was required.

By the way, digging through all the old code makes me appreciate modern 
packages such as xparse, etoolbox, xifthen, xstring, everyhook, calc, 
arrayjobx, zref, environ, printlen, etc.  Thanks to all these authors!


> I see that there is a Tikz -> SVG support already
> operational. Is that building on the tex4ht driver for SVG directly?

The environment is embedded inside a "lateximage".  The way it works is LaTeX 
draws the image on a page by itself, and also writes external instructions to 
grab that single page, tight crop, convert to SVG, and rename.  Meanwhile, 
LaTeX places a reference to that name in the HTML output.

The same procedure is used for math, which has the unfortunate side-effect of 
littering the project with images, and there is not yet any mechanism for 
reuse.  Copy/paste yields the LaTeX expression for each math object, inline 
with the regular text.

There are some counterarguments for the ideas of using 300dpi PNG or GIF 
instead of SVG, or MathML with the use of some post-processing.


-- 
Brian Dunn
BD Tech Concepts LLC
http://www.BDTechConcepts.com
bd at BDTechConcepts.com

http://www.linkedin.com/in/bdtechconcepts/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160321/85d068bb/attachment-0001.html>

From BD at bdtechconcepts.com  Mon Mar 21 18:19:18 2016
From: BD at bdtechconcepts.com (Brian Dunn)
Date: Mon, 21 Mar 2016 12:19:18 -0500
Subject: [texhax] =?utf-8?q?lwarp_package_=E2=80=94_CaptionSeparator?=
In-Reply-To: <20160321143157.GF13251@engels.historicalmaterialism.info>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <20160321143157.GF13251@engels.historicalmaterialism.info>
Message-ID: <201603211219.18986.BD@bdtechconcepts.com>

On Monday, March 21, 2016, Haines Brown wrote:
> I simply copied lwarp.sty into
> the directory holding my article tex files, added the line to my
> preamble,
> 
>  \usepackage[warpHTML]{lwarp} %
> 
> When I compile I get error:
> 
>   ERROR: LaTeX Error: Command \CaptionSeparator already defined.

Start with the documentation in "lwarp.pdf", under "Usage" (which I am going 
to rename to something more descriptive!).  There are some changes to make in 
the preamble, and a few additional files to set up.

I recommend that you start with the test suite, which will ensure that the 
toolchain is working on your computer.

The test suite and sample output are both provided in the .zip file.

I'm not sure which package is actually causing that error.  lwarp uses 
\providecommand, and babel uses \def.  Perhaps another package tries to create 
the same macro name.  What filename is mentioned in the output log just before 
that error message appears?

Brian


-- 
Brian Dunn
BD Tech Concepts LLC
http://www.BDTechConcepts.com
bd at BDTechConcepts.com

http://www.linkedin.com/in/bdtechconcepts/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160321/7f54cc23/attachment.html>

From reinhard.kotucha at web.de  Mon Mar 21 23:17:04 2016
From: reinhard.kotucha at web.de (Reinhard Kotucha)
Date: Mon, 21 Mar 2016 23:17:04 +0100
Subject: [texhax] lwarp package =?macintosh?Q?=D1?= Native LaTeX to
 HTMLconversion
In-Reply-To: <56EF5C5C.4040806@jacobs-university.de>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
Message-ID: <22256.29408.889142.649336@zaphod.ms25.net>

On 2016-03-20 at 22:28:44 -0400, Deyan Ginev wrote:

 > Well, that measure of being "promising" depends on the goal you're
 > trying to achieve...

Isn't this always the case?

 > http://latexml.mathweb.org/editor?demo=xii

This is extremely impressive indeed.  Thank you very much for the
link.  In which programming language is the parser written?

Regards,
  Reinhard

-- 
------------------------------------------------------------------
Reinhard Kotucha                            Phone: +49-511-3373112
Marschnerstr. 25
D-30167 Hannover                    mailto:reinhard.kotucha at web.de
------------------------------------------------------------------

From d.p.carlisle at gmail.com  Mon Mar 21 23:26:01 2016
From: d.p.carlisle at gmail.com (David Carlisle)
Date: Mon, 21 Mar 2016 22:26:01 +0000
Subject: [texhax] 
	=?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTMLc?=
	=?utf-8?q?onversion?=
In-Reply-To: <22256.29408.889142.649336@zaphod.ms25.net>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
 <22256.29408.889142.649336@zaphod.ms25.net>
Message-ID: <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>

On 21 March 2016 at 22:17, Reinhard Kotucha <reinhard.kotucha at web.de> wrote:
> On 2016-03-20 at 22:28:44 -0400, Deyan Ginev wrote:
>
>  > Well, that measure of being "promising" depends on the goal you're
>  > trying to achieve...
>
> Isn't this always the case?
>
>  > http://latexml.mathweb.org/editor?demo=xii
>
> This is extremely impressive indeed.  Thank you very much for the
> link.  In which programming language is the parser written?
>
> Regards,
>   Reinhard
>

latexml is all in perl but it is a fairly faithful implementation of
the tex macro language in perl hence its ability to cope with xii.tex
which usually defeats systems that try to match normal top level latex
syntax. (tex4ht can similarly convert that, using tex to expand the
macros).

David

From reinhard.kotucha at web.de  Tue Mar 22 01:23:46 2016
From: reinhard.kotucha at web.de (Reinhard Kotucha)
Date: Tue, 22 Mar 2016 01:23:46 +0100
Subject: [texhax] lwarp package =?macintosh?Q?=D1?= Native LaTeX to
 HTMLconversion
In-Reply-To: <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
 <22256.29408.889142.649336@zaphod.ms25.net>
 <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>
Message-ID: <22256.37010.197497.623147@zaphod.ms25.net>

On 2016-03-21 at 22:26:01 +0000, David Carlisle wrote:

 > On 21 March 2016 at 22:17, Reinhard Kotucha <reinhard.kotucha at web.de> wrote:
 > > On 2016-03-20 at 22:28:44 -0400, Deyan Ginev wrote:
 > >
 > >  > Well, that measure of being "promising" depends on the goal you're
 > >  > trying to achieve...
 > >
 > > Isn't this always the case?
 > >
 > >  > http://latexml.mathweb.org/editor?demo=xii
 > >
 > > This is extremely impressive indeed.  Thank you very much for the
 > > link.  In which programming language is the parser written?
 > >
 > > Regards,
 > >   Reinhard
 > >
 > 
 > latexml is all in perl but it is a fairly faithful implementation of
 > the tex macro language in perl hence its ability to cope with xii.tex
 > which usually defeats systems that try to match normal top level latex
 > syntax. (tex4ht can similarly convert that, using tex to expand the
 > macros).

Sure, tex4ht is in advantage because it's using TeX's parser.  What is
so impressive IMO is that now TeX files can be parsed properly by
another scripting language.  This is a big step forward.  Is anybody
willing to port the Perl code to Emacs Lisp?

Regards,
  Reinhard

-- 
------------------------------------------------------------------
Reinhard Kotucha                            Phone: +49-511-3373112
Marschnerstr. 25
D-30167 Hannover                    mailto:reinhard.kotucha at web.de
------------------------------------------------------------------

From P.Taylor at Rhul.Ac.Uk  Tue Mar 22 01:47:11 2016
From: P.Taylor at Rhul.Ac.Uk (Philip Taylor)
Date: Tue, 22 Mar 2016 00:47:11 +0000
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTMLc?=
 =?utf-8?q?onversion?=
In-Reply-To: <22256.37010.197497.623147@zaphod.ms25.net>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
 <22256.29408.889142.649336@zaphod.ms25.net>
 <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>
 <22256.37010.197497.623147@zaphod.ms25.net>
Message-ID: <56F0960F.3040202@Rhul.Ac.Uk>



Reinhard Kotucha wrote:

> Sure, tex4ht is in advantage because it's using TeX's parser.  What is
> so impressive IMO is that now TeX files can be parsed properly by
> another scripting language. 

Is this true, Reinhard ?  Can /any/ TeX file now be parsed properly by
another scripting language, including (for example) those that change
catcode on the fly, those that use \uppercase / \lowercase to perform
"TeX magic" and so on, or only those (relatively simple) files that use
only basic LaTeX markup ?

** Phil.

From d.p.carlisle at gmail.com  Tue Mar 22 08:51:35 2016
From: d.p.carlisle at gmail.com (David Carlisle)
Date: Tue, 22 Mar 2016 07:51:35 +0000
Subject: [texhax] 
	=?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTMLc?=
	=?utf-8?q?onversion?=
In-Reply-To: <56F0960F.3040202@Rhul.Ac.Uk>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
 <22256.29408.889142.649336@zaphod.ms25.net>
 <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>
 <22256.37010.197497.623147@zaphod.ms25.net>	<56F0960F.3040202@Rhul.Ac.Uk>
Message-ID: <CAEW6iOiTb3fm0dWB3MvcGfYtD95szPNXX6=BGpejNAa5hjf6YQ@mail.gmail.com>

On 22 March 2016 at 00:47, Philip Taylor <P.Taylor at rhul.ac.uk> wrote:
>
>
> Reinhard Kotucha wrote:
>
>> Sure, tex4ht is in advantage because it's using TeX's parser.  What is
>> so impressive IMO is that now TeX files can be parsed properly by
>> another scripting language.
>
> Is this true, Reinhard ?  Can /any/ TeX file now be parsed properly by
> another scripting language, including (for example) those that change
> catcode on the fly, those that use \uppercase / \lowercase to perform
> "TeX magic" and so on, or only those (relatively simple) files that use
> only basic LaTeX markup ?
>
> ** Phil.

I can only assume you've never looked at xii.tex, the example
mentioned earlier in the thread, (which is typical plain tex markup,
not "basic LaTeX markup" :-)
(it's on ctan or you've probably got a copy already in texlive)

David

From P.Taylor at Rhul.Ac.Uk  Tue Mar 22 11:00:15 2016
From: P.Taylor at Rhul.Ac.Uk (Philip Taylor)
Date: Tue, 22 Mar 2016 10:00:15 +0000
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTMLc?=
 =?utf-8?q?onversion?=
In-Reply-To: <CAEW6iOiTb3fm0dWB3MvcGfYtD95szPNXX6=BGpejNAa5hjf6YQ@mail.gmail.com>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
 <22256.29408.889142.649336@zaphod.ms25.net>
 <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>
 <22256.37010.197497.623147@zaphod.ms25.net> <56F0960F.3040202@Rhul.Ac.Uk>
 <CAEW6iOiTb3fm0dWB3MvcGfYtD95szPNXX6=BGpejNAa5hjf6YQ@mail.gmail.com>
Message-ID: <56F117AF.5060004@Rhul.Ac.Uk>



David Carlisle wrote:

> I can only assume you've never looked at xii.tex, the example 
> mentioned earlier in the thread, (which is typical plain tex markup,
>  not "basic LaTeX markup" :-)

Er, no. Should I have ?!

OK, so if "xii.tex" is anything to go by, this Perl script is capable of
handling at least some of TeX's more arcane features. What would be
really useful (IMHO) is if the author could list (a) the more arcane
features that it is known to support (e.g., catcode changes, lc/uccode
changes, \uppercase/lowercase, ^^ notation, ^^^^ notation, etc) and (b)
those features that it is known not yet to support, if any (if he/she
has not already done so). Also the extent to which it supports some or
all of the extensions and enhancements offered by {e-TeX, PdfTeX, XeTeX,
...).

Kaveh wrote :

> Phil, I wouldn't give it much chance of parsing your complex macros. 
> From what I remember even TeX struggles with those. ;-)

Oh, it usually manages (on a good day. The hard part (so my Polish
friends tell me) is translating the five levels of subordinate clauses
that I typically use in my descriptions of how they work :-)

** Phil.

From kaveh at rivervalleytechnologies.com  Tue Mar 22 08:28:01 2016
From: kaveh at rivervalleytechnologies.com (Kaveh Bazargan)
Date: Tue, 22 Mar 2016 11:28:01 +0400
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTMLc?=
 =?utf-8?q?onversion?=
In-Reply-To: <56F0960F.3040202@Rhul.Ac.Uk>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
 <22256.29408.889142.649336@zaphod.ms25.net>
 <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>
 <22256.37010.197497.623147@zaphod.ms25.net> <56F0960F.3040202@Rhul.Ac.Uk>
Message-ID: <CAJ2R9piEcSMx85vvFC=+tR1OykAzztOYb9V551XB8i1bryfMaw@mail.gmail.com>

On 22 March 2016 at 04:47, Philip Taylor <P.Taylor at rhul.ac.uk> wrote:

>
>
> Reinhard Kotucha wrote:
>
> > Sure, tex4ht is in advantage because it's using TeX's parser.  What is
> > so impressive IMO is that now TeX files can be parsed properly by
> > another scripting language.
>
> Is this true, Reinhard ?  Can /any/ TeX file now be parsed properly by
> another scripting language, including (for example) those that change
> catcode on the fly, those that use \uppercase / \lowercase to perform
> "TeX magic" and so on, or only those (relatively simple) files that use
> only basic LaTeX markup ?
>
>
Phil, I wouldn't give it much chance of parsing your complex macros. From
what I remember even TeX struggles with those. ;-)



> ** Phil.
> _______________________________________________
> TeX FAQ: http://www.tex.ac.uk/faq
> Mailing list archives: http://tug.org/pipermail/texhax/
> More links: http://tug.org/begin.html
>
> Automated subscription management: http://tug.org/mailman/listinfo/texhax
> Human mailing list managers: postmaster at tug.org
>



-- 
Kaveh Bazargan
Director
River Valley Technologies
@kaveh1000
+44 7771 824 111
www.rivervalleytechnologies.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160322/8f5b5ed9/attachment.html>

From haines at histomat.net  Tue Mar 22 14:02:58 2016
From: haines at histomat.net (Haines Brown)
Date: Tue, 22 Mar 2016 09:02:58 -0400
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native__LaTeX_to_HTML?=
 =?utf-8?q?_conversion?=
In-Reply-To: <CANRay2C=rYSLwU65cGc9MWY5z733r_uepK29WsYrQv3+8Z-hJw@mail.gmail.com>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <20160321143157.GF13251@engels.historicalmaterialism.info>
 <CANRay2C=rYSLwU65cGc9MWY5z733r_uepK29WsYrQv3+8Z-hJw@mail.gmail.com>
Message-ID: <20160322130258.GH13251@engels.historicalmaterialism.info>

On Mon, Mar 21, 2016 at 09:09:40PM +0530, Jagath AR wrote:
> Hi Haines,
> The problem is due to the following definition in the style file:
> 
> \providecommand{\CaptionSeparator}{:}
> 
> For the time being, you could comment this line in the package and try
> once more.
> 
> Regards
> Jagath
> 
> On 21 March 2016 at 20:01, Haines Brown <haines at histomat.net> wrote:

snip

>     When I compile I get error:
> 
>     ? ERROR: LaTeX Error: Command \CaptionSeparator already defined.

Jagath, thanks, but not much luck.

I commented the definition:

  \providecommand{\CaptionSeparator}{:}

But now I get other errors. In each case I the \newcommand{} and then
the next error shows

  LaTeX Error: Command \dropchapter already defined.

  LaTeX Error: Command \undodrop already defined.

  LaTeX Error: Command \epigraphhead already defined.

When I finally got this error, I gave up.

  LaTeX Error: Option clash for package geometry.

I should mention that any connection I try to make to
http://bdtechconcepts.com/ times out. I tried about four hours ago and
again just now.

Haines

From kaveh at rivervalleytechnologies.com  Tue Mar 22 14:14:06 2016
From: kaveh at rivervalleytechnologies.com (Kaveh Bazargan)
Date: Tue, 22 Mar 2016 13:14:06 +0000
Subject: [texhax] 
	=?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTML_?=
	=?utf-8?q?conversion?=
In-Reply-To: <20160322130258.GH13251@engels.historicalmaterialism.info>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <20160321143157.GF13251@engels.historicalmaterialism.info>
 <CANRay2C=rYSLwU65cGc9MWY5z733r_uepK29WsYrQv3+8Z-hJw@mail.gmail.com>
 <20160322130258.GH13251@engels.historicalmaterialism.info>
Message-ID: <CAJ2R9pj66_3KwMMFO3wpPii8ZkRbwm_HwqKvABssWvHaFFAUxg@mail.gmail.com>

On 22 March 2016 at 13:02, Haines Brown <haines at histomat.net> wrote:

> I should mention that any connection I try to make to
> http://bdtechconcepts.com/ times out. I tried about four hours ago and
> again just now.
>

Just on that point, the site is working for me. I will discuss the error
points with Jagath.

Regards
Kaveh


-- 
Kaveh Bazargan
Director
River Valley Technologies
@kaveh1000
+44 7771 824 111
www.rivervalleytechnologies.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160322/ae85c5cf/attachment-0001.html>

From BD at bdtechconcepts.com  Tue Mar 22 14:36:51 2016
From: BD at bdtechconcepts.com (Brian Dunn)
Date: Tue, 22 Mar 2016 08:36:51 -0500
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native__LaTeX_to_HTML?=
 =?utf-8?q?_conversion?=
In-Reply-To: <20160322130258.GH13251@engels.historicalmaterialism.info>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <CANRay2C=rYSLwU65cGc9MWY5z733r_uepK29WsYrQv3+8Z-hJw@mail.gmail.com>
 <20160322130258.GH13251@engels.historicalmaterialism.info>
Message-ID: <201603220836.51258.BD@bdtechconcepts.com>


> I should mention that any connection I try to make to
> http://bdtechconcepts.com/ times out. I tried about four hours ago and
> again just now.

The web-hosting people seem to have it fixed now.


-- 
Brian Dunn
BD Tech Concepts LLC
http://www.BDTechConcepts.com
bd at BDTechConcepts.com

http://www.linkedin.com/in/bdtechconcepts/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160322/99174363/attachment.html>

From BD at bdtechconcepts.com  Tue Mar 22 14:42:23 2016
From: BD at bdtechconcepts.com (Brian Dunn)
Date: Tue, 22 Mar 2016 08:42:23 -0500
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native__LaTeX_to_HTML?=
 =?utf-8?q?_conversion?=
In-Reply-To: <20160322130258.GH13251@engels.historicalmaterialism.info>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <CANRay2C=rYSLwU65cGc9MWY5z733r_uepK29WsYrQv3+8Z-hJw@mail.gmail.com>
 <20160322130258.GH13251@engels.historicalmaterialism.info>
Message-ID: <201603220842.23568.BD@bdtechconcepts.com>

On Tuesday, March 22, 2016, Haines Brown wrote:

> I commented the definition:
> 
>   \providecommand{\CaptionSeparator}{:}
> 
> But now I get other errors.

Check the lwarp manual for how to use lwarp.  In general, many packages in the 
preamble will not work for lwarp's HTML conversion, in many cases because they 
are replaced by a layer of emulation, and so the \usepackage{} commands and 
related options must be inside \begin{warpprint} and \end{warpprint}.  There 
are other steps to take as well; see the manual.  I do recommend that you 
start by trying to compile the test suite before doing anything else.

Brian


-- 
Brian Dunn
BD Tech Concepts LLC
http://www.BDTechConcepts.com
bd at BDTechConcepts.com

http://www.linkedin.com/in/bdtechconcepts/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160322/9c5f6023/attachment-0001.html>

From d.ginev at jacobs-university.de  Tue Mar 22 15:47:46 2016
From: d.ginev at jacobs-university.de (Deyan Ginev)
Date: Tue, 22 Mar 2016 10:47:46 -0400
Subject: [texhax] latexml discussion
In-Reply-To: <56F117AF.5060004@Rhul.Ac.Uk>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
 <22256.29408.889142.649336@zaphod.ms25.net>
 <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>
 <22256.37010.197497.623147@zaphod.ms25.net> <56F0960F.3040202@Rhul.Ac.Uk>
 <CAEW6iOiTb3fm0dWB3MvcGfYtD95szPNXX6=BGpejNAa5hjf6YQ@mail.gmail.com>
 <56F117AF.5060004@Rhul.Ac.Uk>
Message-ID: <56F15B12.1090409@jacobs-university.de>

Dear all,

Let me clarify some high level bits here, but if you really want to know
more about latexml I suggest reading the manual [1] or joining its
mailing list [2], to avoid cluttering [texhax] with side projects.

On 03/22/2016 06:00 AM, Philip Taylor wrote:
> 
> David Carlisle wrote:
> 
>> I can only assume you've never looked at xii.tex, the example 
>> mentioned earlier in the thread, (which is typical plain tex markup,
>>  not "basic LaTeX markup" :-)
> 
> Er, no. Should I have ?!

The way I was brought up into the world of TeX, "xii.tex" had legendary
status in my university :-) It's a privilege to have the original author
(David) participate in the email thread.

> 
> OK, so if "xii.tex" is anything to go by, this Perl script is capable of
> handling at least some of TeX's more arcane features.

First, and this is important, please do not refer to latexml as a "Perl
script". Scripts are one-off programs, typically between 100-1000 lines
of code, that offer a quick solution to a small task. There are many
actual perl scripts trying to parse LaTeX of course, but latexml goes
beyond that.

With over 20,000 lines of code, and following best practices for code
organization and quality (via perltidy and perlcritic), the core of
LaTeXML is a well-documented library for interpreting and manipulating
TeX sources.

In response to the suggestion to reimplement it in Lisp - I wouldn't
take a reimplementation effort lightly, as you could spend the better
part of a year working on that (if not more). That said, moving to a
lower level language is something that is currently under active
discussion internally, as performance is a self-confessed weakness at
the moment.

A different sign of maturity is that latexml currently has a plugin
ecosystem [3] (still growing, and the interfaces are still stabilizing),
which offers various extensions - e.g. an output capability for docx and
odt files currently resides in an extension, and so do several
tex-to-html web services, including the one behind the showcase that I
linked to in my last reply. Mature plugins (e.g. complete bindings for
LaTeX packages) tend to be merged into the core project, which is
usually a pleasant workflow.

> What would be
> really useful (IMHO) is if the author could list (a) the more arcane
> features that it is known to support (e.g., catcode changes, lc/uccode
> changes, \uppercase/lowercase, ^^ notation, ^^^^ notation, etc) and (b)
> those features that it is known not yet to support, if any (if he/she
> has not already done so). Also the extent to which it supports some or
> all of the extensions and enhancements offered by {e-TeX, PdfTeX, XeTeX,
> ...).

If we had an exhaustive list of all features offered by the various
engines, then we could go through it and tell you what latexml could
handle (where applicable). Getting that list may be the hardest ordeal
here. That also sounds like a check-list worth adding to the manual.
Btw, I think the examples you enumerated are all supported.

Ever since latexml managed to successfully interpret the raw TeX of
tikz.sty and pgf.sty, I think our perspective in the team has changed
from "we try our best, but we're nowhere near complete" to "any specific
failure to interpret TeX is an unknown bug, and we would like to hear
about it and patch it". The official goal for the 1.0 milestone is to
reach full parity with TeX, so at least we're being ambitious.

We're at version 0.8.1 right now (with 0.8.2 coming out soon).

> 
> Kaveh wrote :
> 
>> Phil, I wouldn't give it much chance of parsing your complex macros. 
>> From what I remember even TeX struggles with those. ;-)
> 
> Oh, it usually manages (on a good day. The hard part (so my Polish
> friends tell me) is translating the five levels of subordinate clauses
> that I typically use in my descriptions of how they work :-)

Feel free to try latexml on (ever larger) minimal examples of your
macros, and if you see it gasping for breath - please let us know! It
has become ever harder to find isolated flaws of the TeX interpretation,
so any help with that would be very valuable.

Greetings,
Deyan

> 
> ** Phil.
> _______________________________________________
> TeX FAQ: http://www.tex.ac.uk/faq
> Mailing list archives: http://tug.org/pipermail/texhax/
> More links: http://tug.org/begin.html
> 
> Automated subscription management: http://tug.org/mailman/listinfo/texhax
> Human mailing list managers: postmaster at tug.org
> 

[1] LaTeXML manual in HTML
http://math.nist.gov/~BMiller/LaTeXML/manual/

[2] LaTeXML mailing list
http://lists.jacobs-university.de/mailman/listinfo/project-latexml

[3] LaTeXML plugins on GitHub
https://github.com/search?q=latexml-plugin&ref=searchresults&type=Repositories&utf8=%E2%9C%93



From P.Taylor at Rhul.Ac.Uk  Tue Mar 22 15:53:44 2016
From: P.Taylor at Rhul.Ac.Uk (Philip Taylor)
Date: Tue, 22 Mar 2016 14:53:44 +0000
Subject: [texhax] latexml discussion
In-Reply-To: <56F15B12.1090409@jacobs-university.de>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
 <22256.29408.889142.649336@zaphod.ms25.net>
 <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>
 <22256.37010.197497.623147@zaphod.ms25.net> <56F0960F.3040202@Rhul.Ac.Uk>
 <CAEW6iOiTb3fm0dWB3MvcGfYtD95szPNXX6=BGpejNAa5hjf6YQ@mail.gmail.com>
 <56F117AF.5060004@Rhul.Ac.Uk> <56F15B12.1090409@jacobs-university.de>
Message-ID: <56F15C78.1010202@Rhul.Ac.Uk>



Deyan Ginev wrote:

> First, and this is important, please do not refer to latexml as a "Perl
> script". 

No offence intended, and profuse apologies proffered.

> If we had an exhaustive list of all features offered by the various
> engines, then we could go through it and tell you what latexml could
> handle (where applicable). Getting that list may be the hardest ordeal
> here. 

Understood.

> That also sounds like a check-list worth adding to the manual.

That would be much appreciated.

> Btw, I think the examples you enumerated are all supported.

Excellent news.

> Feel free to try latexml on (ever larger) minimal examples of your
> macros, and if you see it gasping for breath - please let us know! It
> has become ever harder to find isolated flaws of the TeX interpretation,
> so any help with that would be very valuable.

I don't have any "minimal examples" but I do have fully developed (and,
of course, arcane) programs, and when I next have spare time I will let
it loose on one (or more).

Philip Taylor

From michal.h21 at gmail.com  Tue Mar 22 17:48:59 2016
From: michal.h21 at gmail.com (Michal Hoftich)
Date: Tue, 22 Mar 2016 17:48:59 +0100
Subject: [texhax] 
 =?utf-8?q?lwarp_package_=E2=80=94_Native_LaTeX_to_HTML_?=
 =?utf-8?q?conversion?=
In-Reply-To: <201603220842.23568.BD@bdtechconcepts.com>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <CANRay2C=rYSLwU65cGc9MWY5z733r_uepK29WsYrQv3+8Z-hJw@mail.gmail.com>
 <20160322130258.GH13251@engels.historicalmaterialism.info>
 <201603220842.23568.BD@bdtechconcepts.com>
Message-ID: <CAOCj1Of9xvOpJzSzYsdhUUKdDZSGvj_5p3K32QqVrq7z8OdWeQ@mail.gmail.com>

Haines Brown wrote:

> Having struggled unsuccessfully until now to convert a biblatex
> style=historian article to .doc (via .html and otherwise), I certainly
> have interest in the lwarp package.

tex4ht supports biblatex, it can be even used to compile the document
to .odt format, which is directly supported by Word these days. I've
tried some simple test cases for biblatex-historian and I get lot of
errors both with tex4ht and pdflatex. But the output seems similar
(probably similarly broken). It seems that it was broken by
recent biblatex update, which broke almost all existing styles.

tex4ht has bug tracker, we would be really happy if it was used more to
report both package issues and feature requests.

PS: Sorry for replying in a wrong thread, I've just signed in to TeXhax and
can't reply directly.

[1] https://puszcza.gnu.org.ua/bugs/?group=tex4ht

From haines at histomat.net  Tue Mar 22 19:41:19 2016
From: haines at histomat.net (Haines Brown)
Date: Tue, 22 Mar 2016 14:41:19 -0400
Subject: [texhax] =?utf-8?q?lwarp_package_=E2=80=94_CaptionSeparator?=
In-Reply-To: <201603211219.18986.BD@bdtechconcepts.com>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <20160321143157.GF13251@engels.historicalmaterialism.info>
 <201603211219.18986.BD@bdtechconcepts.com>
Message-ID: <20160322184119.GJ13251@engels.historicalmaterialism.info>

On Mon, Mar 21, 2016 at 12:19:18PM -0500, Brian Dunn wrote:
> On Monday, March 21, 2016, Haines Brown wrote:

> > ERROR: LaTeX Error: Command \CaptionSeparator already defined.
 
> Start with the documentation in "lwarp.pdf", under "Usage" (which I am going to
> rename to something more descriptive!). There are some changes to make in the
> preamble, and a few additional files to set up.
> 
> I recommend that you start with the test suite, which will ensure that the
> toolchain is working on your computer.
 
> I'm not sure which package is actually causing that error. lwarp uses
> \providecommand, and babel uses \def. Perhaps another package tries to create
> the same macro name. What filename is mentioned in the output log just before
> that error message appears?

Brian, as am amateur struggling to understand the lwarp manual, perhaps
my blunders will be helpful.

I went to the test_suite. I switched from warpprint to warpHTML; from book to
article; uncommented the line \newbool{dotitlingpage}; uncommented
\booltrue{dotitlingpage} . Then compiled. 

Same fatal error as before, so I comment
\providecommand{\CaptionSeparator}{:} line in test_suite lwarp.style
file. Now only two non-fatal errors:

> ! Package etoolbox Error: Boolean '\ifdocustomtitling' undefined.
> l.309 ...}{Used maketitle without a titlingpage.}}

> ! Package tikz Error: Sorry, some package has redefined the meaning of
> the math -mode dollar sign. This is incompatible with tikz and its
> calc library and might cause unrecoverable errors.

The compilation finishes. However, no test_suite.html file showed up in
the test_suite folder. Or is the output sent to sample_output directory?
I displayed a couple of them there and saw what I expected. I looked at
the test_suite.pdf and it displays html markups, which is not what I
expected.

In terms of my working document, following the manual I see that I need
to insert this environment into the preface, but failed to understand
what packages I need to include within it. I gather than inputenc and
fontenc are accessed by default, but do I need an obvious package such
as {mathptmx}? {biblatex} is obviously needed for html, and so should
the \usepackage for it be moved into the warpHTML environment? Do I need
commands like pagenumbering{arabic}?

  \begin{warpHTML}

  \end{warpHTML}

Haines


From reinhard.kotucha at web.de  Tue Mar 22 23:35:59 2016
From: reinhard.kotucha at web.de (Reinhard Kotucha)
Date: Tue, 22 Mar 2016 23:35:59 +0100
Subject: [texhax] lwarp package =?macintosh?Q?=D1?= Native LaTeX to
 HTMLconversion
In-Reply-To: <56F117AF.5060004@Rhul.Ac.Uk>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
 <22256.29408.889142.649336@zaphod.ms25.net>
 <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>
 <22256.37010.197497.623147@zaphod.ms25.net>	<56F0960F.3040202@Rhul.Ac.Uk>
 <CAEW6iOiTb3fm0dWB3MvcGfYtD95szPNXX6=BGpejNAa5hjf6YQ@mail.gmail.com>
 <56F117AF.5060004@Rhul.Ac.Uk>
Message-ID: <22257.51407.789142.864080@zaphod.ms25.net>

On 2016-03-22 at 10:00:15 +0000, Philip Taylor wrote:

 > David Carlisle wrote:
 > 
 > > I can only assume you've never looked at xii.tex, the example
 > > mentioned earlier in the thread, (which is typical plain tex
 > > markup, not "basic LaTeX markup" :-)
 > 
 > Er, no. Should I have ?!

Yes.  When I provide a link and then comment it, it's necessary to
follow the link in order to know what I'm talking about.

See you at BachoTeX, hopefully,
  Reinhard

-- 
------------------------------------------------------------------
Reinhard Kotucha                            Phone: +49-511-3373112
Marschnerstr. 25
D-30167 Hannover                    mailto:reinhard.kotucha at web.de
------------------------------------------------------------------

From BD at bdtechconcepts.com  Wed Mar 23 00:35:10 2016
From: BD at bdtechconcepts.com (Brian Dunn)
Date: Tue, 22 Mar 2016 18:35:10 -0500
Subject: [texhax] =?utf-8?q?lwarp_package_=E2=80=94_CaptionSeparator?=
In-Reply-To: <20160322184119.GJ13251@engels.historicalmaterialism.info>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <201603211219.18986.BD@bdtechconcepts.com>
 <20160322184119.GJ13251@engels.historicalmaterialism.info>
Message-ID: <201603221835.10142.BD@bdtechconcepts.com>

Hi all,

I shall be replying to potential bug reports directly, instead of cluttering 
up the mailing list.

Additional bug reports, success/failure stories, ideas, or questions are 
welcome.

I shall also be adding a tutorial to the manual, and a shell script to verify 
installation of the necessary tools.

For those who got earlier versions, v0.11 attempts to add some Windows 
support.  If someone could verify that this works, please let me know.  v0.12 
adds a script to set up the initial symbolic links for a new project.

I am also working on emulating the subcaption and floatrow packages.

Thanks for everyone's patience.

Brian


-- 
Brian Dunn
BD Tech Concepts LLC
http://www.BDTechConcepts.com
bd at BDTechConcepts.com

http://www.linkedin.com/in/bdtechconcepts/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160322/2648b877/attachment-0001.html>

From reinhard.kotucha at web.de  Wed Mar 23 00:40:54 2016
From: reinhard.kotucha at web.de (Reinhard Kotucha)
Date: Wed, 23 Mar 2016 00:40:54 +0100
Subject: [texhax] latexml discussion
In-Reply-To: <56F15B12.1090409@jacobs-university.de>
References: <201603160407.01780.BD@bdtechconcepts.com>
 <trinity-12e777ca-5fe8-4cb5-add3-99175c335e60-1458518937718@3capp-webde-bap50>
 <56EF5C5C.4040806@jacobs-university.de>
 <22256.29408.889142.649336@zaphod.ms25.net>
 <CAEW6iOh31ho-LJBHiOU-uC6ay1c4BmG-YPR6hqW93GL7j+DpBw@mail.gmail.com>
 <22256.37010.197497.623147@zaphod.ms25.net>	<56F0960F.3040202@Rhul.Ac.Uk>
 <CAEW6iOiTb3fm0dWB3MvcGfYtD95szPNXX6=BGpejNAa5hjf6YQ@mail.gmail.com>
 <56F117AF.5060004@Rhul.Ac.Uk>	<56F15B12.1090409@jacobs-university.de>
Message-ID: <22257.55302.230095.816523@zaphod.ms25.net>

On 2016-03-22 at 10:47:46 -0400, Deyan Ginev wrote:

 > The way I was brought up into the world of TeX, "xii.tex" had
 > legendary status in my university :-) It's a privilege to have the
 > original author (David) participate in the email thread.

BTW, P?ter Szab? extended this file some years ago so that one and the
same file was a valid TeX file (could be compiled with TeX), a valid C
and C++ source file, and a valid Perl script.

The file was on his home page, which obviously doesn't exist anymore.

Regards,
  Reinhard

-- 
------------------------------------------------------------------
Reinhard Kotucha                            Phone: +49-511-3373112
Marschnerstr. 25
D-30167 Hannover                    mailto:reinhard.kotucha at web.de
------------------------------------------------------------------


From great123456 at mail.com  Thu Mar 24 05:33:51 2016
From: great123456 at mail.com (great123456 at mail.com)
Date: Thu, 24 Mar 2016 00:33:51 -0400
Subject: [texhax] Multi toc
Message-ID: <20160324003351.7de16e3b@ulgy_thing>

Hello,
I did a little research on the \label command and it seems that it is
intended to link chapters too (I had thought that there was something
else that did this).
Still waiting on the rest.

Thanks, David

From BD at bdtechconcepts.com  Thu Mar 24 15:29:47 2016
From: BD at bdtechconcepts.com (Brian Dunn)
Date: Thu, 24 Mar 2016 09:29:47 -0500
Subject: [texhax] lwarp update, and fonts with multiple TexLive versions
Message-ID: <201603240929.47145.BD@bdtechconcepts.com>

lwarp had conflicts with newer versions of some packages (now seemingly 
resolved in v0.13).

It turns out that when you install vanilla TexLive in parallel with a Debian-
packaged TexLive, you end up with a mess of fonts, as things are found in 
several places.  A purge of the Debian packages took care of that problem.

I shall avoid posting here about future updates of lwarp.  Check the site 
every now and then if you are interested.  One person has sent nice list of 
suggestions for the documentation.  I'd still like to hear from someone with a 
Windows box how well it goes on that op-system.


Brian


-- 
Brian Dunn
BD Tech Concepts LLC
http://www.BDTechConcepts.com
bd at BDTechConcepts.com

http://www.linkedin.com/in/bdtechconcepts/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160324/eb5f3351/attachment.html>

From joseph.wright at morningstar2.co.uk  Fri Mar 25 22:17:28 2016
From: joseph.wright at morningstar2.co.uk (Joseph Wright)
Date: Fri, 25 Mar 2016 21:17:28 +0000
Subject: [texhax] Biblatex user survey
Message-ID: <56F5AAE8.9070002@morningstar2.co.uk>

Hello all,

Some of you will have seen this elsewhere, but for those who have not,
the biblatex team are looking for feedback in a (very) short survey:

https://www.surveymonkey.com/r/X2FWPNR

We are particularly after an idea of what 'real' end users are doing in
terms of back-ends. Both feedback and further dissemination is very welcome.

Joseph

From uwe.lueck at web.de  Sat Mar 26 22:06:41 2016
From: uwe.lueck at web.de (Uwe Lueck)
Date: Sat, 26 Mar 2016 22:06:41 +0100
Subject: [texhax] lwarp update, and fonts with multiple TexLive versions
In-Reply-To: <201603240929.47145.BD@bdtechconcepts.com>
References: <201603240929.47145.BD@bdtechconcepts.com>
Message-ID: <trinity-8f944315-9b7a-4400-84a6-0da3eeb57861-1459026401770@3capp-webde-bs38>

Brian Dunn:
> lwarp had conflicts with newer versions of some packages
> (now seemingly resolved in v0.13).
>?
> It turns out that when you install vanilla TexLive in parallel
> with a Debian-packaged TexLive, you end up with a mess of fonts,
> as things are found in several places. A purge of the Debian
> packages took care of that problem.
>?
> I shall avoid posting here about future updates of lwarp.
> Check the site every now and then if you are interested.
> One person has sent nice list of suggestions for the documentation.
> I'd still like to hear from someone with a Windows box how well
> it goes on that op-system.

I have realized that some (La)TeX-to-... conversion tools 
(and other TeX-related software) are not submitted to CTAN, 
not understanding why. The ctan-ann mailing list is a 
straightforward medium for reporting improvements of TeX-related
software submitted to CTAN. You upload your update together with 
a changelog summary, and a few hours later everybody curious 
about advances in using TeX sees it (thanks to a few near to 
too idealistic volunteers).

-- Uwe.


From reinhard.kotucha at web.de  Sun Mar 27 04:28:54 2016
From: reinhard.kotucha at web.de (Reinhard Kotucha)
Date: Sun, 27 Mar 2016 04:28:54 +0200
Subject: [texhax] lwarp update, and fonts with multiple TexLive versions
In-Reply-To: <trinity-8f944315-9b7a-4400-84a6-0da3eeb57861-1459026401770@3capp-webde-bs38>
References: <201603240929.47145.BD@bdtechconcepts.com>
 <trinity-8f944315-9b7a-4400-84a6-0da3eeb57861-1459026401770@3capp-webde-bs38>
Message-ID: <22263.17766.749931.980296@zaphod.ms25.net>

On 2016-03-26 at 22:06:41 +0100, Uwe Lueck wrote:

 > I have realized that some (La)TeX-to-... conversion tools 
 > (and other TeX-related software) are not submitted to CTAN, 
 > not understanding why.

Uwe, I fully agree with you that everything related to TeX should be on
CTAN.

I must admit that I'm quite unhappy with the current situation too,
but the only solution I can imagine is to ask authors politely to
put their stuff on CTAN.

If you think that you can convince authors to push their stuff to
CTAN, please proceed.

Regards,
  Reinhard

-- 
------------------------------------------------------------------
Reinhard Kotucha                            Phone: +49-511-3373112
Marschnerstr. 25
D-30167 Hannover                    mailto:reinhard.kotucha at web.de
------------------------------------------------------------------

From BD at bdtechconcepts.com  Sun Mar 27 12:37:18 2016
From: BD at bdtechconcepts.com (Brian Dunn)
Date: Sun, 27 Mar 2016 05:37:18 -0500
Subject: [texhax] CTAN for experimental / testing packages
Message-ID: <201603270537.18663.BD@bdtechconcepts.com>

Does it make sense to upload to CTAN packages which are still experimental and 
being updated at least once per week?  Or would doing so be considered to be 
abusing the archive system, and require excessive time on a the part of the 
CTAN maintainers?


-- 
Brian Dunn
BD Tech Concepts LLC
http://www.BDTechConcepts.com
bd at BDTechConcepts.com

http://www.linkedin.com/in/bdtechconcepts/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160327/fc7d71fa/attachment.html>

From gene at gerd-neugebauer.de  Sun Mar 27 18:01:54 2016
From: gene at gerd-neugebauer.de (Gerd Neugebauer)
Date: Sun, 27 Mar 2016 18:01:54 +0200
Subject: [texhax] CTAN for experimental / testing packages
In-Reply-To: <201603270537.18663.BD@bdtechconcepts.com>
References: <201603270537.18663.BD@bdtechconcepts.com>
Message-ID: <1702284557.50657.1f82278f-75c6-4ddd-9d3a-082b3db5e458.open-xchange@email.1und1.de>


>     On 27 March 2016 at 12:37 Brian Dunn <BD at bdtechconcepts.com> wrote:
> 
>     Does it make sense to upload to CTAN packages which are still experimental
> and being updated at least once per week? Or would doing so be considered to
> be abusing the archive system, and require excessive time on a the part of the
> CTAN maintainers?
> 


If your package has reached some stability and user base then it makes sense to
upload it to CTAN.

While you are in the middle of development you should wait until you have
achieved one of the two goals above. If you develop new features and get them
usable, bugfree, and stable on a weekly basis then feel free to upload to CTAN.

Rationals:

- CTAN is driven as a manual process to ensure a certain formal quality of the
packages. This binds a lot of resources.

- The packages on CTAN make it into the major distributions. Most users don't
download the packages directly but use a distribution. Thus the update reaches
the end users with some delay and they stick to the version for some time.


>      
>     --
>     Brian Dunn
>     BD Tech Concepts LLC
>     http://www.BDTechConcepts.com
>     bd at BDTechConcepts.com
>      
>     http://www.linkedin.com/in/bdtechconcepts/
> 


Ciao

Gerd (CTAN webmaster)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://tug.org/pipermail/texhax/attachments/20160327/628796ec/attachment.html>

From h.y.acetaminophen at gmail.com  Wed Mar 30 09:29:10 2016
From: h.y.acetaminophen at gmail.com (Hironobu YAMASHITA)
Date: Wed, 30 Mar 2016 16:29:10 +0900
Subject: [texhax] Misplaced footer with multicol and fancyhdr
Message-ID: <56FB8046.9000203@gmail.com>

I see footers with fancyhdr.sty (March 22, 2005, v3.2) are
wrongly shifted toward the upper direction in the mulitcols
env defined in the latest multicol.sty (2015/08/19 v1.8n).
I had no problem with multicol.sty v1.8i in TL2014.

%#!pdflatex
\documentclass[a5paper]{article}
\usepackage{lipsum}
\usepackage{multicol} % v1.8n
\usepackage{fancyhdr} % v3.2
\pagestyle{fancy}
\cfoot{Page\\\thepage}
\begin{document}
\lipsum[1-3]
\begin{multicols}{2}
\lipsum[4-8]
\end{multicols}
\lipsum[9-10]
\end{document}

This behavior is due to the change in multicol.sty between
v1.8i and v1.8j, which adds \boxmaxdepth\maxdepth in the
definition of \multi at column@out. It seems that \boxmaxdepth
has affected not only splitting routine itself but also
routines _between_ splitting (such as header and footer).

Is this a bug in fancyhdr.sty, or in multicol.sty? Or am I
doing something wrong?

Hironobu Yamashita

From news3 at nililand.de  Thu Mar 31 14:05:12 2016
From: news3 at nililand.de (Ulrike Fischer)
Date: Thu, 31 Mar 2016 14:05:12 +0200
Subject: [texhax] Misplaced footer with multicol and fancyhdr
References: <56FB8046.9000203@gmail.com>
Message-ID: <4cbphpxwmlug.dlg@nililand.de>

Am Wed, 30 Mar 2016 16:29:10 +0900 schrieb Hironobu YAMASHITA:

> I see footers with fancyhdr.sty (March 22, 2005, v3.2) are
> wrongly shifted toward the upper direction in the mulitcols
> env defined in the latest multicol.sty (2015/08/19 v1.8n).
> I had no problem with multicol.sty v1.8i in TL2014.
> 
> %#!pdflatex
> \documentclass[a5paper]{article}
> \usepackage{lipsum}
> \usepackage{multicol} % v1.8n
> \usepackage{fancyhdr} % v3.2
> \pagestyle{fancy}
> \cfoot{Page\\\thepage}
> \begin{document}
> \lipsum[1-3]
> \begin{multicols}{2}
> \lipsum[4-8]
> \end{multicols}
> \lipsum[9-10]
> \end{document}
> 
> This behavior is due to the change in multicol.sty between
> v1.8i and v1.8j, which adds \boxmaxdepth\maxdepth in the
> definition of \multi at column@out. It seems that \boxmaxdepth
> has affected not only splitting routine itself but also
> routines _between_ splitting (such as header and footer).
> 
> Is this a bug in fancyhdr.sty, or in multicol.sty? Or am I
> doing something wrong?

Imho is it a fancyhdr bug. It sets the footer in a \vbox and simply
assumes that \boxmaxdepth is large enough. But when someone (in this
case multicol) change \boxmaxdepth the depth of the \vbox is changed
and so it moves up. 

You should make a bug report.
As a workaround you can locally change \boxmaxdepth to some larger
value by adding some code to \fancy at reset:

\documentclass[a5paper]{article}
\usepackage{lipsum}
\usepackage{multicol} % v1.8n
\usepackage{fancyhdr} % v3.2
\pagestyle{fancy}
\cfoot{Page\\\thepage}

\usepackage{etoolbox}
\makeatletter
\appto\fancy at reset{\boxmaxdepth=\maxdimen} %or some other large 
\makeatother
\begin{document}
\lipsum[1-3]
\begin{multicols}{2}

\lipsum[4-8]
\end{multicols}
\lipsum[9-10]
\end{document}



-- 
Ulrike Fischer 
http://www.troubleshooting-tex.de/


From h.y.acetaminophen at gmail.com  Thu Mar 31 19:10:36 2016
From: h.y.acetaminophen at gmail.com (Hironobu YAMASHITA)
Date: Fri, 1 Apr 2016 02:10:36 +0900
Subject: [texhax] Misplaced footer with multicol and fancyhdr
In-Reply-To: <4cbphpxwmlug.dlg@nililand.de>
References: <56FB8046.9000203@gmail.com> <4cbphpxwmlug.dlg@nililand.de>
Message-ID: <56FD5A0C.30506@gmail.com>

On 2016/03/31 21:05, Ulrike Fischer wrote:
> As a workaround you can locally change \boxmaxdepth to some larger
> value by adding some code to \fancy at reset:
Thank you for the suggestion. It works fine.
> Imho is it a fancyhdr bug. It sets the footer in a \vbox and simply
> assumes that \boxmaxdepth is large enough. But when someone (in this
> case multicol) change \boxmaxdepth the depth of the \vbox is changed
> and so it moves up.
I don't know why \boxmaxdepth\maxdepth was added to multicol.sty, but
the assumption in fanchhdr seems harmful. I'll tell the author about
this issue.

Hironobu

